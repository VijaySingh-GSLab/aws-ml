{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/how-to-use-azureml/ml-frameworks/scikit-learn/training/train-hyperparameter-tune-deploy-with-sklearn/train-hyperparameter-tune-deploy-with-sklearn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and hyperparameter tune on Iris Dataset with Scikit-learn\n",
    "In this tutorial, we demonstrate how to use the Azure ML Python SDK to train a support vector machine (SVM) on a single-node CPU with Scikit-learn to perform classification on the popular [Iris dataset](https://archive.ics.uci.edu/ml/datasets/iris). We will also demonstrate how to perform hyperparameter tuning of the model using Azure ML's HyperDrive service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Go through the [Configuration](../../../configuration.ipynb) notebook to install the Azure Machine Learning Python SDK and create an Azure ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opt-in diagnostics for better experience, quality, and security of future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code AMYPFRS62 to authenticate.\n",
      "Interactive authentication successfully completed.\n",
      "Workspace name: bais-ml\n",
      "Azure region: eastus\n",
      "Subscription id: 328d2afe-2a26-4e47-8e3b-db00b6ada105\n",
      "Resource group: ml-resource-group\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create AmlCompute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, we use Azure ML managed compute ([AmlCompute](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute)) for our remote training compute resource.\n",
    "\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we could not find the cluster with the given name, then we will create a new cluster here. We will create an `AmlCompute` cluster of `STANDARD_D2_V2` CPU VMs. This process is broken down into 3 steps:\n",
    "1. create the configuration (this step is local and only takes a second)\n",
    "2. create the cluster (this step will take about **20 seconds**)\n",
    "3. provision the VMs to bring the cluster to the initial size (of 1 in this case). This step will take about **3-5 minutes** and is providing only sparse output in the process. Please make sure to wait until the call returns before moving to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "{'errors': [], 'creationTime': '2020-09-21T06:54:56.620586+00:00', 'createdBy': {'userObjectId': '8fa1d96a-0d33-4d7f-8816-072b711328ca', 'userTenantId': '15a31e5b-2fea-47b6-bd80-d516edbd961b', 'userName': 'VIJAY SINGH'}, 'modifiedTime': '2020-09-21T06:58:15.406003+00:00', 'state': 'Running', 'vmSize': 'STANDARD_D1'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "#cluster_name = \"cpu-cluster\"\n",
    "cluster_name = \"ml-compute-instance-v2\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code retrieves a CPU compute target. Scikit-learn does not support GPU computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on the remote compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have your data and training script prepared, you are ready to train on your remote compute. You can take advantage of Azure compute to leverage a CPU cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './sklearn-iris'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will need to create your training script. In this tutorial, the training script is already provided for you at `train_iris`.py. In practice, you should be able to take any custom training script as is and run it with Azure ML without having to modify your code.\n",
    "\n",
    "However, if you would like to use Azure ML's [tracking and metrics](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#metrics) capabilities, you will have to add a small amount of Azure ML code inside your training script.\n",
    "\n",
    "In `train_iris.py`, we will log some metrics to our Azure ML run. To do so, we will access the Azure ML Run object within the script:\n",
    "\n",
    "```python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "\n",
    "Further within `train_iris.py`, we log the kernel and penalty parameters, and the highest accuracy the model achieves:\n",
    "\n",
    "```python\n",
    "run.log('Kernel type', np.string(args.kernel))\n",
    "run.log('Penalty', np.float(args.penalty))\n",
    "\n",
    "run.log('Accuracy', np.float(accuracy))\n",
    "```\n",
    "\n",
    "These run metrics will become particularly important when we begin hyperparameter tuning our model in the \"Tune model hyperparameters\" section.\n",
    "\n",
    "Once your script is ready, copy the training script `train_iris.py` into your project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./sklearn-iris/train_iris.py'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('train_iris.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this Scikit-learn tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'train_iris'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Scikit-learn estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Azure ML SDK's Scikit-learn estimator enables you to easily submit Scikit-learn training jobs for single-node runs. The following code will define a single-node Scikit-learn job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "sklearn-remarks-sample"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have specified to install packages in your run. Note that you have overridden Azure ML's installation of the following packages: ['joblib']. We cannot guarantee image build will succeed.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "\n",
    "script_params = {\n",
    "    '--kernel': 'linear',\n",
    "    '--penalty': 1.0,\n",
    "}\n",
    "\n",
    "estimator = SKLearn(source_directory=project_folder, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='train_iris.py',\n",
    "                    pip_packages=['joblib==0.13.2']\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `script_params` parameter is a dictionary containing the command-line arguments to your training script `entry_script`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor your run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b61531c50a546e9b601dc5add797cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/train_iris/runs/train_iris_1600672092_9d9763cf?wsid=/subscriptions/328d2afe-2a26-4e47-8e3b-db00b6ada105/resourcegroups/ml-resource-group/workspaces/bais-ml\", \"run_id\": \"train_iris_1600672092_9d9763cf\", \"run_properties\": {\"run_id\": \"train_iris_1600672092_9d9763cf\", \"created_utc\": \"2020-09-21T07:08:19.752889Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"565de756-7147-448a-b62a-300a1d92e325\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":1}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-09-21T07:15:56.984029Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/20_image_build_log.txt\": \"https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=SjN3DNDix61jbnMcKBgfyVdbdf7VRatFX3y7X5l1OzQ%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt\": \"https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/55_azureml-execution-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt?sv=2019-02-02&sr=b&sig=2KJt%2FAJi9o1ormHa0QfGTQeJGtjTDcyz%2FeVCPEvpULE%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt\": \"https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/65_job_prep-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt?sv=2019-02-02&sr=b&sig=jcOfee2P7PWiknx20UcgXNIWJ9gRIiMCfxo53E3OBC8%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=adHDz7ni4LK8kFSTKkYC%2BQoPT5kLEx7Jr0YEJ9HA7qc%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r\", \"azureml-logs/75_job_post-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt\": \"https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/75_job_post-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt?sv=2019-02-02&sr=b&sig=jxJSRUCHCZbOk5BzgarUm92e0RT837U4jg6o4jrtDKM%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r\", \"azureml-logs/process_info.json\": \"https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=yUACUWqAk5ONhPBSdwh0RWt7Po2UsQAthhmIKaPQOi8%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r\", \"azureml-logs/process_status.json\": \"https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=zLKGqJzbGVTdqYMPWofbzGKYhWGvQi8MODS9DZngL9k%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r\", \"logs/azureml/92_azureml.log\": \"https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/logs/azureml/92_azureml.log?sv=2019-02-02&sr=b&sig=gSYrN6AUa3cuJj4b%2FEaaBm86BbXGdwW5wUK9M1GH6lU%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=QoUkkonVRW7aJKcFMSjfp69pjrOTAI3qZbnBFUdsjrY%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=aWnZt%2BPfdOTYaywPzO%2FtHqYpBxkLrdtMdtcZpp9270A%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/20_image_build_log.txt\"], [\"azureml-logs/55_azureml-execution-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt\"], [\"logs/azureml/92_azureml.log\"]], \"run_duration\": \"0:07:37\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Kernel type\", \"run_id\": \"train_iris_1600672092_9d9763cf\", \"categories\": [0], \"series\": [{\"data\": [\"linear\"]}]}, {\"name\": \"Penalty\", \"run_id\": \"train_iris_1600672092_9d9763cf\", \"categories\": [0], \"series\": [{\"data\": [1.0]}]}, {\"name\": \"Accuracy\", \"run_id\": \"train_iris_1600672092_9d9763cf\", \"categories\": [0], \"series\": [{\"data\": [0.9736842105263158]}]}], \"run_logs\": \"2020/09/21 07:08:30 Downloading source code...\\r\\n2020/09/21 07:08:32 Finished downloading source code\\r\\n2020/09/21 07:08:32 Creating Docker network: acb_default_network, driver: 'bridge'\\n2020/09/21 07:08:32 Successfully set up Docker network: acb_default_network\\n2020/09/21 07:08:32 Setting up Docker configuration...\\n2020/09/21 07:08:33 Successfully set up Docker configuration\\n2020/09/21 07:08:33 Logging in to registry: 1b5df4ad0b024632ac65ad6fcccac40d.azurecr.io\\n2020/09/21 07:08:34 Successfully logged into 1b5df4ad0b024632ac65ad6fcccac40d.azurecr.io\\n2020/09/21 07:08:34 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\\n2020/09/21 07:08:34 Scanning for dependencies...\\r\\n2020/09/21 07:08:35 Successfully scanned dependencies\\n2020/09/21 07:08:35 Launching container with name: acb_step_0\\nSending build context to Docker daemon  60.93kB\\r\\r\\nStep 1/14 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1@sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d\\nsha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d: Pulling from azureml/intelmpi2018.3-ubuntu16.04\\nfe703b657a32: Pulling fs layer\\nf9df1fafd224: Pulling fs layer\\na645a4b887f9: Pulling fs layer\\n57db7fe0b522: Pulling fs layer\\n20b5fabe4f63: Pulling fs layer\\n22898513a7dc: Pulling fs layer\\nb77f65fcd9d7: Pulling fs layer\\n132ebd5cd5ca: Pulling fs layer\\n01991399be72: Pulling fs layer\\n60c58ca14ef7: Pulling fs layer\\nca339bb1ce1b: Pulling fs layer\\nb77f65fcd9d7: Waiting\\n132ebd5cd5ca: Waiting\\n01991399be72: Waiting\\n60c58ca14ef7: Waiting\\nca339bb1ce1b: Waiting\\n57db7fe0b522: Waiting\\n20b5fabe4f63: Waiting\\n22898513a7dc: Waiting\\nf9df1fafd224: Verifying Checksum\\nf9df1fafd224: Download complete\\na645a4b887f9: Verifying Checksum\\na645a4b887f9: Download complete\\n57db7fe0b522: Verifying Checksum\\n57db7fe0b522: Download complete\\nfe703b657a32: Verifying Checksum\\nfe703b657a32: Download complete\\r\\n22898513a7dc: Verifying Checksum\\n22898513a7dc: Download complete\\nb77f65fcd9d7: Verifying Checksum\\nb77f65fcd9d7: Download complete\\n20b5fabe4f63: Verifying Checksum\\n20b5fabe4f63: Download complete\\n60c58ca14ef7: Verifying Checksum\\n60c58ca14ef7: Download complete\\n132ebd5cd5ca: Verifying Checksum\\n132ebd5cd5ca: Download complete\\nca339bb1ce1b: Verifying Checksum\\nca339bb1ce1b: Download complete\\n01991399be72: Verifying Checksum\\n01991399be72: Download complete\\r\\nfe703b657a32: Pull complete\\nf9df1fafd224: Pull complete\\na645a4b887f9: Pull complete\\r\\n57db7fe0b522: Pull complete\\n20b5fabe4f63: Pull complete\\r\\n22898513a7dc: Pull complete\\nb77f65fcd9d7: Pull complete\\r\\n132ebd5cd5ca: Pull complete\\r\\n01991399be72: Pull complete\\r\\n60c58ca14ef7: Pull complete\\nca339bb1ce1b: Pull complete\\nDigest: sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d\\r\\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1@sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d\\n ---> a0dab4f7c804\\nStep 2/14 : USER root\\n ---> Running in 53e66b82ae64\\nRemoving intermediate container 53e66b82ae64\\n ---> 789b0fb22425\\nStep 3/14 : RUN mkdir -p $HOME/.cache\\r\\n ---> Running in 9a43a816ade8\\nRemoving intermediate container 9a43a816ade8\\n ---> de8a25dcf6f4\\nStep 4/14 : WORKDIR /\\n ---> Running in f643fceced34\\nRemoving intermediate container f643fceced34\\n ---> 18a60443b4fd\\nStep 5/14 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\\r\\n ---> 492de516ddac\\nStep 6/14 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\\n ---> Running in dc443a742f5e\\nRemoving intermediate container dc443a742f5e\\n ---> 5621cb8996ed\\nStep 7/14 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\\r\\n ---> f08c7ca715f9\\nStep 8/14 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_618d79f5f9d88bbf887dccf51537da4b -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \\\"$HOME/.cache/pip\\\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \\\"$CONDA_ROOT_DIR/pkgs\\\" && find \\\"$CONDA_ROOT_DIR\\\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\\n ---> Running in 076fde87e30c\\nWarning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\\r\\nCollecting package metadata (repodata.json): ...working... \\r\\ndone\\r\\nSolving environment: ...working... done\\n\\nDownloading and Extracting Packages\\n\\rlibffi-3.2.1         | 43 KB     |            |   0% \\rlibffi-3.2.1         | 43 KB     | ########## | 100% \\n\\rreadline-7.0         | 387 KB    |            |   0% \\rreadline-7.0         | 387 KB    | ########## | 100% \\n\\rlibgcc-ng-9.1.0      | 8.1 MB    |            |   0% \\rlibgcc-ng-9.1.0      | 8.1 MB    | #######7   |  77% \\rlibgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \\r\\n\\ropenssl-1.0.2u       | 3.1 MB    |            |   0% \\ropenssl-1.0.2u       | 3.1 MB    | ########## | 100% \\n\\rzlib-1.2.11          | 120 KB    |            |   0% \\rzlib-1.2.11          | 120 KB    | ########## | 100% \\n\\rsetuptools-49.6.0    | 927 KB    |            |   0% \\rsetuptools-49.6.0    | 927 KB    | ########## | 100% \\n\\rpip-20.2.2           | 2.0 MB    |            |   0% \\rpip-20.2.2           | 2.0 MB    | ########## | 100% \\n\\rsqlite-3.23.1        | 1.5 MB    |            |   0% \\rsqlite-3.23.1        | 1.5 MB    | ########## | 100% \\n\\rncurses-6.0          | 907 KB    |            |   0% \\rncurses-6.0          | 907 KB    | ########## | 100% \\n\\rca-certificates-2020 | 132 KB    |            |   0% \\rca-certificates-2020 | 132 KB    | ########## | 100% \\r\\n\\rxz-5.2.5             | 438 KB    |            |   0% \\rxz-5.2.5             | 438 KB    | ########## | 100% \\n\\rpython-3.6.2         | 27.0 MB   |            |   0% \\rpython-3.6.2         | 27.0 MB   | #9         |  19% \\rpython-3.6.2         | 27.0 MB   | #####2     |  52% \\rpython-3.6.2         | 27.0 MB   | ########5  |  86% \\rpython-3.6.2         | 27.0 MB   | ########## | 100% \\r\\n\\rlibstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \\rlibstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \\n\\rtk-8.6.10            | 3.2 MB    |            |   0% \\rtk-8.6.10            | 3.2 MB    | ########## | 100% \\n\\rlibedit-3.1          | 171 KB    |            |   0% \\rlibedit-3.1          | 171 KB    | ########## | 100% \\n\\rcertifi-2020.6.20    | 160 KB    |            |   0% \\rcertifi-2020.6.20    | 160 KB    | ########## | 100% \\n\\rwheel-0.35.1         | 36 KB     |            |   0% \\rwheel-0.35.1         | 36 KB     | ########## | 100% \\nPreparing transaction: ...working... done\\r\\nVerifying transaction: ...working... done\\nExecuting transaction: ...working... done\\r\\nRan pip subprocess with arguments:\\n['/azureml-envs/azureml_618d79f5f9d88bbf887dccf51537da4b/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.2xnv6wfw.requirements.txt']\\nPip subprocess output:\\nCollecting joblib==0.13.2\\n  Downloading joblib-0.13.2-py2.py3-none-any.whl (278 kB)\\nCollecting azureml-defaults\\n  Downloading azureml_defaults-1.13.0-py3-none-any.whl (3.0 kB)\\nCollecting scikit-learn==0.20.3\\n  Downloading scikit_learn-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (5.4 MB)\\nCollecting scipy==1.2.1\\n  Downloading scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8 MB)\\nCollecting azureml-dataset-runtime[fuse]~=1.13.0\\n  Downloading azureml_dataset_runtime-1.13.0-py3-none-any.whl (3.2 kB)\\nCollecting werkzeug==0.16.1\\n  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\\nCollecting flask==1.0.3\\n  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\\nCollecting configparser==3.7.4\\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\\nCollecting json-logging-py==0.2\\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\\nCollecting gunicorn==19.9.0\\n  Downloading gunicorn-19.9.0-py2.py3-none-any.whl (112 kB)\\nCollecting applicationinsights>=0.11.7\\n  Downloading applicationinsights-0.11.9-py2.py3-none-any.whl (58 kB)\\nCollecting azureml-core~=1.13.0\\n  Downloading azureml_core-1.13.0.post1-py3-none-any.whl (2.0 MB)\\nCollecting azureml-model-management-sdk==1.0.1b6.post1\\n  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\\nCollecting numpy>=1.8.2\\n  Downloading numpy-1.19.2-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\\nCollecting pyarrow<2.0.0,>=0.17.0\\n  Downloading pyarrow-1.0.1-cp36-cp36m-manylinux2014_x86_64.whl (17.3 MB)\\nCollecting azureml-dataprep<2.1.0a,>=2.0.1a\\n  Downloading azureml_dataprep-2.0.10-py3-none-any.whl (28.2 MB)\\nCollecting fusepy<4.0.0,>=3.0.1; extra == \\\"fuse\\\"\\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\\nCollecting itsdangerous>=0.24\\n  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\\nCollecting Jinja2>=2.10\\n  Downloading Jinja2-2.11.2-py2.py3-none-any.whl (125 kB)\\nCollecting click>=5.1\\n  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*\\n  Downloading cryptography-3.1-cp35-abi3-manylinux2010_x86_64.whl (2.6 MB)\\nCollecting backports.tempfile\\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\\nCollecting azure-common>=1.1.12\\n  Downloading azure_common-1.1.25-py2.py3-none-any.whl (12 kB)\\nCollecting docker\\n  Downloading docker-4.3.1-py2.py3-none-any.whl (145 kB)\\nCollecting ndg-httpsclient\\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\\nCollecting jsonpickle\\n  Downloading jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\\nCollecting contextlib2\\n  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\\nCollecting azure-mgmt-resource<=10.2.0,>=1.2.1\\n  Downloading azure_mgmt_resource-10.2.0-py2.py3-none-any.whl (968 kB)\\nCollecting azure-mgmt-containerregistry>=2.0.0\\n  Downloading azure_mgmt_containerregistry-2.8.0-py2.py3-none-any.whl (718 kB)\\nCollecting adal>=1.2.0\\n  Downloading adal-1.2.4-py2.py3-none-any.whl (55 kB)\\nCollecting msrest>=0.5.1\\n  Downloading msrest-0.6.19-py2.py3-none-any.whl (84 kB)\\nCollecting pathspec\\n  Downloading pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\\nCollecting pyopenssl\\n  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\\nCollecting SecretStorage\\n  Downloading SecretStorage-3.1.2-py3-none-any.whl (14 kB)\\nCollecting azure-mgmt-storage>=1.5.0\\n  Downloading azure_mgmt_storage-16.0.0-py2.py3-none-any.whl (811 kB)\\nCollecting python-dateutil>=2.7.3\\n  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\\nCollecting jmespath\\n  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\\nCollecting pytz\\n  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\\nCollecting msrestazure>=0.4.33\\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\\nCollecting ruamel.yaml>=0.15.35\\n  Downloading ruamel.yaml-0.16.12-py2.py3-none-any.whl (111 kB)\\nCollecting urllib3>=1.23\\n  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\\nCollecting azure-graphrbac>=0.40.0\\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\\nCollecting azure-mgmt-authorization>=0.40.0\\n  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\\nCollecting azure-mgmt-keyvault>=0.40.0\\n  Downloading azure_mgmt_keyvault-7.0.0-py2.py3-none-any.whl (197 kB)\\nCollecting PyJWT\\n  Downloading PyJWT-1.7.1-py2.py3-none-any.whl (18 kB)\\nCollecting requests>=2.19.1\\n  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\\nCollecting dill>=0.2.7.1\\n  Downloading dill-0.3.2.zip (177 kB)\\nCollecting pandas>=0.20.2\\n  Downloading pandas-1.1.2-cp36-cp36m-manylinux1_x86_64.whl (10.5 MB)\\nCollecting liac-arff>=2.1.1\\n  Downloading liac-arff-2.5.0.tar.gz (13 kB)\\nCollecting six>=1.10\\n  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\\nCollecting azureml-dataprep-native<21.0.0,>=20.1.1\\n  Downloading azureml_dataprep_native-20.1.1-cp36-cp36m-manylinux1_x86_64.whl (11.1 MB)\\nCollecting cloudpickle<2.0.0,>=1.1.0\\n  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\\nCollecting azure-identity<1.3.0,>=1.2.0\\n  Downloading azure_identity-1.2.0-py2.py3-none-any.whl (58 kB)\\nCollecting dotnetcore2<3.0.0,>=2.1.14\\n  Downloading dotnetcore2-2.1.16-py3-none-manylinux1_x86_64.whl (28.7 MB)\\nCollecting MarkupSafe>=0.23\\n  Downloading MarkupSafe-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (27 kB)\\nCollecting cffi!=1.11.3,>=1.8\\n  Downloading cffi-1.14.3-cp36-cp36m-manylinux1_x86_64.whl (400 kB)\\nCollecting backports.weakref\\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\\nCollecting websocket-client>=0.32.0\\n  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\\nCollecting pyasn1>=0.1.1\\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\\nCollecting importlib-metadata\\n  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\\nCollecting requests-oauthlib>=0.5.0\\n  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\\nCollecting isodate>=0.6.0\\n  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_618d79f5f9d88bbf887dccf51537da4b/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core~=1.13.0->azureml-defaults->-r /azureml-environment-setup/condaenv.2xnv6wfw.requirements.txt (line 2)) (2020.6.20)\\nCollecting jeepney>=0.4.2\\n  Downloading jeepney-0.4.3-py3-none-any.whl (21 kB)\\nCollecting azure-mgmt-core<2.0.0,>=1.2.0\\n  Downloading azure_mgmt_core-1.2.0-py2.py3-none-any.whl (21 kB)\\nCollecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \\\"CPython\\\" and python_version < \\\"3.9\\\"\\n  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\\nCollecting idna<3,>=2.5\\n  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\\nCollecting chardet<4,>=3.0.2\\n  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\\nCollecting msal<2.0.0,>=1.0.0\\n  Downloading msal-1.5.0-py2.py3-none-any.whl (49 kB)\\nCollecting azure-core<2.0.0,>=1.0.0\\n  Downloading azure_core-1.8.1-py2.py3-none-any.whl (121 kB)\\nCollecting msal-extensions~=0.1.3\\n  Downloading msal_extensions-0.1.3-py2.py3-none-any.whl (9.0 kB)\\nCollecting distro>=1.2.0\\n  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\\nCollecting pycparser\\n  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\\nCollecting zipp>=0.5\\n  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\\nCollecting oauthlib>=3.0.0\\n  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\\nCollecting portalocker~=1.0\\n  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\\nBuilding wheels for collected packages: json-logging-py, fusepy, dill, liac-arff\\n  Building wheel for json-logging-py (setup.py): started\\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=6320eeac76c4b5431a2d68801eef9abd678f9aa9aacd2c527be45e0c12b81b32\\n  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\\n  Building wheel for fusepy (setup.py): started\\n  Building wheel for fusepy (setup.py): finished with status 'done'\\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=a17f015528974e370cdf1fc81e7684cb3dbbb988864bb1aa7bd0a0899b661c6a\\n  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\\n  Building wheel for dill (setup.py): started\\n  Building wheel for dill (setup.py): finished with status 'done'\\n  Created wheel for dill: filename=dill-0.3.2-py3-none-any.whl size=78912 sha256=b780d6c1e29bdda81b02f378cf0f2c589073a5914ecb6ab3349ddcc890df5496\\n  Stored in directory: /root/.cache/pip/wheels/02/49/cf/660924cd9bc5fcddc3a0246fe39800c83028d3ccea244de352\\n  Building wheel for liac-arff (setup.py): started\\n  Building wheel for liac-arff (setup.py): finished with status 'done'\\n  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11730 sha256=ed7bee9ea51c63d17eac0c6f606dcedc04ef815c790e08b40e2f293007a534e7\\n  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\\nSuccessfully built json-logging-py fusepy dill liac-arff\\nInstalling collected packages: joblib, numpy, pyarrow, azureml-dataprep-native, cloudpickle, six, pycparser, cffi, cryptography, idna, urllib3, chardet, requests, PyJWT, msal, azure-core, portalocker, msal-extensions, azure-identity, distro, dotnetcore2, azureml-dataprep, fusepy, azureml-dataset-runtime, werkzeug, itsdangerous, MarkupSafe, Jinja2, click, flask, configparser, json-logging-py, gunicorn, applicationinsights, backports.weakref, backports.tempfile, azure-common, websocket-client, docker, pyopenssl, pyasn1, ndg-httpsclient, zipp, importlib-metadata, jsonpickle, contextlib2, python-dateutil, adal, oauthlib, requests-oauthlib, isodate, msrest, msrestazure, azure-mgmt-resource, azure-mgmt-containerregistry, pathspec, jeepney, SecretStorage, azure-mgmt-core, azure-mgmt-storage, jmespath, pytz, ruamel.yaml.clib, ruamel.yaml, azure-graphrbac, azure-mgmt-authorization, azure-mgmt-keyvault, azureml-core, dill, pandas, liac-arff, azureml-model-management-sdk, azureml-defaults, scipy, scikit-learn\\nSuccessfully installed Jinja2-2.11.2 MarkupSafe-1.1.1 PyJWT-1.7.1 SecretStorage-3.1.2 adal-1.2.4 applicationinsights-0.11.9 azure-common-1.1.25 azure-core-1.8.1 azure-graphrbac-0.61.1 azure-identity-1.2.0 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-2.8.0 azure-mgmt-core-1.2.0 azure-mgmt-keyvault-7.0.0 azure-mgmt-resource-10.2.0 azure-mgmt-storage-16.0.0 azureml-core-1.13.0.post1 azureml-dataprep-2.0.10 azureml-dataprep-native-20.1.1 azureml-dataset-runtime-1.13.0 azureml-defaults-1.13.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.3 chardet-3.0.4 click-7.1.2 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.1 dill-0.3.2 distro-1.5.0 docker-4.3.1 dotnetcore2-2.1.16 flask-1.0.3 fusepy-3.0.1 gunicorn-19.9.0 idna-2.10 importlib-metadata-1.7.0 isodate-0.6.0 itsdangerous-1.1.0 jeepney-0.4.3 jmespath-0.10.0 joblib-0.13.2 json-logging-py-0.2 jsonpickle-1.4.1 liac-arff-2.5.0 msal-1.5.0 msal-extensions-0.1.3 msrest-0.6.19 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.19.2 oauthlib-3.1.0 pandas-1.1.2 pathspec-0.8.0 portalocker-1.7.1 pyarrow-1.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-19.1.0 python-dateutil-2.8.1 pytz-2020.1 requests-2.24.0 requests-oauthlib-1.3.0 ruamel.yaml-0.16.12 ruamel.yaml.clib-0.2.2 scikit-learn-0.20.3 scipy-1.2.1 six-1.15.0 urllib3-1.25.10 websocket-client-0.57.0 werkzeug-0.16.1 zipp-3.1.0\\r\\n\\n#\\n# To activate this environment, use\\n#\\n#     $ conda activate /azureml-envs/azureml_618d79f5f9d88bbf887dccf51537da4b\\n#\\n# To deactivate an active environment, use\\n#\\n#     $ conda deactivate\\n\\n\\u001b[91m\\n\\n==> WARNING: A newer version of conda exists. <==\\n  current version: 4.7.12\\n  latest version: 4.8.4\\n\\nPlease update conda by running\\n\\n    $ conda update -n base -c defaults conda\\n\\n\\n\\u001b[0mWARNING: /root/.conda/pkgs does not exist\\r\\nRemoving intermediate container 076fde87e30c\\n ---> ed0849e36926\\nStep 9/14 : ENV PATH /azureml-envs/azureml_618d79f5f9d88bbf887dccf51537da4b/bin:$PATH\\r\\n ---> Running in 51e874111066\\nRemoving intermediate container 51e874111066\\n ---> 8827b9133b80\\r\\nStep 10/14 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_618d79f5f9d88bbf887dccf51537da4b\\n ---> Running in 2549593575e0\\nRemoving intermediate container 2549593575e0\\n ---> d77fdef28ee3\\nStep 11/14 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_618d79f5f9d88bbf887dccf51537da4b/lib:$LD_LIBRARY_PATH\\r\\n ---> Running in 9bd4244c953b\\nRemoving intermediate container 9bd4244c953b\\n ---> 971ec07ad9bd\\nStep 12/14 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\\r\\n ---> 6e8af9963699\\nStep 13/14 : ENV AZUREML_ENVIRONMENT_IMAGE True\\r\\n ---> Running in 7e447494e609\\nRemoving intermediate container 7e447494e609\\n ---> c77fb375a319\\nStep 14/14 : CMD [\\\"bash\\\"]\\r\\n ---> Running in c436d60eb64a\\nRemoving intermediate container c436d60eb64a\\n ---> aebec57dd4a3\\r\\nSuccessfully built aebec57dd4a3\\nSuccessfully tagged 1b5df4ad0b024632ac65ad6fcccac40d.azurecr.io/azureml/azureml_0cf266db6beb7180c01b79fda0b048c1:latest\\n2020/09/21 07:11:13 Successfully executed container: acb_step_0\\n2020/09/21 07:11:13 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\\n2020/09/21 07:11:13 Pushing image: 1b5df4ad0b024632ac65ad6fcccac40d.azurecr.io/azureml/azureml_0cf266db6beb7180c01b79fda0b048c1:latest, attempt 1\\nThe push refers to repository [1b5df4ad0b024632ac65ad6fcccac40d.azurecr.io/azureml/azureml_0cf266db6beb7180c01b79fda0b048c1]\\n04da504b4de6: Preparing\\n311154cb890c: Preparing\\n67744ae814fa: Preparing\\n2ede4856db61: Preparing\\n2bd2ba5e70eb: Preparing\\nc2bf0aefdf8a: Preparing\\nf5aa53607bc1: Preparing\\n07eae5ad8c0b: Preparing\\nfacf43cddd83: Preparing\\n69a9bdc813b0: Preparing\\n7e2b9752143f: Preparing\\n63a67842a4c7: Preparing\\nae3a847dbd6b: Preparing\\n4ae3adcb66cb: Preparing\\naa6685385151: Preparing\\n0040d8f00d7e: Preparing\\n9e6f810a2aab: Preparing\\nc2bf0aefdf8a: Waiting\\nf5aa53607bc1: Waiting\\n07eae5ad8c0b: Waiting\\nfacf43cddd83: Waiting\\n69a9bdc813b0: Waiting\\n7e2b9752143f: Waiting\\n63a67842a4c7: Waiting\\nae3a847dbd6b: Waiting\\n4ae3adcb66cb: Waiting\\naa6685385151: Waiting\\n0040d8f00d7e: Waiting\\n9e6f810a2aab: Waiting\\n2bd2ba5e70eb: Pushed\\r\\n04da504b4de6: Pushed\\n67744ae814fa: Pushed\\n2ede4856db61: Pushed\\nc2bf0aefdf8a: Pushed\\nf5aa53607bc1: Pushed\\r\\n07eae5ad8c0b: Pushed\\n\\r\\n63a67842a4c7: Pushed\\r\\n7e2b9752143f: Pushed\\r\\n4ae3adcb66cb: Pushed\\r\\naa6685385151: Pushed\\r\\nfacf43cddd83: Pushed\\n0040d8f00d7e: Pushed\\r\\n69a9bdc813b0: Pushed\\r\\nae3a847dbd6b: Pushed\\n9e6f810a2aab: Pushed\\n311154cb890c: Pushed\\r\\nlatest: digest: sha256:999750bffd4b9ed84d7d86a42990fc7d384cc153f376be20d273a7df23cb76ed size: 3883\\r\\n2020/09/21 07:12:38 Successfully pushed image: 1b5df4ad0b024632ac65ad6fcccac40d.azurecr.io/azureml/azureml_0cf266db6beb7180c01b79fda0b048c1:latest\\n2020/09/21 07:12:38 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 158.890470)\\n2020/09/21 07:12:38 Populating digests for step ID: acb_step_0...\\n2020/09/21 07:12:40 Successfully populated digests for step ID: acb_step_0\\n2020/09/21 07:12:40 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 85.156981)\\n2020/09/21 07:12:40 The following dependencies were found:\\n2020/09/21 07:12:40 \\n- image:\\n    registry: 1b5df4ad0b024632ac65ad6fcccac40d.azurecr.io\\n    repository: azureml/azureml_0cf266db6beb7180c01b79fda0b048c1\\n    tag: latest\\n    digest: sha256:999750bffd4b9ed84d7d86a42990fc7d384cc153f376be20d273a7df23cb76ed\\n  runtime-dependency:\\n    registry: mcr.microsoft.com\\n    repository: azureml/intelmpi2018.3-ubuntu16.04\\n    tag: 20200423.v1\\n    digest: sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d\\n  git: {}\\n\\n\\r\\nRun ID: ca1 was successful after 4m11s\\r\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": true, \"log_level\": \"INFO\", \"sdk_version\": \"1.12.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: train_iris_1600672092_9d9763cf\n",
      "Web View: https://ml.azure.com/experiments/train_iris/runs/train_iris_1600672092_9d9763cf?wsid=/subscriptions/328d2afe-2a26-4e47-8e3b-db00b6ada105/resourcegroups/ml-resource-group/workspaces/bais-ml\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "2020/09/21 07:08:30 Downloading source code...\n",
      "2020/09/21 07:08:32 Finished downloading source code\n",
      "2020/09/21 07:08:32 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2020/09/21 07:08:32 Successfully set up Docker network: acb_default_network\n",
      "2020/09/21 07:08:32 Setting up Docker configuration...\n",
      "2020/09/21 07:08:33 Successfully set up Docker configuration\n",
      "2020/09/21 07:08:33 Logging in to registry: 1b5df4ad0b024632ac65ad6fcccac40d.azurecr.io\n",
      "2020/09/21 07:08:34 Successfully logged into 1b5df4ad0b024632ac65ad6fcccac40d.azurecr.io\n",
      "2020/09/21 07:08:34 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2020/09/21 07:08:34 Scanning for dependencies...\n",
      "2020/09/21 07:08:35 Successfully scanned dependencies\n",
      "2020/09/21 07:08:35 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  60.93kB\n",
      "\n",
      "Step 1/14 : FROM mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1@sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d\n",
      "sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d: Pulling from azureml/intelmpi2018.3-ubuntu16.04\n",
      "fe703b657a32: Pulling fs layer\n",
      "f9df1fafd224: Pulling fs layer\n",
      "a645a4b887f9: Pulling fs layer\n",
      "57db7fe0b522: Pulling fs layer\n",
      "20b5fabe4f63: Pulling fs layer\n",
      "22898513a7dc: Pulling fs layer\n",
      "b77f65fcd9d7: Pulling fs layer\n",
      "132ebd5cd5ca: Pulling fs layer\n",
      "01991399be72: Pulling fs layer\n",
      "60c58ca14ef7: Pulling fs layer\n",
      "ca339bb1ce1b: Pulling fs layer\n",
      "b77f65fcd9d7: Waiting\n",
      "132ebd5cd5ca: Waiting\n",
      "01991399be72: Waiting\n",
      "60c58ca14ef7: Waiting\n",
      "ca339bb1ce1b: Waiting\n",
      "57db7fe0b522: Waiting\n",
      "20b5fabe4f63: Waiting\n",
      "22898513a7dc: Waiting\n",
      "f9df1fafd224: Verifying Checksum\n",
      "f9df1fafd224: Download complete\n",
      "a645a4b887f9: Verifying Checksum\n",
      "a645a4b887f9: Download complete\n",
      "57db7fe0b522: Verifying Checksum\n",
      "57db7fe0b522: Download complete\n",
      "fe703b657a32: Verifying Checksum\n",
      "fe703b657a32: Download complete\n",
      "22898513a7dc: Verifying Checksum\n",
      "22898513a7dc: Download complete\n",
      "b77f65fcd9d7: Verifying Checksum\n",
      "b77f65fcd9d7: Download complete\n",
      "20b5fabe4f63: Verifying Checksum\n",
      "20b5fabe4f63: Download complete\n",
      "60c58ca14ef7: Verifying Checksum\n",
      "60c58ca14ef7: Download complete\n",
      "132ebd5cd5ca: Verifying Checksum\n",
      "132ebd5cd5ca: Download complete\n",
      "ca339bb1ce1b: Verifying Checksum\n",
      "ca339bb1ce1b: Download complete\n",
      "01991399be72: Verifying Checksum\n",
      "01991399be72: Download complete\n",
      "fe703b657a32: Pull complete\n",
      "f9df1fafd224: Pull complete\n",
      "a645a4b887f9: Pull complete\n",
      "57db7fe0b522: Pull complete\n",
      "20b5fabe4f63: Pull complete\n",
      "22898513a7dc: Pull complete\n",
      "b77f65fcd9d7: Pull complete\n",
      "132ebd5cd5ca: Pull complete\n",
      "01991399be72: Pull complete\n",
      "60c58ca14ef7: Pull complete\n",
      "ca339bb1ce1b: Pull complete\n",
      "Digest: sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1@sha256:a8f6491296cbc183e95e9de29b59098e97d50ea87b4f1afa93e2afd43afeaf6d\n",
      " ---> a0dab4f7c804\n",
      "Step 2/14 : USER root\n",
      " ---> Running in 53e66b82ae64\n",
      "Removing intermediate container 53e66b82ae64\n",
      " ---> 789b0fb22425\n",
      "Step 3/14 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 9a43a816ade8\n",
      "Removing intermediate container 9a43a816ade8\n",
      " ---> de8a25dcf6f4\n",
      "Step 4/14 : WORKDIR /\n",
      " ---> Running in f643fceced34\n",
      "Removing intermediate container f643fceced34\n",
      " ---> 18a60443b4fd\n",
      "Step 5/14 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 492de516ddac\n",
      "Step 6/14 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in dc443a742f5e\n",
      "Removing intermediate container dc443a742f5e\n",
      " ---> 5621cb8996ed\n",
      "Step 7/14 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> f08c7ca715f9\n",
      "Step 8/14 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_618d79f5f9d88bbf887dccf51537da4b -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 076fde87e30c\n",
      "Warning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "libffi-3.2.1         | 43 KB     |            |   0% \n",
      "libffi-3.2.1         | 43 KB     | ########## | 100% \n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | #######7   |  77% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "\n",
      "setuptools-49.6.0    | 927 KB    |            |   0% \n",
      "setuptools-49.6.0    | 927 KB    | ########## | 100% \n",
      "\n",
      "pip-20.2.2           | 2.0 MB    |            |   0% \n",
      "pip-20.2.2           | 2.0 MB    | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 132 KB    |            |   0% \n",
      "ca-certificates-2020 | 132 KB    | ########## | 100% \n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2020-09-21T07:13:08Z Starting output-watcher...\n",
      "2020-09-21T07:13:08Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_0cf266db6beb7180c01b79fda0b048c1\n",
      "fe703b657a32: Pulling fs layer\n",
      "f9df1fafd224: Pulling fs layer\n",
      "a645a4b887f9: Pulling fs layer\n",
      "57db7fe0b522: Pulling fs layer\n",
      "20b5fabe4f63: Pulling fs layer\n",
      "22898513a7dc: Pulling fs layer\n",
      "b77f65fcd9d7: Pulling fs layer\n",
      "132ebd5cd5ca: Pulling fs layer\n",
      "01991399be72: Pulling fs layer\n",
      "60c58ca14ef7: Pulling fs layer\n",
      "ca339bb1ce1b: Pulling fs layer\n",
      "0d83c3e450be: Pulling fs layer\n",
      "59e71360afdc: Pulling fs layer\n",
      "399fc13e2969: Pulling fs layer\n",
      "6521a95cbf4f: Pulling fs layer\n",
      "67f02fce72da: Pulling fs layer\n",
      "65245fdebca1: Pulling fs layer\n",
      "57db7fe0b522: Waiting\n",
      "20b5fabe4f63: Waiting\n",
      "22898513a7dc: Waiting\n",
      "b77f65fcd9d7: Waiting\n",
      "132ebd5cd5ca: Waiting\n",
      "01991399be72: Waiting\n",
      "60c58ca14ef7: Waiting\n",
      "ca339bb1ce1b: Waiting\n",
      "0d83c3e450be: Waiting\n",
      "59e71360afdc: Waiting\n",
      "399fc13e2969: Waiting\n",
      "6521a95cbf4f: Waiting\n",
      "67f02fce72da: Waiting\n",
      "65245fdebca1: Waiting\n",
      "a645a4b887f9: Verifying Checksum\n",
      "a645a4b887f9: Download complete\n",
      "f9df1fafd224: Verifying Checksum\n",
      "f9df1fafd224: Download complete\n",
      "57db7fe0b522: Verifying Checksum\n",
      "57db7fe0b522: Download complete\n",
      "fe703b657a32: Verifying Checksum\n",
      "fe703b657a32: Download complete\n",
      "22898513a7dc: Verifying Checksum\n",
      "22898513a7dc: Download complete\n",
      "20b5fabe4f63: Verifying Checksum\n",
      "20b5fabe4f63: Download complete\n",
      "b77f65fcd9d7: Verifying Checksum\n",
      "b77f65fcd9d7: Download complete\n",
      "132ebd5cd5ca: Verifying Checksum\n",
      "132ebd5cd5ca: Download complete\n",
      "60c58ca14ef7: Verifying Checksum\n",
      "60c58ca14ef7: Download complete\n",
      "ca339bb1ce1b: Verifying Checksum\n",
      "ca339bb1ce1b: Download complete\n",
      "59e71360afdc: Verifying Checksum\n",
      "59e71360afdc: Download complete\n",
      "0d83c3e450be: Verifying Checksum\n",
      "0d83c3e450be: Download complete\n",
      "6521a95cbf4f: Verifying Checksum\n",
      "6521a95cbf4f: Download complete\n",
      "399fc13e2969: Verifying Checksum\n",
      "399fc13e2969: Download complete\n",
      "01991399be72: Verifying Checksum\n",
      "01991399be72: Download complete\n",
      "65245fdebca1: Verifying Checksum\n",
      "65245fdebca1: Download complete\n",
      "67f02fce72da: Verifying Checksum\n",
      "67f02fce72da: Download complete\n",
      "fe703b657a32: Pull complete\n",
      "f9df1fafd224: Pull complete\n",
      "a645a4b887f9: Pull complete\n",
      "57db7fe0b522: Pull complete\n",
      "20b5fabe4f63: Pull complete\n",
      "22898513a7dc: Pull complete\n",
      "b77f65fcd9d7: Pull complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132ebd5cd5ca: Pull complete\n",
      "01991399be72: Pull complete\n",
      "60c58ca14ef7: Pull complete\n",
      "ca339bb1ce1b: Pull complete\n",
      "0d83c3e450be: Pull complete\n",
      "59e71360afdc: Pull complete\n",
      "399fc13e2969: Pull complete\n",
      "6521a95cbf4f: Pull complete\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "Entering job release. Current time:2020-09-21T07:15:43.697234\n",
      "Starting job release. Current time:2020-09-21T07:15:45.338965\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 118\n",
      "[2020-09-21T07:15:45.362955] job release stage : upload_datastore starting...\n",
      "[{}] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2020-09-21T07:15:45.363966] job release stage : execute_job_release starting...\n",
      "[2020-09-21T07:15:45.364150] job release stage : copy_batchai_cached_logs starting...\n",
      "[2020-09-21T07:15:45.364197] job release stage : copy_batchai_cached_logs completed...\n",
      "[2020-09-21T07:15:45.366163] Entering context manager injector.\n",
      "[2020-09-21T07:15:45.368654] job release stage : upload_datastore completed...\n",
      "[2020-09-21T07:15:45.711230] job release stage : send_run_telemetry starting...\n",
      "[2020-09-21T07:15:46.677612] job release stage : execute_job_release completed...\n",
      "[2020-09-21T07:15:47.605875] job release stage : send_run_telemetry completed...\n",
      "Job release is complete. Current time:2020-09-21T07:15:47.606054\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: train_iris_1600672092_9d9763cf\n",
      "Web View: https://ml.azure.com/experiments/train_iris/runs/train_iris_1600672092_9d9763cf?wsid=/subscriptions/328d2afe-2a26-4e47-8e3b-db00b6ada105/resourcegroups/ml-resource-group/workspaces/bais-ml\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'train_iris_1600672092_9d9763cf',\n",
       " 'target': 'ml-compute-instance-v2',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-09-21T07:13:08.340844Z',\n",
       " 'endTimeUtc': '2020-09-21T07:15:56.984029Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '565de756-7147-448a-b62a-300a1d92e325',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train_iris.py',\n",
       "  'scriptType': None,\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--kernel', 'linear', '--penalty', '1.0'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'ml-compute-instance-v2',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment train_iris Environment',\n",
       "   'version': 'Autosave_2020-09-21T07:08:17Z_c1d4854e',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['joblib==0.13.2',\n",
       "        'azureml-defaults',\n",
       "        'scikit-learn==0.20.3',\n",
       "        'scipy==1.2.1']}],\n",
       "     'name': 'azureml_618d79f5f9d88bbf887dccf51537da4b'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'cmAksCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=SjN3DNDix61jbnMcKBgfyVdbdf7VRatFX3y7X5l1OzQ%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt': 'https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/55_azureml-execution-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt?sv=2019-02-02&sr=b&sig=2KJt%2FAJi9o1ormHa0QfGTQeJGtjTDcyz%2FeVCPEvpULE%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt': 'https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/65_job_prep-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt?sv=2019-02-02&sr=b&sig=jcOfee2P7PWiknx20UcgXNIWJ9gRIiMCfxo53E3OBC8%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=adHDz7ni4LK8kFSTKkYC%2BQoPT5kLEx7Jr0YEJ9HA7qc%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt': 'https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/75_job_post-tvmps_87961dbb879fbefc8a4a1a8ab7de8c07d2d150931b4901abf0274a6fb0ce631f_d.txt?sv=2019-02-02&sr=b&sig=jxJSRUCHCZbOk5BzgarUm92e0RT837U4jg6o4jrtDKM%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=yUACUWqAk5ONhPBSdwh0RWt7Po2UsQAthhmIKaPQOi8%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=zLKGqJzbGVTdqYMPWofbzGKYhWGvQi8MODS9DZngL9k%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r',\n",
       "  'logs/azureml/92_azureml.log': 'https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/logs/azureml/92_azureml.log?sv=2019-02-02&sr=b&sig=gSYrN6AUa3cuJj4b%2FEaaBm86BbXGdwW5wUK9M1GH6lU%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=QoUkkonVRW7aJKcFMSjfp69pjrOTAI3qZbnBFUdsjrY%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.train_iris_1600672092_9d9763cf/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=aWnZt%2BPfdOTYaywPzO%2FtHqYpBxkLrdtMdtcZpp9270A%3D&st=2020-09-21T07%3A05%3A58Z&se=2020-09-21T15%3A15%3A58Z&sp=r'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen how to do a simple Scikit-learn training run using the SDK, let's see if we can further improve the accuracy of our model. We can optimize our model's hyperparameters using Azure Machine Learning's hyperparameter tuning capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a hyperparameter sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will define the hyperparameter space to sweep over. Let's tune the `kernel` and `penalty` parameters. In this example we will use random sampling to try different configuration sets of hyperparameters to maximize our primary metric, `Accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HyperDriveRunConfig is deprecated. Please use the new HyperDriveConfig class.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.hyperdrive.runconfig import HyperDriveRunConfig\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\n",
    "    \n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "    \"--kernel\": choice('linear', 'rbf', 'poly', 'sigmoid'),\n",
    "    \"--penalty\": choice(0.5, 1, 1.5)\n",
    "    }\n",
    ")\n",
    "\n",
    "hyperdrive_run_config = HyperDriveRunConfig(estimator=estimator,\n",
    "                                            hyperparameter_sampling=param_sampling, \n",
    "                                            primary_metric_name='Accuracy',\n",
    "                                            primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                            max_total_runs=12,\n",
    "                                            max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lauch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The same input parameter(s) are specified in estimator/run_config script params and HyperDrive parameter space. HyperDrive parameter space definition will override these duplicate entries. ['--kernel', '--penalty'] is the list of overridden parameter(s).\n"
     ]
    }
   ],
   "source": [
    "# start the HyperDrive run\n",
    "hyperdrive_run = experiment.submit(hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor HyperDrive runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can monitor the progress of the runs with the following Jupyter widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e018e0959b425296e521b0598c1759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/train_iris/runs/HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2?wsid=/subscriptions/328d2afe-2a26-4e47-8e3b-db00b6ada105/resourcegroups/ml-resource-group/workspaces/bais-ml\", \"run_id\": \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2\", \"run_properties\": {\"run_id\": \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2\", \"created_utc\": \"2020-09-21T07:16:17.004936Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"565de756-7147-448a-b62a-300a1d92e325\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"12\", \"max_total_jobs\": \"12\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--kernel\\\": [\\\"choice\\\", [[\\\"linear\\\", \\\"rbf\\\", \\\"poly\\\", \\\"sigmoid\\\"]]], \\\"--penalty\\\": [\\\"choice\\\", [[0.5, 1, 1.5]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--kernel\\\": [\\\"choice\\\", [[\\\"linear\\\", \\\"rbf\\\", \\\"poly\\\", \\\"sigmoid\\\"]]], \\\"--penalty\\\": [\\\"choice\\\", [[0.5, 1, 1.5]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://eastus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/328d2afe-2a26-4e47-8e3b-db00b6ada105/resourceGroups/ml-resource-group/providers/Microsoft.MachineLearningServices/workspaces/bais-ml/experiments/train_iris\\\", \\\"SubscriptionId\\\": \\\"328d2afe-2a26-4e47-8e3b-db00b6ada105\\\", \\\"ResourceGroupName\\\": \\\"ml-resource-group\\\", \\\"WorkspaceName\\\": \\\"bais-ml\\\", \\\"ExperimentName\\\": \\\"train_iris\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train_iris.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"ml-compute-instance-v2\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"joblib==0.13.2\\\", \\\"azureml-defaults\\\", \\\"scikit-learn==0.20.3\\\", \\\"scipy==1.2.1\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"565de756-7147-448a-b62a-300a1d92e325\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"15a31e5b-2fea-47b6-bd80-d516edbd961b\\\", \\\"amlClientRequestId\\\": \\\"bcb7a3e3-231d-45a8-8f1d-a1c015632581\\\", \\\"amlClientSessionId\\\": \\\"33713fea-a305-4c54-a623-f6e23a41f08e\\\", \\\"subscriptionId\\\": \\\"328d2afe-2a26-4e47-8e3b-db00b6ada105\\\", \\\"estimator\\\": \\\"SKLearn\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 12, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://eastus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/328d2afe-2a26-4e47-8e3b-db00b6ada105/resourceGroups/ml-resource-group/providers/Microsoft.MachineLearningServices/workspaces/bais-ml/experiments/train_iris\\\", \\\"SubscriptionId\\\": \\\"328d2afe-2a26-4e47-8e3b-db00b6ada105\\\", \\\"ResourceGroupName\\\": \\\"ml-resource-group\\\", \\\"WorkspaceName\\\": \\\"bais-ml\\\", \\\"ExperimentName\\\": \\\"train_iris\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train_iris.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"ml-compute-instance-v2\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"joblib==0.13.2\\\", \\\"azureml-defaults\\\", \\\"scikit-learn==0.20.3\\\", \\\"scipy==1.2.1\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"565de756-7147-448a-b62a-300a1d92e325\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"15a31e5b-2fea-47b6-bd80-d516edbd961b\\\", \\\"amlClientRequestId\\\": \\\"bcb7a3e3-231d-45a8-8f1d-a1c015632581\\\", \\\"amlClientSessionId\\\": \\\"33713fea-a305-4c54-a623-f6e23a41f08e\\\", \\\"subscriptionId\\\": \\\"328d2afe-2a26-4e47-8e3b-db00b6ada105\\\", \\\"estimator\\\": \\\"SKLearn\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 12, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"false\", \"all_jobs_generated\": \"false\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2020-09-21T07:16:18.635209\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2020-09-21T07:16:18.635209\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"207286e7cde4cb2710b2d6e481023a578d637532477ae1a12b29fb6c59f12fa6\\\"\", \"progress_metadata_digest\": \"\\\"207286e7cde4cb2710b2d6e481023a578d637532477ae1a12b29fb6c59f12fa6\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2020-09-21T07:16:18.635209\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2020-09-21T07:16:18.635209\\\"\", \"_aml_system_HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_0\": \"{\\\"--kernel\\\": \\\"sigmoid\\\", \\\"--penalty\\\": 0.5}\", \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_0\": \"{\\\"--kernel\\\": \\\"sigmoid\\\", \\\"--penalty\\\": 0.5}\", \"_aml_system_HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_1\": \"{\\\"--kernel\\\": \\\"rbf\\\", \\\"--penalty\\\": 0.5}\", \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_1\": \"{\\\"--kernel\\\": \\\"rbf\\\", \\\"--penalty\\\": 0.5}\", \"_aml_system_HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_2\": \"{\\\"--kernel\\\": \\\"linear\\\", \\\"--penalty\\\": 1}\", \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_2\": \"{\\\"--kernel\\\": \\\"linear\\\", \\\"--penalty\\\": 1}\", \"_aml_system_HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_3\": \"{\\\"--kernel\\\": \\\"poly\\\", \\\"--penalty\\\": 1}\", \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_3\": \"{\\\"--kernel\\\": \\\"poly\\\", \\\"--penalty\\\": 1}\", \"_aml_system_environment_preparation_status\": \"PREPARED\", \"environment_preparation_status\": \"PREPARED\", \"_aml_system_prepare_run_id\": \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_preparation\", \"prepare_run_id\": \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_preparation\", \"_aml_system_HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_4\": \"{\\\"--kernel\\\": \\\"sigmoid\\\", \\\"--penalty\\\": 1.5}\", \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_4\": \"{\\\"--kernel\\\": \\\"sigmoid\\\", \\\"--penalty\\\": 1.5}\", \"_aml_system_HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_5\": \"{\\\"--kernel\\\": \\\"sigmoid\\\", \\\"--penalty\\\": 1}\", \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_5\": \"{\\\"--kernel\\\": \\\"sigmoid\\\", \\\"--penalty\\\": 1}\", \"_aml_system_HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_6\": \"{\\\"--kernel\\\": \\\"poly\\\", \\\"--penalty\\\": 1.5}\", \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_6\": \"{\\\"--kernel\\\": \\\"poly\\\", \\\"--penalty\\\": 1.5}\", \"_aml_system_HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_7\": \"{\\\"--kernel\\\": \\\"rbf\\\", \\\"--penalty\\\": 1.5}\", \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_7\": \"{\\\"--kernel\\\": \\\"rbf\\\", \\\"--penalty\\\": 1.5}\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://baisml2621283428.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=7gLKix9FW0A1xToShQpm0PETs4xT1dyzn4dP5AJaU2w%3D&st=2020-09-21T07%3A09%3A29Z&se=2020-09-21T15%3A19%3A29Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:03:12\", \"hyper_parameters\": {\"--kernel\": [\"choice\", [[\"linear\", \"rbf\", \"poly\", \"sigmoid\"]]], \"--penalty\": [\"choice\", [[0.5, 1, 1.5]]]}}, \"child_runs\": [{\"run_id\": \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_3\", \"run_number\": 4, \"metric\": 0.94736842, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-09-21T07:17:13.756869Z\", \"end_time\": \"2020-09-21T07:18:14.362826Z\", \"created_time\": \"2020-09-21T07:16:54.367063Z\", \"created_time_dt\": \"2020-09-21T07:16:54.367063Z\", \"duration\": \"0:01:19\", \"hyperdrive_id\": \"be5f8d20-6d3c-4022-9cb2-4481659abfe2\", \"arguments\": null, \"param_--kernel\": \"poly\", \"param_--penalty\": 1, \"best_metric\": 0.94736842}, {\"run_id\": \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_0\", \"run_number\": 5, \"metric\": 0.23684211, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-09-21T07:18:20.789046Z\", \"end_time\": \"2020-09-21T07:19:20.641324Z\", \"created_time\": \"2020-09-21T07:16:55.226437Z\", \"created_time_dt\": \"2020-09-21T07:16:55.226437Z\", \"duration\": \"0:02:25\", \"hyperdrive_id\": \"be5f8d20-6d3c-4022-9cb2-4481659abfe2\", \"arguments\": null, \"param_--kernel\": \"sigmoid\", \"param_--penalty\": 0.5, \"best_metric\": 0.94736842}, {\"run_id\": \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_1\", \"run_number\": 6, \"metric\": 0.97368421, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-09-21T07:17:13.159711Z\", \"end_time\": \"2020-09-21T07:18:12.617267Z\", \"created_time\": \"2020-09-21T07:16:56.086711Z\", \"created_time_dt\": \"2020-09-21T07:16:56.086711Z\", \"duration\": \"0:01:16\", \"hyperdrive_id\": \"be5f8d20-6d3c-4022-9cb2-4481659abfe2\", \"arguments\": null, \"param_--kernel\": \"rbf\", \"param_--penalty\": 0.5, \"best_metric\": 0.97368421}, {\"run_id\": \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_2\", \"run_number\": 7, \"metric\": 0.97368421, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-09-21T07:18:17.18951Z\", \"end_time\": \"2020-09-21T07:19:17.477075Z\", \"created_time\": \"2020-09-21T07:16:56.492261Z\", \"created_time_dt\": \"2020-09-21T07:16:56.492261Z\", \"duration\": \"0:02:20\", \"hyperdrive_id\": \"be5f8d20-6d3c-4022-9cb2-4481659abfe2\", \"arguments\": null, \"param_--kernel\": \"linear\", \"param_--penalty\": 1, \"best_metric\": 0.97368421}, {\"run_id\": \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_5\", \"run_number\": 8, \"metric\": null, \"status\": \"Running\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-09-21T07:19:24.117329Z\", \"end_time\": \"\", \"created_time\": \"2020-09-21T07:18:32.570229Z\", \"created_time_dt\": \"2020-09-21T07:18:32.570229Z\", \"duration\": \"0:00:57\", \"hyperdrive_id\": \"be5f8d20-6d3c-4022-9cb2-4481659abfe2\", \"arguments\": null, \"param_--kernel\": \"sigmoid\", \"param_--penalty\": 1, \"best_metric\": null}, {\"run_id\": \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_4\", \"run_number\": 9, \"metric\": null, \"status\": \"Running\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-09-21T07:19:27.446643Z\", \"end_time\": \"\", \"created_time\": \"2020-09-21T07:18:33.227669Z\", \"created_time_dt\": \"2020-09-21T07:18:33.227669Z\", \"duration\": \"0:00:56\", \"hyperdrive_id\": \"be5f8d20-6d3c-4022-9cb2-4481659abfe2\", \"arguments\": null, \"param_--kernel\": \"sigmoid\", \"param_--penalty\": 1.5, \"best_metric\": null}], \"children_metrics\": {\"categories\": [0], \"series\": {\"Kernel type\": [{\"categories\": [4, 5, 6, 7], \"mode\": \"markers\", \"name\": \"Kernel type\", \"stepped\": false, \"type\": \"scatter\", \"data\": [\"poly\", \"sigmoid\", \"rbf\", \"linear\"]}, {\"categories\": [4, 5, 6, 7], \"mode\": \"lines\", \"name\": \"Kernel type_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": []}], \"Penalty\": [{\"categories\": [4, 5, 6, 7], \"mode\": \"markers\", \"name\": \"Penalty\", \"stepped\": false, \"type\": \"scatter\", \"data\": [1.0, 0.5, 0.5, 1.0]}, {\"categories\": [4, 5, 6, 7], \"mode\": \"lines\", \"name\": \"Penalty_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [1.0, 1.0, 1.0, 1.0]}], \"Accuracy\": [{\"categories\": [4, 5, 6, 7], \"mode\": \"markers\", \"name\": \"Accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9473684210526315, 0.23684210526315788, 0.9736842105263158, 0.9736842105263158]}, {\"categories\": [4, 5, 6, 7], \"mode\": \"lines\", \"name\": \"Accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9473684210526315, 0.9473684210526315, 0.9736842105263158, 0.9736842105263158]}]}, \"metricName\": null, \"primaryMetricName\": \"Accuracy\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2\", \"categories\": [0], \"series\": [{\"data\": [{\"metric_name\": \"Accuracy\", \"timestamp\": \"2020-09-21 07:18:24.649080+00:00\", \"run_id\": \"HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_1\", \"metric_value\": 0.9736842105263158, \"final\": false}]}]}], \"run_logs\": \"[2020-09-21T07:16:17.981101][API][INFO]Experiment created\\r\\n[2020-09-21T07:16:19.120243][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2020-09-21T07:16:19.4921685Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2020-09-21T07:16:19.662091][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2020-09-21T07:16:52.9831995Z][SCHEDULER][INFO]Scheduling job, id='HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_3'\\r\\n[2020-09-21T07:16:52.9300799Z][SCHEDULER][INFO]Scheduling job, id='HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_0'\\r\\n[2020-09-21T07:16:52.9302326Z][SCHEDULER][INFO]The execution environment was successfully prepared.\\r\\n[2020-09-21T07:16:53.0306074Z][SCHEDULER][INFO]Scheduling job, id='HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_2'\\r\\n[2020-09-21T07:16:52.9609990Z][SCHEDULER][INFO]Scheduling job, id='HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_1'\\r\\n[2020-09-21T07:16:54.6019833Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_3'\\r\\n[2020-09-21T07:16:55.5620068Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_0'\\r\\n[2020-09-21T07:16:56.3079952Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_1'\\r\\n[2020-09-21T07:16:56.9280440Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_2'\\r\\n[2020-09-21T07:18:21.610304][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2020-09-21T07:18:22.042043][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2020-09-21T07:18:30.9579288Z][SCHEDULER][INFO]Scheduling job, id='HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_4'\\r\\n[2020-09-21T07:18:30.9473663Z][SCHEDULER][INFO]Scheduling job, id='HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_5'\\r\\n[2020-09-21T07:18:33.0642304Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_5'\\r\\n[2020-09-21T07:18:33.6577844Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2_4'\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": true, \"log_level\": \"INFO\", \"sdk_version\": \"1.12.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2\n",
      "Web View: https://ml.azure.com/experiments/train_iris/runs/HD_be5f8d20-6d3c-4022-9cb2-4481659abfe2?wsid=/subscriptions/328d2afe-2a26-4e47-8e3b-db00b6ada105/resourcegroups/ml-resource-group/workspaces/bais-ml\n",
      "\n",
      "Streaming azureml-logs/hyperdrive.txt\n",
      "=====================================\n",
      "\n",
      "\"<START>[2020-09-21T07:16:17.981101][API][INFO]Experiment created<END>\\n\"\"<START>[2020-09-21T07:16:19.120243][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"<START>[2020-09-21T07:16:19.4921685Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\"<START>[2020-09-21T07:16:19.662091][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"\n"
     ]
    }
   ],
   "source": [
    "hyperdrive_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(hyperdrive_run.get_status() == \"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm start a Hyperparameter Tuning experiment and resuming child runs\n",
    "Often times, finding the best hyperparameter values for your model can be an iterative process, needing multiple tuning runs that learn from previous hyperparameter tuning runs. Reusing knowledge from these previous runs will accelerate the hyperparameter tuning process, thereby reducing the cost of tuning the model and will potentially improve the primary metric of the resulting model. When warm starting a hyperparameter tuning experiment with Bayesian sampling, trials from the previous run will be used as prior knowledge to intelligently pick new samples, so as to improve the primary metric. Additionally, when using Random or Grid sampling, any early termination decisions will leverage metrics from the previous runs to determine poorly performing training runs. \n",
    "\n",
    "Azure Machine Learning allows you to warm start your hyperparameter tuning run by leveraging knowledge from up to 5 previously completed hyperparameter tuning parent runs. \n",
    "\n",
    "Additionally, there might be occasions when individual training runs of a hyperparameter tuning experiment are cancelled due to budget constraints or fail due to other reasons. It is now possible to resume such individual training runs from the last checkpoint (assuming your training script handles checkpoints). Resuming an individual training run will use the same hyperparameter configuration and mount the storage used for that run. The training script should accept the \"--resume-from\" argument, which contains the checkpoint or model files from which to resume the training run. You can also resume individual runs as part of an experiment that spends additional budget on hyperparameter tuning. Any additional budget, after resuming the specified training runs is used for exploring additional configurations.\n",
    "\n",
    "For more information on warm starting and resuming hyperparameter tuning runs, please refer to the [Hyperparameter Tuning for Azure Machine Learning documentation](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters) \n",
    "\n",
    "### Find and register best model\n",
    "When all jobs finish, we can find out the one that has the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "print(best_run.get_details()['runDefinition']['arguments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's list the model files uploaded during the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then register the folder (and all files in it) as a model named `sklearn-iris` under the workspace for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name='sklearn-iris', model_path='outputs/model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Modified from https://www.geeksforgeeks.org/multiclass-classification-using-scikit-learn/\r\n",
      "\r\n",
      "import argparse\r\n",
      "import os\r\n",
      "\r\n",
      "# importing necessary libraries\r\n",
      "import numpy as np\r\n",
      "\r\n",
      "from sklearn import datasets\r\n",
      "from sklearn.metrics import confusion_matrix\r\n",
      "from sklearn.model_selection import train_test_split\r\n",
      "\r\n",
      "import joblib\r\n",
      "\r\n",
      "from azureml.core.run import Run\r\n",
      "run = Run.get_context()\r\n",
      "\r\n",
      "\r\n",
      "def main():\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    parser.add_argument('--kernel', type=str, default='linear',\r\n",
      "                        help='Kernel type to be used in the algorithm')\r\n",
      "    parser.add_argument('--penalty', type=float, default=1.0,\r\n",
      "                        help='Penalty parameter of the error term')\r\n",
      "\r\n",
      "    args = parser.parse_args()\r\n",
      "    run.log('Kernel type', np.str(args.kernel))\r\n",
      "    run.log('Penalty', np.float(args.penalty))\r\n",
      "\r\n",
      "    # loading the iris dataset\r\n",
      "    iris = datasets.load_iris()\r\n",
      "\r\n",
      "    # X -> features, y -> label\r\n",
      "    X = iris.data\r\n",
      "    y = iris.target\r\n",
      "\r\n",
      "    # dividing X, y into train and test data\r\n",
      "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\r\n",
      "\r\n",
      "    # training a linear SVM classifier\r\n",
      "    from sklearn.svm import SVC\r\n",
      "    svm_model_linear = SVC(kernel=args.kernel, C=args.penalty).fit(X_train, y_train)\r\n",
      "    svm_predictions = svm_model_linear.predict(X_test)\r\n",
      "\r\n",
      "    # model accuracy for X_test\r\n",
      "    accuracy = svm_model_linear.score(X_test, y_test)\r\n",
      "    print('Accuracy of SVM classifier on test set: {:.2f}'.format(accuracy))\r\n",
      "    run.log('Accuracy', np.float(accuracy))\r\n",
      "    # creating a confusion matrix\r\n",
      "    cm = confusion_matrix(y_test, svm_predictions)\r\n",
      "    print(cm)\r\n",
      "\r\n",
      "    os.makedirs('outputs', exist_ok=True)\r\n",
      "    # files saved in the \"outputs\" folder are automatically uploaded into run history\r\n",
      "    joblib.dump(svm_model_linear, 'outputs/model.joblib')\r\n",
      "\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    main()\r\n"
     ]
    }
   ],
   "source": [
    "!cat train_iris.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import joblib\n",
    "\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--kernel', type=str, default='linear',\n",
    "                        help='Kernel type to be used in the algorithm')\n",
    "    parser.add_argument('--penalty', type=float, default=1.0,\n",
    "                        help='Penalty parameter of the error term')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    run.log('Kernel type', np.str(args.kernel))\n",
    "    run.log('Penalty', np.float(args.penalty))\n",
    "\n",
    "    # loading the iris dataset\n",
    "    iris = datasets.load_iris()\n",
    "\n",
    "    # X -> features, y -> label\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "\n",
    "    # dividing X, y into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "    # training a linear SVM classifier\n",
    "    from sklearn.svm import SVC\n",
    "    svm_model_linear = SVC(kernel=args.kernel, C=args.penalty).fit(X_train, y_train)\n",
    "    svm_predictions = svm_model_linear.predict(X_test)\n",
    "\n",
    "    # model accuracy for X_test\n",
    "    accuracy = svm_model_linear.score(X_test, y_test)\n",
    "    print('Accuracy of SVM classifier on test set: {:.2f}'.format(accuracy))\n",
    "    run.log('Accuracy', np.float(accuracy))\n",
    "    # creating a confusion matrix\n",
    "    cm = confusion_matrix(y_test, svm_predictions)\n",
    "    print(cm)\n",
    "\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    # files saved in the \"outputs\" folder are automatically uploaded into run history\n",
    "    joblib.dump(svm_model_linear, 'outputs/model.joblib')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "swatig"
   }
  ],
  "categories": [
   "how-to-use-azureml",
   "ml-frameworks",
   "scikit-learn",
   "training"
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Iris"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "Scikit-learn"
  ],
  "friendly_name": "Training and hyperparameter tuning with Scikit-learn",
  "index_order": 1,
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "msauthor": "dipeck",
  "tags": [
   "None"
  ],
  "task": "Train a support vector machine (SVM) to perform classification"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
