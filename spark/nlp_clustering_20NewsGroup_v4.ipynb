{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spark-nlp\n",
    "#!pip install fastparquet \n",
    "#!pip install spark-nlp==2.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF, StringIndexer, SQLTransformer,IndexToString\n",
    "from pyspark.ml.feature import CountVectorizer , IDF\n",
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "from utils import CUSTOM_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[4]\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.6.1\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1000M\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "spark\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-16-10-164.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0cdbe13320>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.6.1\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n"
     ]
    }
   ],
   "source": [
    "df_spark = sqlContext.read.parquet(\"newsgroup_20_data.parquet\")\n",
    "print(df_spark.count())\n",
    "#df_spark.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "d = df_spark.head(1)\n",
    "d = d[0]\n",
    "\n",
    "print(d.asDict()['category'])\n",
    "#print(d.asDict()['news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainingData = df_spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_input = \"news\"\n",
    "col_label = \"category\"\n",
    "col_nlp = 'col_nlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(sentence):\n",
    "    \n",
    "    # clean the punctuations\n",
    "    punc_re = r'[^a-zA-Z0-9 &]'\n",
    "    sentence = re.sub(punc_re, ' ', sentence)\n",
    "    \n",
    "    # tokens\n",
    "    arr = sentence.split()\n",
    "    \n",
    "    # remove white spaces\n",
    "    # lowercase\n",
    "    # filter words having lenght <= 3\n",
    "    arr = [word.strip().lower() for word in arr if word.isalpha() and len(word)>=4]\n",
    "    \n",
    "    arr = \" \".join(arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "+--------------------+--------------------+--------------------+\n",
      "|                news|            category|             col_nlp|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|From: Mamatha Dev...|    rec.sport.hockey|from mamatha devi...|\n",
      "|From: mblawson@mi...|comp.sys.ibm.pc.h...|from mblawson mid...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = df_spark.limit(10000)\n",
    "#data = df_spark\n",
    "\n",
    "udf_text_cleaner = F.udf(text_cleaner, StringType())\n",
    "\n",
    "data_clean = data.withColumn(col_nlp, udf_text_cleaner(col_input))\n",
    "\n",
    "print(data_clean.count())\n",
    "data_clean.limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, size, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df = data_clean.filter(col(\"col_nlp\").contains(col(\"number\")))\n",
    "#df = data_clean.where(length(col(\"col_nlp\")) >=  3)\n",
    "\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "8672\n",
      "+--------------------+--------------------+--------------------+\n",
      "|            category|                news|            features|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|    rec.sport.hockey|From: Mamatha Dev...|(11222,[1,3,4,5,6...|\n",
      "|comp.sys.ibm.pc.h...|From: mblawson@mi...|(11222,[0,1,3,4,6...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def type_changer(sentence):\n",
    "    return sentence.split(\" \")\n",
    "udf_type_changer = F.udf(type_changer, ArrayType(elementType=StringType()))\n",
    "\n",
    "#data_in = data_clean.limit(1000)\n",
    "data_in = data_clean\n",
    "\n",
    "# get tokens\n",
    "data_arr = data_in.withColumn(\"col_nlp_arr\", udf_type_changer(col_nlp))\n",
    "\n",
    "data_arr = data_arr.where(size(col(\"col_nlp_arr\")) >= 50)\n",
    "\n",
    "# TF\n",
    "cv = CountVectorizer(inputCol=\"col_nlp_arr\", outputCol=\"raw_features\", minDF=10.0)\n",
    "cvmodel = cv.fit(data_arr)\n",
    "result_cv = cvmodel.transform(data_arr)\n",
    "\n",
    "# IDF\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(result_cv)\n",
    "result_tfidf = idfModel.transform(result_cv)\n",
    "\n",
    "data_pp = result_tfidf.select('category', col_input, \"features\")\n",
    "\n",
    "print(type(data_pp))\n",
    "print(data_pp.count())\n",
    "data_pp.limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done....\n"
     ]
    }
   ],
   "source": [
    "numTopics = 20 # number of topics\n",
    " \n",
    "lda = LDA(k=numTopics, seed = 1, optimizer=\"online\", optimizeDocConcentration=True,\n",
    "          maxIter = 10,           # number of iterations\n",
    "          learningDecay = 0.51,   # kappa, learning rate\n",
    "          learningOffset = 64.0,  # tau_0, larger values downweigh early iterations\n",
    "          subsamplingRate = 0.05, # mini batch fraction \n",
    "          )\n",
    " \n",
    "model = lda.fit(data_pp)\n",
    "print(\"done....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -3353019.809906279\n",
      "The upper bound on perplexity: 8.438440880488498\n"
     ]
    }
   ],
   "source": [
    "ll = model.logLikelihood(data_pp.limit(1000))\n",
    "lp = model.logPerplexity(data_pp.limit(1000))\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelling completed..!\n"
     ]
    }
   ],
   "source": [
    "print(\"modelling completed..!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. topic insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11222"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocabSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(topic=0, termIndices=[5, 23, 62, 292, 387, 2438, 338, 1082, 25, 140], termWeights=[0.006638956653846592, 0.0064438381700256155, 0.005173762968008978, 0.005089163464615525, 0.004763270586481971, 0.004142239044601799, 0.0037997531017483987, 0.0032487619708818087, 0.0032111439308443713, 0.00319652052859968])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.describeTopics().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+--------------------+--------------------+\n",
      "|topic|         termIndices|         termWeights|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[5, 23, 62, 292, ...|[0.00663895665384...|\n",
      "|    1|[302, 439, 15, 12...|[0.00644475641676...|\n",
      "|    2|[259, 23, 241, 19...|[0.00431153449081...|\n",
      "|    3|[219, 1552, 1687,...|[0.01006660274848...|\n",
      "|    4|[300, 370, 88, 33...|[0.00613868741279...|\n",
      "|    5|[936, 829, 909, 1...|[0.00489366810433...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The topics described by their top-weighted terms:\")\n",
    "model.describeTopics(5).limit(6).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(11222, 20, [618.6914, 0.3279, 267.4274, 239.3289, 383.351, 1490.7257, 0.3215, 0.9759, ..., 0.4557, 0.3079, 0.5633, 12.3413, 0.711, 0.3757, 0.486, 0.3415], 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.topicsMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_in, data_clean, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. topic assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = F.udf(lambda x: x.tolist().index(max(x)), IntegerType())\n",
    "\n",
    "\n",
    "data_lda = model.transform(data_pp)\n",
    "data_lda = data_lda.withColumn(\"topicID\", max_index(\"topicDistribution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8672\n",
      "+--------------------+--------------------+--------------------+--------------------+-------+\n",
      "|            category|                news|            features|   topicDistribution|topicID|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------+\n",
      "|    rec.sport.hockey|From: Mamatha Dev...|(11222,[1,3,4,5,6...|[1.84369692171841...|     19|\n",
      "|comp.sys.ibm.pc.h...|From: mblawson@mi...|(11222,[0,1,3,4,6...|[2.11782672755489...|     16|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_lda.count())\n",
    "data_lda.limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "topicDistribution : list of topic weights (len==num_topics)\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. topic model assesment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda_train_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8672, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>topicID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   category  topicID\n",
       "0          rec.sport.hockey       19\n",
       "1  comp.sys.ibm.pc.hardware       16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_topics = data_lda.select(\"category\", \"topicID\").toPandas()\n",
    "\n",
    "print(X_topics.shape)\n",
    "X_topics.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_metrics(df):\n",
    "    #print(df.head(2))\n",
    "    arr = df[\"topicID\"].value_counts()\n",
    "    max_topic = arr.index.values[0]\n",
    "    perc_dominance = arr[max_topic] / arr.sum()\n",
    "    \n",
    "    result = pd.Series(data=[int(max_topic), perc_dominance], index=[\"category_pred\", \"perc_dominance\"])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>category_pred</th>\n",
       "      <th>perc_dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>16</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>16</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>13</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>16</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>16</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>16</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>8</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>8</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>7</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>11</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>4</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>16</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>14</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sci.space</td>\n",
       "      <td>14</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>1</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>2</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>0</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>talk.politics.misc</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>1</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    category  category_pred  perc_dominance\n",
       "0                alt.atheism              1            0.38\n",
       "1              comp.graphics             16            0.41\n",
       "2    comp.os.ms-windows.misc             16            0.43\n",
       "3   comp.sys.ibm.pc.hardware             13            0.37\n",
       "4      comp.sys.mac.hardware             16            0.29\n",
       "5             comp.windows.x             16            0.29\n",
       "6               misc.forsale             16            0.35\n",
       "7                  rec.autos              8            0.20\n",
       "8            rec.motorcycles              8            0.13\n",
       "9         rec.sport.baseball              7            0.50\n",
       "10          rec.sport.hockey             11            0.54\n",
       "11                 sci.crypt              4            0.56\n",
       "12           sci.electronics             16            0.30\n",
       "13                   sci.med             14            0.30\n",
       "14                 sci.space             14            0.49\n",
       "15    soc.religion.christian              1            0.39\n",
       "16        talk.politics.guns              2            0.41\n",
       "17     talk.politics.mideast              0            0.22\n",
       "18        talk.politics.misc              2            0.22\n",
       "19        talk.religion.misc              1            0.34"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_topics.copy()\n",
    "#X = X_topics.head(10)\n",
    "\n",
    "X_label_mapping = X.groupby(\"category\").apply(topic_metrics).reset_index()\n",
    "X_label_mapping[\"category_pred\"] = X_label_mapping[\"category_pred\"].astype(\"int\")\n",
    "X_label_mapping[\"perc_dominance\"] = np.round(X_label_mapping[\"perc_dominance\"], 2)\n",
    "X_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mapper = {}\n",
    "for i in zip(X_label_mapping[\"category\"], X_label_mapping[\"category_pred\"]):\n",
    "    dict_mapper[i[0]] = int(i[1])\n",
    "    \n",
    "X = X_topics.copy()\n",
    "X[\"category_pred\"] = X[\"topicID\"].replace(dict_mapper)\n",
    "\n",
    "print(X.shape)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_topics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
