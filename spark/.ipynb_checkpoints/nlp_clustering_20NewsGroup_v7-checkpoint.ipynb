{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documents Clustering\n",
    "\n",
    "\n",
    "# Spark-NLP\n",
    "\n",
    "Clustering 20k documents using LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spark-nlp\n",
    "#!pip install fastparquet \n",
    "#!pip install spark-nlp==2.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql.functions import col, size, length\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF, StringIndexer, SQLTransformer,IndexToString\n",
    "from pyspark.ml.feature import CountVectorizer , IDF\n",
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "from custom_utils import CUSTOM_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-16-10-164.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f248bbbf7f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.6.1\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n"
     ]
    }
   ],
   "source": [
    "df_spark = sqlContext.read.parquet(\"newsgroup_20_data.parquet\")\n",
    "print(df_spark.count())\n",
    "#df_spark.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.sport.hockey\n",
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = df_spark.head(1)\n",
    "d = d[0]\n",
    "\n",
    "print(d.asDict()['category'])\n",
    "print(d.asDict()['news'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. data cleaning\n",
    "String level data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_input = \"news\"\n",
    "col_label = \"category\"\n",
    "col_nlp = 'col_nlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(sentence):\n",
    "    \n",
    "    # clean the punctuations\n",
    "    punc_re = r'[^a-zA-Z0-9 &]'\n",
    "    sentence = re.sub(punc_re, ' ', sentence)\n",
    "    \n",
    "    # tokens\n",
    "    arr = sentence.split()\n",
    "    \n",
    "    # remove white spaces\n",
    "    # lowercase\n",
    "    # filter words having lenght <= 3\n",
    "    arr = [word.strip().lower() for word in arr if word.isalpha() and len(word)>=4]\n",
    "    \n",
    "    # remove starting 4 words as they are email id\n",
    "    arr = arr[20:-4]\n",
    "    \n",
    "    arr = \" \".join(arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "+--------------------+--------------------+--------------------+\n",
      "|                news|            category|             col_nlp|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|From: Mamatha Dev...|    rec.sport.hockey|sure some bashers...|\n",
      "|From: mblawson@mi...|comp.sys.ibm.pc.h...|midway uoknor org...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data = df_spark.limit(10000)\n",
    "data = df_spark\n",
    "\n",
    "udf_text_cleaner = F.udf(text_cleaner, StringType())\n",
    "\n",
    "data_clean = data.withColumn(col_nlp, udf_text_cleaner(col_input))\n",
    "\n",
    "print(data_clean.count())\n",
    "data_clean.limit(2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. nlp pre-processing\n",
    "token level data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    ".setInputCol(\"col_nlp\")\\\n",
    ".setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"stem\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"stem\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)\\\n",
    "      #.setStopWords([\"no\", \"without\"])\n",
    "      \n",
    "tokenassembler = TokenAssembler()\\\n",
    "    .setInputCols([\"document\", \"cleanTokens\"]) \\\n",
    "    .setOutputCol(\"clean_text\")\n",
    "\n",
    "\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"cleanTokens\"]) \\\n",
    "    .setIncludeMetadata(False) # set to False to remove metadata\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    " documentAssembler, \n",
    " tokenizer,\n",
    " stemmer,\n",
    " stopwords_cleaner,\n",
    " #tokenassembler,\n",
    " finisher\n",
    " ])\n",
    "\n",
    "empty_df = spark.createDataFrame([['']]).toDF(\"col_nlp\")\n",
    "pipelineModel = nlpPipeline.fit(empty_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                news|            category|         col_nlp_arr|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|From: Mamatha Dev...|    rec.sport.hockey|[sure, basher, pe...|\n",
      "|From: mblawson@mi...|comp.sys.ibm.pc.h...|[midwai, uoknor, ...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data_in = data_clean.limit(1000)\n",
    "data_in = data_clean\n",
    "\n",
    "data_arr = pipelineModel.transform(data_in)\n",
    "\n",
    "data_arr = data_arr.withColumnRenamed(\"finished_cleanTokens\", \"col_nlp_arr\")\n",
    "data_arr = data_arr.select(\"news\", \"category\", \"col_nlp_arr\")\n",
    "\n",
    "data_arr.limit(2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. tfidf\n",
    "coverting text data to ML features i.e tfidf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "18846\n",
      "+--------------------+--------------------+--------------------+\n",
      "|            category|                news|            features|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|    rec.sport.hockey|From: Mamatha Dev...|(10936,[1,10,25,2...|\n",
      "|comp.sys.ibm.pc.h...|From: mblawson@mi...|(10936,[13,16,18,...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF\n",
    "cv = CountVectorizer(inputCol=\"col_nlp_arr\", outputCol=\"raw_features\", minDF=10.0)\n",
    "cvmodel = cv.fit(data_arr)\n",
    "result_cv = cvmodel.transform(data_arr)\n",
    "\n",
    "# IDF\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(result_cv)\n",
    "result_tfidf = idfModel.transform(result_cv)\n",
    "\n",
    "\n",
    "data_pp = result_tfidf.select('category', \"news\", \"features\")\n",
    "\n",
    "print(type(data_pp))\n",
    "print(data_pp.count())\n",
    "data_pp.limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up the memory by deleting meta data\n",
    "del df_spark, data_in, data_clean, data, data_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done....\n"
     ]
    }
   ],
   "source": [
    "numTopics = 20 # number of topics\n",
    " \n",
    "lda = LDA(k=numTopics, seed = 1, optimizer=\"online\", optimizeDocConcentration=True,\n",
    "          maxIter = 100,           # number of iterations\n",
    "          learningDecay = 0.51,   # kappa, learning rate\n",
    "          learningOffset = 64.0,  # tau_0, larger values downweigh early iterations\n",
    "          subsamplingRate = 0.05, # mini batch fraction \n",
    "          )\n",
    " \n",
    "model = lda.fit(data_pp)\n",
    "print(\"done....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -62048237.8191261\n",
      "The upper bound on perplexity: 8.116322726619108\n"
     ]
    }
   ],
   "source": [
    "ll = model.logLikelihood(data_pp)\n",
    "lp = model.logPerplexity(data_pp)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelling completed..!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The lower bound on the log likelihood of the entire corpus: -62048237.8191261\n",
    "The upper bound on perplexity: 8.116322726619108\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"modelling completed..!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. topic insights\n",
    "analyze the baisc stats and results of LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10936"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocabSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(topic=0, termIndices=[1, 662, 4, 0, 491, 866, 188, 572, 3, 697], termWeights=[0.004411460852739662, 0.0035909083370883653, 0.0031902594842626924, 0.0030005012275865113, 0.0029926489641961982, 0.002930798711081479, 0.0027677610071719576, 0.002763779728452812, 0.002734556764124069, 0.002688112941764219])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.describeTopics().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+--------------------+--------------------+\n",
      "|topic|         termIndices|         termWeights|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0| [1, 662, 4, 0, 491]|[0.00441146085273...|\n",
      "|    1|[1, 375, 129, 18, 4]|[0.00471588834969...|\n",
      "|    2|[29, 85, 33, 41, ...|[0.01667896786871...|\n",
      "|    3|[266, 165, 557, 5...|[0.00802559458063...|\n",
      "|    4|[141, 547, 760, 8...|[0.02130935804497...|\n",
      "|    5|[323, 625, 54, 17...|[0.01138897638407...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The topics described by their top-weighted terms:\")\n",
    "model.describeTopics(5).limit(6).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(10936, 20, [1024.5231, 1506.2962, 635.8746, 933.7162, 1089.3162, 542.5992, 417.4316, 839.7049, ..., 0.3166, 23.263, 1.348, 0.3556, 0.3033, 1.0197, 0.5744, 1.1436], 0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.topicsMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. topic assignment\n",
    "assign most prevalent topic as the prediction label for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = F.udf(lambda x: x.tolist().index(max(x)), IntegerType())\n",
    "\n",
    "\n",
    "data_lda = model.transform(data_pp)\n",
    "data_lda = data_lda.withColumn(\"topicID\", max_index(\"topicDistribution\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n",
      "+--------------------+--------------------+--------------------+--------------------+-------+\n",
      "|            category|                news|            features|   topicDistribution|topicID|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------+\n",
      "|    rec.sport.hockey|From: Mamatha Dev...|(10936,[1,10,25,2...|[2.59616787230400...|      9|\n",
      "|comp.sys.ibm.pc.h...|From: mblawson@mi...|(10936,[13,16,18,...|[2.63984907034494...|      8|\n",
      "+--------------------+--------------------+--------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_lda.count())\n",
    "data_lda.limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "topicDistribution : list of topic weights (len==num_topics)\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. topic model assesment\n",
    "analyze the qulaity of model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>topicID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   category  topicID\n",
       "0          rec.sport.hockey        9\n",
       "1  comp.sys.ibm.pc.hardware        8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_topics = data_lda.select(\"category\", \"topicID\").toPandas()\n",
    "\n",
    "print(X_topics.shape)\n",
    "X_topics.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_metrics(df):\n",
    "    #print(df.head(2))\n",
    "    arr = df[\"topicID\"].value_counts()\n",
    "    max_topic = arr.index.values[0]\n",
    "    perc_dominance = arr[max_topic] / arr.sum()\n",
    "    \n",
    "    result = pd.Series(data=[int(max_topic), perc_dominance], index=[\"category_pred\", \"perc_dominance\"])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>category_pred</th>\n",
       "      <th>perc_dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>0</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>talk.politics.misc</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>2</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>2</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>2</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>3</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>5</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>9</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>9</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>12</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>14</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>14</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>14</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>15</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>16</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>16</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>16</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sci.space</td>\n",
       "      <td>18</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    category  category_pred  perc_dominance\n",
       "0                  rec.autos              0            0.52\n",
       "1         talk.politics.guns              1            0.40\n",
       "2      talk.politics.mideast              1            0.38\n",
       "3         talk.politics.misc              1            0.25\n",
       "4             comp.windows.x              2            0.74\n",
       "5              comp.graphics              2            0.60\n",
       "6    comp.os.ms-windows.misc              2            0.54\n",
       "7                  sci.crypt              3            0.66\n",
       "8   comp.sys.ibm.pc.hardware              5            0.26\n",
       "9           rec.sport.hockey              9            0.38\n",
       "10           rec.motorcycles              9            0.37\n",
       "11                   sci.med             12            0.21\n",
       "12    soc.religion.christian             14            0.83\n",
       "13        talk.religion.misc             14            0.55\n",
       "14               alt.atheism             14            0.52\n",
       "15        rec.sport.baseball             15            0.19\n",
       "16     comp.sys.mac.hardware             16            0.26\n",
       "17              misc.forsale             16            0.23\n",
       "18           sci.electronics             16            0.17\n",
       "19                 sci.space             18            0.38"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for each category:\n",
    "    1. select the category_pred i.e topicID which is assigned to max number of docs\n",
    "    for ex: for category: \"rec.autos\", category_pred/topicID: \"0\" is assigned to 52% of records\n",
    "    \n",
    "We can observe that few category_pred are common in multiple category.\n",
    "For ex: \n",
    "topicId : 1 --> (talk.politics.guns, talk.politics.mideast, talk.politics.misc)\n",
    "topicId : 2 --> (comp.windows, comp.graphics, comp.os.ms-windows.misc)\n",
    "This also makes good sense\n",
    "\n",
    "By doing mannual evauation of topics, this mapping can be improved further\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "X = X_topics.copy()\n",
    "#X = X_topics.head(10)\n",
    "\n",
    "X_label_mapping = X.groupby(\"category\").apply(topic_metrics).reset_index()\n",
    "X_label_mapping[\"category_pred\"] = X_label_mapping[\"category_pred\"].astype(\"int\")\n",
    "X_label_mapping[\"perc_dominance\"] = np.round(X_label_mapping[\"perc_dominance\"], 2)\n",
    "X_label_mapping = X_label_mapping.sort_values(by=[\"category_pred\", \"perc_dominance\"], ascending=[True, False])\n",
    "X_label_mapping = X_label_mapping.reset_index(drop=True)\n",
    "X_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Since I am using free tier AWS sagemaker service, the available instance can't handle the much larger dataset.\n",
    "Therefore I am using only 20k rows datset.\n",
    "\n",
    "Although the complete code is in PySpark, therefore based on underlying cluster, it can be scaled up for any size of dataset.\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
