{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spark-nlp\n",
    "#!pip install fastparquet \n",
    "#!pip install spark-nlp==2.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF, StringIndexer, SQLTransformer,IndexToString\n",
    "from pyspark.ml.feature import CountVectorizer , IDF\n",
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "from utils import CUSTOM_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[4]\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.6.1\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1000M\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# start spark session configured for spark nlp\n",
    "spark = SparkSession.builder \\\n",
    "     .master('local[*]') \\\n",
    "     .appName('Spark NLP') \\\n",
    "     .config('spark.jars.packages') \\\n",
    "     .getOrCreate()\n",
    "\n",
    "spark\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark = sparknlp.start()\n",
    "\n",
    "#spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7f5d55379ba8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark\n",
    "sqlContext = SQLContext(spark)\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = SparkContext('local', 'PySPARK LDA Example')\n",
    "#sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n"
     ]
    }
   ],
   "source": [
    "df_spark = sqlContext.read.parquet(\"newsgroup_20_data.parquet\")\n",
    "print(df_spark.count())\n",
    "#df_spark.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "d = df_spark.head(1)\n",
    "d = d[0]\n",
    "\n",
    "print(d.asDict()['category'])\n",
    "#print(d.asDict()['news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(trainingData, testData) = df_spark.randomSplit([0.7, 0.3], seed = 100)\n",
    "trainingData = df_spark.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_input = \"news\"\n",
    "col_label = \"category\"\n",
    "col_nlp = 'col_nlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(sentence):\n",
    "    \n",
    "    # clean the punctuations\n",
    "    punc_re = r'[^a-zA-Z0-9 &]'\n",
    "    sentence = re.sub(punc_re, ' ', sentence)\n",
    "    \n",
    "    # tokens\n",
    "    arr = sentence.split()\n",
    "    \n",
    "    # remove white spaces\n",
    "    # lowercase\n",
    "    # filter words having lenght <= 3\n",
    "    arr = [word.strip().lower() for word in arr if word.isalpha() and len(word)>=4]\n",
    "    \n",
    "    arr = \" \".join(arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "+--------------------+------------+--------------------+\n",
      "|                news|    category|             col_nlp|\n",
      "+--------------------+------------+--------------------+\n",
      "| agate!ames!purdu...|misc.forsale|agate ames purdue...|\n",
      "| agate!iat.holone...|   rec.autos|agate holonet psi...|\n",
      "+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data = trainingData.limit(1000)\n",
    "data = trainingData\n",
    "\n",
    "udf_text_cleaner = F.udf(text_cleaner, StringType())\n",
    "\n",
    "data_train_clean = data.withColumn(col_nlp, udf_text_cleaner(col_input))\n",
    "\n",
    "print(data_train_clean.count())\n",
    "data_train_clean.limit(2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "+------------+--------------------+--------------------+\n",
      "|    category|                news|            features|\n",
      "+------------+--------------------+--------------------+\n",
      "|misc.forsale| agate!ames!purdu...|(2341,[1,5,9,10,1...|\n",
      "|   rec.autos| agate!iat.holone...|(2341,[2,4,5,8,9,...|\n",
      "+------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def type_changer(sentence):\n",
    "    return sentence.split(\" \")\n",
    "udf_type_changer = F.udf(type_changer, ArrayType(elementType=StringType()))\n",
    "\n",
    "# get tokens\n",
    "data_arr = data_train_clean.withColumn(\"col_nlp_arr\", udf_type_changer(col_nlp))\n",
    "\n",
    "# TF\n",
    "cv = CountVectorizer(inputCol=\"col_nlp_arr\", outputCol=\"raw_features\", vocabSize=5000, minDF=10.0)\n",
    "cvmodel = cv.fit(data_arr)\n",
    "result_cv = cvmodel.transform(data_arr)\n",
    "\n",
    "# IDF\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "idfModel = idf.fit(result_cv)\n",
    "result_tfidf = idfModel.transform(result_cv)\n",
    "\n",
    "pp_train_data = result_tfidf.select('category', col_input, \"features\")\n",
    "\n",
    "print(type(pp_train_data))\n",
    "pp_train_data.limit(2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -2617672.0557389343\n",
      "The upper bound on perplexity: 7.414561064286616\n"
     ]
    }
   ],
   "source": [
    "numTopics = 20 # number of topics\n",
    " \n",
    "lda = LDA(k=numTopics, seed = 1, optimizer=\"online\", optimizeDocConcentration=True,\n",
    "          maxIter = 10,           # number of iterations\n",
    "          learningDecay = 0.51,   # kappa, learning rate\n",
    "          learningOffset = 64.0,  # tau_0, larger values downweigh early iterations\n",
    "          subsamplingRate = 0.05, # mini batch fraction \n",
    "          )\n",
    " \n",
    "model = lda.fit(pp_train_data)\n",
    " \n",
    "ll = model.logLikelihood(pp_train_data)\n",
    "lp = model.logPerplexity(pp_train_data)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. topic insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2341"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocabSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(topic=0, termIndices=[100, 152, 270, 173, 141, 143, 652, 79, 1333, 1207], termWeights=[0.024727203510017844, 0.023794269140414222, 0.019429802217925642, 0.01463371667707337, 0.014203720926158618, 0.011568025166145409, 0.0077366301886060765, 0.007355781593427101, 0.00674755516396202, 0.006632266944292659])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.describeTopics().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+--------------------+--------------------+\n",
      "|topic|         termIndices|         termWeights|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[100, 152, 270, 1...|[0.02472720351001...|\n",
      "|    1|[464, 1198, 516, ...|[0.03841356958562...|\n",
      "|    2|[29, 15, 0, 12, 471]|[0.01256180374072...|\n",
      "|    3|[149, 42, 16, 544...|[0.01433550461279...|\n",
      "|    4|[606, 1619, 362, ...|[0.02711100743922...|\n",
      "|    5|[622, 469, 752, 1...|[0.04554353468421...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The topics described by their top-weighted terms:\")\n",
    "model.describeTopics(5).limit(6).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(2341, 20, [66.9965, 18.5971, 28.7697, 20.0368, 51.356, 0.3535, 49.3757, 49.3248, ..., 0.3328, 0.3344, 0.4823, 0.3447, 0.3529, 0.6234, 0.3979, 0.3094], 0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.topicsMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. topic assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "+------------+--------------------+--------------------+--------------------+-------+\n",
      "|    category|                news|            features|   topicDistribution|topicID|\n",
      "+------------+--------------------+--------------------+--------------------+-------+\n",
      "|misc.forsale| agate!ames!purdu...|(2341,[1,5,9,10,1...|[0.00125609086439...|     11|\n",
      "|   rec.autos| agate!iat.holone...|(2341,[2,4,5,8,9,...|[0.23104235605356...|      0|\n",
      "+------------+--------------------+--------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_index = F.udf(lambda x: x.tolist().index(max(x)), IntegerType())\n",
    "\n",
    "\n",
    "lda_train_data = model.transform(pp_train_data)\n",
    "lda_train_data = lda_train_data.withColumn(\"topicID\", max_index(\"topicDistribution\"))\n",
    "\n",
    "print(lda_train_data.count())\n",
    "lda_train_data.limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "topicDistribution : list of topic weights (len==num_topics)\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. topic model assesment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda_train_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>topicID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category  topicID\n",
       "0  misc.forsale       11\n",
       "1     rec.autos        0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_topics = lda_train_data.select(\"category\", \"topicID\").toPandas()\n",
    "\n",
    "print(X_topics.shape)\n",
    "X_topics.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_metrics(df):\n",
    "    #print(df.head(2))\n",
    "    arr = df[\"topicID\"].value_counts()\n",
    "    max_topic = arr.index.values[0]\n",
    "    perc_dominance = arr[max_topic] / arr.sum()\n",
    "    \n",
    "    result = pd.Series(data=[int(max_topic), perc_dominance], index=[\"category_pred\", \"perc_dominance\"])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>category_pred</th>\n",
       "      <th>perc_dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>18</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>12</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>12</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>12</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>12</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>12</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>7</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>12</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>14</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>14</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>9</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>13</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>14</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>18</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sci.space</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>8</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>6</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>0</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>talk.politics.misc</td>\n",
       "      <td>17</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>8</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    category  category_pred  perc_dominance\n",
       "0                alt.atheism             18            0.37\n",
       "1              comp.graphics             12            0.46\n",
       "2    comp.os.ms-windows.misc             12            0.74\n",
       "3   comp.sys.ibm.pc.hardware             12            0.39\n",
       "4      comp.sys.mac.hardware             12            0.39\n",
       "5             comp.windows.x             12            0.38\n",
       "6               misc.forsale              7            0.18\n",
       "7                  rec.autos             12            0.24\n",
       "8            rec.motorcycles             14            0.22\n",
       "9         rec.sport.baseball             14            0.27\n",
       "10          rec.sport.hockey              9            0.38\n",
       "11                 sci.crypt             13            0.29\n",
       "12           sci.electronics             14            0.18\n",
       "13                   sci.med             18            0.16\n",
       "14                 sci.space              0            0.33\n",
       "15    soc.religion.christian              8            0.39\n",
       "16        talk.politics.guns              6            0.39\n",
       "17     talk.politics.mideast              0            0.32\n",
       "18        talk.politics.misc             17            0.42\n",
       "19        talk.religion.misc              8            0.32"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_topics.copy()\n",
    "#X = X_topics.head(10)\n",
    "\n",
    "X_label_mapping = X.groupby(\"category\").apply(topic_metrics).reset_index()\n",
    "X_label_mapping[\"category_pred\"] = X_label_mapping[\"category_pred\"].astype(\"int\")\n",
    "X_label_mapping[\"perc_dominance\"] = np.round(X_label_mapping[\"perc_dominance\"], 2)\n",
    "X_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_mapper = {}\n",
    "for i in zip(X_label_mapping[\"category\"], X_label_mapping[\"category_pred\"]):\n",
    "    dict_mapper[i[0]] = int(i[1])\n",
    "    \n",
    "X = X_topics.copy()\n",
    "X[\"category_pred\"] = X[\"topicID\"].replace(dict_mapper)\n",
    "\n",
    "print(X.shape)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_topics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
