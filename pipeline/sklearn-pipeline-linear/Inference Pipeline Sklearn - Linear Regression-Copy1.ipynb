{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline with Scikit-learn and Linear Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-linear\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sklearn-pipeline', 'sklearn-pipeline-linearRegression')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 prefix\n",
    "S3_BUCKET = \"sklearn-pipeline\"\n",
    "S3_PREFIX = 'sklearn-pipeline-linearRegression'\n",
    "\n",
    "S3_BUCKET, S3_PREFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget --directory-prefix=./abalone_data_dir https://s3-us-west-2.amazonaws.com/sparkml-mleap/data/abalone/abalone.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3341, 9) (835, 9) (835, 8)\n",
      "4176\n",
      "(4177, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3       4       5       6     7   8\n",
       "0  M  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.15  15\n",
       "1  M  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.07   7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAW_FILE       = 'abalone.csv'\n",
    "WORK_DIRECTORY = 'abalone_data_dir/'\n",
    "\n",
    "RAW_FILE_PATH  = \"{}/{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "RAW_TRAIN_PATH = \"{}/train_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "RAW_TEST_PATH  = \"{}/test_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "RAW_VAL_PATH   = \"{}/val_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "\n",
    "X = pd.read_csv(filepath_or_buffer=RAW_FILE_PATH, header=None)\n",
    "\n",
    "train_data = X.head(int(len(X)*0.8)).copy()\n",
    "test_data  = X.tail(int(len(X)*0.2)).copy()\n",
    "val_data   = X.tail(int(len(X)*0.2)).drop(columns=[8]).copy()\n",
    "\n",
    "train_data.to_csv(path_or_buf=RAW_TRAIN_PATH, index=False)\n",
    "test_data.to_csv(path_or_buf=RAW_TEST_PATH, index=False)\n",
    "val_data.to_csv(path_or_buf=RAW_VAL_PATH, index=False)\n",
    "\n",
    "print(train_data.shape, test_data.shape, val_data.shape)\n",
    "print(len(train_data)+len(test_data))\n",
    "\n",
    "print(X.shape)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3342</th>\n",
       "      <td>M</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.112</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2      3     4       5      6      7   8\n",
       "3342  M  0.43  0.33  0.095  0.34  0.1315  0.085  0.112  14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://sklearn-pipeline/sklearn-pipeline-linearRegression/data_train/train_abalone.csv',\n",
       " 's3://sklearn-pipeline/sklearn-pipeline-linearRegression/data_test/test_abalone.csv',\n",
       " 's3://sklearn-pipeline/sklearn-pipeline-linearRegression/data_val/val_abalone.csv')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_raw_train = sagemaker_session.upload_data(\n",
    "    path=RAW_TRAIN_PATH, \n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix='{}/{}'.format(S3_PREFIX, 'data_train'))\n",
    "\n",
    "s3_input_raw_test = sagemaker_session.upload_data(\n",
    "    path=RAW_TEST_PATH, \n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix='{}/{}'.format(S3_PREFIX, 'data_test'))\n",
    "\n",
    "s3_input_raw_val = sagemaker_session.upload_data(\n",
    "    path=RAW_VAL_PATH, \n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix='{}/{}'.format(S3_PREFIX, 'data_val'))\n",
    "\n",
    "s3_input_raw_train, s3_input_raw_test, s3_input_raw_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_SCRIPT_NAME = 'sklearn_abalone_featurizer.py'\n",
    "\n",
    "# preprocessor setup\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "sklearn_preprocessor = SKLearn(\n",
    "                            entry_point=PP_SCRIPT_NAME,\n",
    "                            role=role,\n",
    "                            framework_version=FRAMEWORK_VERSION,\n",
    "                            train_instance_type=\"ml.c4.xlarge\",\n",
    "                            sagemaker_session=sagemaker_session\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-16 19:54:01 Starting - Starting the training job...\n",
      "2020-09-16 19:54:04 Starting - Launching requested ML instances......"
     ]
    }
   ],
   "source": [
    "sklearn_preprocessor.fit({'train': s3_input_raw_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch transform the raw data\n",
    "only useful to test the ml_model individually\n",
    "else not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "raw data + label : 9\n",
    "features + label : 12\n",
    "\n",
    "raw data : 8\n",
    "features : 11 (this is pred model required data)\n",
    "\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "pp_transformer = sklearn_preprocessor.transformer(\n",
    "                                                    instance_count=1, \n",
    "                                                    instance_type='ml.m5.xlarge',\n",
    "                                                    assemble_with = 'Line',\n",
    "                                                    accept = 'text/csv'\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess training data : s3_input_raw_train\n",
    "pp_transformer.transform(s3_input_raw_train, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + pp_transformer.latest_transform_job.job_name)\n",
    "pp_transformer.wait()\n",
    "s3_pp_train = pp_transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# batch preprocess test data : s3_input_raw_test\n",
    "pp_transformer.transform(s3_input_raw_test, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + pp_transformer.latest_transform_job.job_name)\n",
    "pp_transformer.wait()\n",
    "s3_pp_test = pp_transformer.output_path\n",
    "\"\"\"\n",
    "s3_pp_test = s3_pp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# batch preprocess val data : s3_input_raw_val\n",
    "pp_transformer.transform(s3_input_raw_val, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + pp_transformer.latest_transform_job.job_name)\n",
    "pp_transformer.wait()\n",
    "s3_pp_val = pp_transformer.output_path\n",
    "\"\"\"\n",
    "s3_pp_val = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_raw_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_pp_train, s3_pp_test, s3_pp_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML model (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_MODEL_SCRIPT_NAME = \"model_script.py\"\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = '0.23-1'\n",
    "ml_estimator = SKLearn(\n",
    "                    entry_point=ML_MODEL_SCRIPT_NAME,\n",
    "                    role = get_execution_role(),\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c5.xlarge',\n",
    "                    framework_version=FRAMEWORK_VERSION,\n",
    "                    base_job_name='rf-scikit',\n",
    "                    metric_definitions=[\n",
    "                                        {'Name': 'median-AE',\n",
    "                                         'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}\n",
    "                                        ],\n",
    "                    hyperparameters = {'n-estimators': 100,\n",
    "                                       'min-samples-leaf': 2,\n",
    "                                       'features': 'CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT',\n",
    "                                       'target': 'target'\n",
    "                                      }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN the model\n",
    "ml_estimator.fit({'train':s3_pp_train, 'test': s3_pp_test}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# step_1 : get models\n",
    "pp_transformer_model = sklearn_preprocessor.create_model()\n",
    "ml_estimator_model   = ml_estimator.create_model()\n",
    "\n",
    "# step_2 : set-up pipeline\n",
    "model_name    = 'sklearn-inference-pipeline-' + timestamp_prefix\n",
    "endpoint_name = 'sklearn-inference-pipeline-ep-' + timestamp_prefix\n",
    "ml_pipeline_model = PipelineModel(\n",
    "                                    name=model_name, \n",
    "                                    role=role, \n",
    "                                    models=[\n",
    "                                            pp_transformer_model, \n",
    "                                            ml_estimator_model\n",
    "                                            ]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch prediction job\n",
    "\n",
    "\"\"\"\n",
    "ml_pipeline_tf = ml_pipeline_model.transformer(\n",
    "                                            instance_count=1, \n",
    "                                            instance_type='ml.m5.xlarge',\n",
    "                                            assemble_with = 'Line',\n",
    "                                            accept = 'text/csv')\n",
    "\n",
    "# input : s3_input_raw_val (raw input data)\n",
    "ml_pipeline_tf.transform(s3_input_raw_val, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + ml_pipeline_tf.latest_transform_job.job_name)\n",
    "ml_pipeline_tf.wait()\n",
    "s3_pred_val = ml_pipeline_tf.output_path\n",
    "s3_pred_val\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deploy pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm_model.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge', endpoint_name=endpoint_name)\n",
    "ml_pipeline_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict from pipeline endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "\n",
    "\n",
    "payload = 'M, 0.43, 0.33, 0.095, 0.34, 0.1315, 0.085, 0.11' # 14\n",
    "# b'[7.8421190476190485]'\n",
    "# b'[8.006166666666667]'\n",
    "\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=csv_serializer,\n",
    "    content_type=CONTENT_TYPE_CSV,\n",
    "    accept=CONTENT_TYPE_JSON)\n",
    "\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict : only using model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy only the - ml model\n",
    "ml_predictor = ml_estimator.deploy(instance_type='ml.m4.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, file_name):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    prefix = parsed_url.path[1:]\n",
    "    s3 = boto3.resource('s3')\n",
    "    print(bucket_name)\n",
    "    print(prefix)\n",
    "    print(file_name)\n",
    "    obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n",
    "    return obj.get()[\"Body\"].read().decode('utf-8')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path       = preprocessed_val\n",
    "batch_file = 'abalone_val.csv' # imp\n",
    "output = get_csv_output_from_s3(path, '{}.out'.format(batch_file))\n",
    "validate_df = pd.read_csv(io.StringIO(output), sep=\",\", header=None)\n",
    "print(validate_df.shape)\n",
    "validate_df.sample(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `data` is a NumPy array or a Python list.\n",
    "# `response` is a NumPy array.\n",
    "\n",
    "#payload = validate_df.drop(columns=[0]).values\n",
    "payload = validate_df.values\n",
    "\n",
    "response = ml_predictor.predict(payload)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint <a class=\"anchor\" id=\"delete_endpoint\"></a>\n",
    "Once we are finished with the endpoint, we clean up the resources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
