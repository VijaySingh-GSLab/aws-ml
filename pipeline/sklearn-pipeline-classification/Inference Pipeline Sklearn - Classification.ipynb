{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline with Scikit-learn and Linear Learner\n",
    "\n",
    "1. fit/train a sklearn pre-processor\n",
    "   \n",
    "   it will perform preprocessing of numeric cat cols\n",
    "   \n",
    "** numeric : imputation, scaling\n",
    "\n",
    "** categoric : imputation, one-hot-encoding\n",
    "   \n",
    "** also perform batch transformation of train/test data to be used for ml_model training\n",
    "   \n",
    "   \n",
    "2. train sklearn ml model (RF regressor)\n",
    "\n",
    "3. build up inference-ml-pipeline\n",
    "    raw_data --> [preprocessing ==> ml_model] --> prediction\n",
    "    \n",
    "4. deploy inference-ml-pipeline as an endpoint\n",
    "\n",
    "5. prediction using the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, file_name):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    prefix = parsed_url.path[1:]\n",
    "    s3 = boto3.resource('s3')\n",
    "    print(bucket_name)\n",
    "    print(prefix)\n",
    "    print(file_name)\n",
    "    obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n",
    "    return obj.get()[\"Body\"].read().decode('utf-8')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sklearn-pipeline', 'sklearn-pipeline-linearRegression')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 prefix\n",
    "S3_BUCKET = \"sklearn-pipeline\"\n",
    "S3_PREFIX = 'sklearn-pipeline-linearRegression'\n",
    "\n",
    "S3_BUCKET, S3_PREFIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget --directory-prefix=./abalone_data_dir https://s3-us-west-2.amazonaws.com/sparkml-mleap/data/abalone/abalone.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3341, 9) (835, 9) (835, 8)\n",
      "4176\n",
      "(4177, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3       4       5       6     7  8\n",
       "0  M  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.15  0\n",
       "1  M  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.07  1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAW_FILE       = 'abalone.csv'\n",
    "WORK_DIRECTORY = 'abalone_data_dir'\n",
    "\n",
    "RAW_FILE_PATH  = \"{}/{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "RAW_TRAIN_PATH = \"{}/train/train_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "RAW_TEST_PATH  = \"{}/test/test_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "RAW_VAL_PATH   = \"{}/val/val_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "\n",
    "PP_TRAIN_PATH = \"{}/pp_train/train_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "PP_TEST_PATH  = \"{}/pp_test/test_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "PP_VAL_PATH   = \"{}/pp_val/val_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "\n",
    "ARTIFACTS_PATH = \"{}/artifacts\".format(WORK_DIRECTORY)\n",
    "\n",
    "X = pd.read_csv(filepath_or_buffer=RAW_FILE_PATH, header=None)\n",
    "X[8] = np.where(X[8]>=8, 0, 1)\n",
    "\n",
    "train_data = X.head(int(len(X)*0.8)).copy()\n",
    "test_data  = X.tail(int(len(X)*0.2)).copy()\n",
    "val_data   = X.tail(int(len(X)*0.2)).drop(columns=[8]).copy()\n",
    "\n",
    "train_data.to_csv(path_or_buf=RAW_TRAIN_PATH, index=False, header=None)\n",
    "test_data.to_csv(path_or_buf=RAW_TEST_PATH, index=False, header=None)\n",
    "val_data.to_csv(path_or_buf=RAW_VAL_PATH, index=False, header=None)\n",
    "\n",
    "print(train_data.shape, test_data.shape, val_data.shape)\n",
    "print(len(train_data)+len(test_data))\n",
    "\n",
    "print(X.shape)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    2670\n",
       " 1     671\n",
       " Name: 8, dtype: int64,\n",
       " 0    667\n",
       " 1    168\n",
       " Name: 8, dtype: int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[8].value_counts(), test_data[8].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4       5      6     7  8\n",
       "0  M  0.455  0.365  0.095  0.514  0.2245  0.101  0.15  0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://sklearn-pipeline/sklearn-pipeline-linearRegression/data_train/train_abalone.csv',\n",
       " 's3://sklearn-pipeline/sklearn-pipeline-linearRegression/data_test/test_abalone.csv',\n",
       " 's3://sklearn-pipeline/sklearn-pipeline-linearRegression/data_val/val_abalone.csv')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_raw_train = sagemaker_session.upload_data(\n",
    "    path=RAW_TRAIN_PATH, \n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix='{}/{}'.format(S3_PREFIX, 'data_train'))\n",
    "\n",
    "s3_input_raw_test = sagemaker_session.upload_data(\n",
    "    path=RAW_TEST_PATH, \n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix='{}/{}'.format(S3_PREFIX, 'data_test'))\n",
    "\n",
    "s3_input_raw_val = sagemaker_session.upload_data(\n",
    "    path=RAW_VAL_PATH, \n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix='{}/{}'.format(S3_PREFIX, 'data_val'))\n",
    "\n",
    "s3_input_raw_train, s3_input_raw_test, s3_input_raw_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_SCRIPT_NAME = 'sklearn_abalone_featurizer.py'\n",
    "\n",
    "# preprocessor setup\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "sklearn_preprocessor = SKLearn(\n",
    "                            entry_point=PP_SCRIPT_NAME,\n",
    "                            role=role,\n",
    "                            framework_version=FRAMEWORK_VERSION,\n",
    "                            train_instance_type=\"ml.c4.xlarge\",\n",
    "                            sagemaker_session=sagemaker_session\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================_training_the_transformModel_========================================\n",
      "extracting arguments\n",
      "data shape :  (3341, 9)\n",
      "to_predict_col : [0. 1.] : [2670  671]\n",
      "imp : shape of data before pp:  (3341, 8)\n",
      "sample data : \n",
      " [['M' 0.455 0.365 0.095 0.514 0.2245 0.101 0.15]]\n",
      "imp : shape of data after pp:  (3341, 10)\n",
      "sample data : \n",
      " [-0.55842639 -0.41971975 -1.03973418 -0.62995301 -0.59257744 -0.71598627\n",
      " -0.62714171  0.          0.          1.        ]\n",
      "saved model!\n"
     ]
    }
   ],
   "source": [
    "train_data_local_dir = \"/\".join(RAW_TRAIN_PATH.split(\"/\")[:-1])\n",
    "artifacts_local_dir  = ARTIFACTS_PATH\n",
    "\n",
    "! python sklearn_abalone_featurizer.py --output-data-dir abalone_data_dir/artifacts/ \\\n",
    "                                       --model-dir abalone_data_dir/artifacts/ \\\n",
    "                                       --train abalone_data_dir/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once local run is succesfull, train the container based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-17 11:57:53 Starting - Starting the training job...\n",
      "2020-09-17 11:57:56 Starting - Launching requested ML instances......\n",
      "2020-09-17 11:59:11 Starting - Preparing the instances for training......\n",
      "2020-09-17 12:00:13 Downloading - Downloading input data......\n",
      "2020-09-17 12:01:00 Training - Downloading the training image..\n",
      "2020-09-17 12:01:38 Uploading - Uploading generated training model\n",
      "2020-09-17 12:01:38 Completed - Training job completed\n",
      "Training seconds: 85\n",
      "Billable seconds: 85\n"
     ]
    }
   ],
   "source": [
    "sklearn_preprocessor.fit({'train': s3_input_raw_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch transform the raw data to train/test data\n",
    "required for training the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "raw data + label : 9\n",
    "features + label : 12\n",
    "\n",
    "raw data : 8\n",
    "features : 11 (this is pred model required data)\n",
    "\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "pp_transformer = sklearn_preprocessor.transformer(\n",
    "                                                    instance_count=1, \n",
    "                                                    instance_type='ml.m5.xlarge',\n",
    "                                                    assemble_with = 'Line',\n",
    "                                                    accept = 'text/csv'\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for transform job: sagemaker-scikit-learn-2020-09-17-12-02-06-346\n",
      "..................................\u001b[34m2020-09-17 12:07:38,677 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-17 12:07:38,679 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-17 12:07:38,679 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:38 [crit] 13#13: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:38 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-09-17 12:07:38,808 INFO - sagemaker-containers - Module sklearn_abalone_featurizer does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-09-17 12:07:38,808 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-09-17 12:07:38,808 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-09-17 12:07:38,808 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:38 [crit] 13#13: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:38 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:38 [crit] 13#13: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:38 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:39 [crit] 13#13: *7 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:39 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:39 [crit] 13#13: *9 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:39 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:39 [crit] 13#13: *11 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:39 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sklearn-abalone-featurizer\n",
      "  Building wheel for sklearn-abalone-featurizer (setup.py): started\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:39 [crit] 13#13: *13 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:39 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:39 [crit] 13#13: *15 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:39 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\n",
      "  Building wheel for sklearn-abalone-featurizer (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn-abalone-featurizer: filename=sklearn_abalone_featurizer-1.0.0-py2.py3-none-any.whl size=10759 sha256=5c8778f20f00ec8590fc15d957dc369dd1fde91e947224498bf8a5813fe3a591\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-n5vklzn0/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built sklearn-abalone-featurizer\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:39 [crit] 13#13: *17 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:39 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:39 [crit] 13#13: *19 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:39 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sklearn-abalone-featurizer\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:39 [crit] 13#13: *21 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:39 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mSuccessfully installed sklearn-abalone-featurizer-1.0.0\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:39 [crit] 13#13: *23 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:39 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:39 [crit] 13#13: *25 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:39 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:40 [crit] 13#13: *27 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:40 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:40 [crit] 13#13: *29 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:40 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:40 [crit] 13#13: *31 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:40 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:40 [crit] 13#13: *33 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:40 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/17 12:07:40 [crit] 13#13: *35 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:40 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-09-17 12:07:40 +0000] [32] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2020-09-17 12:07:40 +0000] [32] [INFO] Listening at: unix:/tmp/gunicorn.sock (32)\u001b[0m\n",
      "\u001b[34m[2020-09-17 12:07:40 +0000] [32] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-09-17 12:07:40 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2020-09-17 12:07:40 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-09-17 12:07:40 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-09-17 12:07:40 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m2020-09-17 12:07:41,198 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:41 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-09-17 12:07:41,663 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:42 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m======================================== input_fn ========================================\u001b[0m\n",
      "\u001b[34mThis is a labelled example, includes the col_to_predict\u001b[0m\n",
      "\u001b[34mdf.shape :  (3341, 9)\u001b[0m\n",
      "\u001b[34m======================================== predict_fn ========================================\u001b[0m\n",
      "\u001b[34mimp : raw data shape : \u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[34mtraining job\u001b[0m\n",
      "\u001b[34mimp : pp feature data shape : (3341, 11)\u001b[0m\n",
      "\u001b[34msample data : \n",
      " [ 0.         -0.55842639 -0.41971975 -1.03973418 -0.62995301 -0.59257744\n",
      " -0.71598627 -0.62714171  0.          0.          1.        ]\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [17/Sep/2020:12:07:42 +0000] \"POST /invocations HTTP/1.1\" 200 511784 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2020-09-17T12:07:42.101:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess training data : s3_input_raw_train\n",
    "pp_transformer.transform(s3_input_raw_train, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + pp_transformer.latest_transform_job.job_name)\n",
    "pp_transformer.wait()\n",
    "s3_pp_train = pp_transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# batch preprocess test data : s3_input_raw_test\n",
    "pp_transformer.transform(s3_input_raw_test, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + pp_transformer.latest_transform_job.job_name)\n",
    "pp_transformer.wait()\n",
    "s3_pp_test = pp_transformer.output_path\n",
    "\"\"\"\n",
    "s3_pp_test = s3_pp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only useful to assessing the ml_model only endpoint\n",
    "\"\"\"\n",
    "# batch preprocess val data : s3_input_raw_val\n",
    "pp_transformer.transform(s3_input_raw_val, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + pp_transformer.latest_transform_job.job_name)\n",
    "pp_transformer.wait()\n",
    "s3_pp_val = pp_transformer.output_path\n",
    "\"\"\"\n",
    "s3_pp_val = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sklearn-pipeline/sklearn-pipeline-linearRegression/data_train/train_abalone.csv'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_raw_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-17-12-02-06-346',\n",
       " 's3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-17-12-02-06-346',\n",
       " None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_pp_train, s3_pp_test, s3_pp_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML model (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_MODEL_SCRIPT_NAME = \"model_script.py\"\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = '0.23-1'\n",
    "ml_estimator = SKLearn(\n",
    "                    entry_point=ML_MODEL_SCRIPT_NAME,\n",
    "                    role = get_execution_role(),\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c5.xlarge',\n",
    "                    framework_version=FRAMEWORK_VERSION,\n",
    "                    base_job_name='rf-scikit',\n",
    "                    metric_definitions=[\n",
    "                                        {'Name': 'median-AE',\n",
    "                                         'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}\n",
    "                                        ],\n",
    "                    hyperparameters = {'n-estimators': 100,\n",
    "                                       'min-samples-leaf': 2,\n",
    "                                       'features': 'CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT',\n",
    "                                       'target': 'target'\n",
    "                                      }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-120286446822\n",
      "sagemaker-scikit-learn-2020-09-17-12-02-06-346\n",
      "train_abalone.csv.out\n",
      "(3341, 11) (3341, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.516983</td>\n",
       "      <td>-0.570109</td>\n",
       "      <td>-0.688968</td>\n",
       "      <td>-0.861892</td>\n",
       "      <td>-0.811230</td>\n",
       "      <td>-0.880144</td>\n",
       "      <td>-0.836163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.351209</td>\n",
       "      <td>-0.369590</td>\n",
       "      <td>-0.338202</td>\n",
       "      <td>-0.711335</td>\n",
       "      <td>-0.797705</td>\n",
       "      <td>-0.693187</td>\n",
       "      <td>-0.450005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6   \\\n",
       "1564  1.0 -0.516983 -0.570109 -0.688968 -0.861892 -0.811230 -0.880144   \n",
       "1572  0.0 -0.351209 -0.369590 -0.338202 -0.711335 -0.797705 -0.693187   \n",
       "\n",
       "            7    8    9    10  \n",
       "1564 -0.836163  0.0  1.0  0.0  \n",
       "1572 -0.450005  0.0  1.0  0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch data\n",
    "s3uri     = s3_pp_train\n",
    "file_name = '{}.out'.format(RAW_TRAIN_PATH.split(\"/\")[-1])\n",
    "s3_obj = get_csv_output_from_s3(s3uri, file_name)\n",
    "train_df_pp  = pd.read_csv(io.StringIO(s3_obj), sep=\",\", header=None)\n",
    "\n",
    "\"\"\"\n",
    "s3uri     = s3_pp_test\n",
    "file_name = '{}.out'.format(RAW_TEST_PATH.split(\"/\")[-1])\n",
    "s3_obj = get_csv_output_from_s3(s3uri, file_name)\n",
    "test_df_pp  = pd.read_csv(io.StringIO(s3_obj), sep=\",\", header=None)\n",
    "\"\"\"\n",
    "test_df_pp = train_df_pp.copy()\n",
    "\n",
    "\n",
    "train_df_pp.to_csv(path_or_buf=PP_TRAIN_PATH, index=False, header=None)\n",
    "test_df_pp.to_csv(path_or_buf=PP_TEST_PATH, index=False, header=None)\n",
    "#val_df_pp.to_csv(path_or_buf=PP_VAL_PATH, index=False, header=None)\n",
    "\n",
    "print(train_df_pp.shape, test_df_pp.shape)\n",
    "train_df_pp.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('abalone_data_dir/pp_train',\n",
       " 'abalone_data_dir/pp_train',\n",
       " 'abalone_data_dir/artifacts')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_train_data_local_dir = \"/\".join(PP_TRAIN_PATH.split(\"/\")[:-1])\n",
    "pp_test_data_local_dir = \"/\".join(PP_TRAIN_PATH.split(\"/\")[:-1])\n",
    "artifacts_local_dir  = ARTIFACTS_PATH\n",
    "pp_train_data_local_dir, pp_test_data_local_dir, artifacts_local_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (3.1.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (46.1.3.post20200330)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: seaborn in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.10.0)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seaborn) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seaborn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seaborn) (3.1.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.22.0->seaborn) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.22.0->seaborn) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas>=0.22.0->seaborn) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn) (46.1.3.post20200330)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "extracting arguments\n",
      "args.train abalone_data_dir/pp_train/\n",
      "args.test abalone_data_dir/pp_test/\n",
      "reading train data\n",
      "args.train :  abalone_data_dir/pp_train/\n",
      "(3341, 11)\n",
      "    0         1        2         3   ...        7    8    9    10\n",
      "0  0.0 -0.558426 -0.41972 -1.039734  ... -0.627142  0.0  0.0  1.0\n",
      "\n",
      "[1 rows x 11 columns]\n",
      "reading test data\n",
      "args.test :  abalone_data_dir/pp_test/\n",
      "(3341, 11)\n",
      "building training and testing datasets\n",
      "columns :  [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "col_to_predict : 0, arg_type : <class 'numpy.int64'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "train : [0. 1.] : [2670  671]\n",
      "test  : [0. 1.] : [2670  671]\n",
      "training model\n",
      "----------------------------------------------------------------------------------------------------\n",
      "X_train.shape :  (3341, 10)\n",
      "model training on num features :  10\n",
      "sample data : \n",
      " [[-0.55842639 -0.41971975 -1.03973418 -0.62995301 -0.59257744 -0.71598627\n",
      "  -0.62714171  0.          0.          1.        ]]\n",
      "accuracy  : 0.98\n",
      "precision : 0.98\n",
      "recall    : 0.96\n",
      "\n",
      "Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       small       0.98      0.99      0.99      2670\n",
      "       large       0.97      0.92      0.95       671\n",
      "\n",
      "    accuracy                           0.98      3341\n",
      "   macro avg       0.98      0.96      0.97      3341\n",
      "weighted avg       0.98      0.98      0.98      3341\n",
      "\n",
      "model persisted at abalone_data_dir/artifacts/model.joblib\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "! python model_script.py --n-estimators 100 \\\n",
    "                         --min-samples-leaf 2 \\\n",
    "                         --model-dir 'abalone_data_dir/artifacts' \\\n",
    "                         --train 'abalone_data_dir/pp_train/' \\\n",
    "                         --test 'abalone_data_dir/pp_test/' \\\n",
    "                         --features 'CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT' \\\n",
    "                         --target 'abc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once local run is succesfull, train the container based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-17 13:21:02 Starting - Starting the training job...\n",
      "2020-09-17 13:21:04 Starting - Launching requested ML instances......\n",
      "2020-09-17 13:22:21 Starting - Preparing the instances for training......\n",
      "2020-09-17 13:23:07 Downloading - Downloading input data...\n",
      "2020-09-17 13:23:57 Training - Training image download completed. Training in progress.\u001b[34m2020-09-17 13:23:57,593 sagemaker-training-toolkit INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-09-17 13:23:57,595 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-17 13:23:57,604 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-09-17 13:23:57,965 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-17 13:24:04,231 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-17 13:24:04,241 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-17 13:24:04,250 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"features\": \"CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT\",\n",
      "        \"n-estimators\": 100,\n",
      "        \"min-samples-leaf\": 2,\n",
      "        \"target\": \"target\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rf-scikit-2020-09-17-13-21-02-527\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-120286446822/rf-scikit-2020-09-17-13-21-02-527/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"model_script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"model_script.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"features\":\"CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT\",\"min-samples-leaf\":2,\"n-estimators\":100,\"target\":\"target\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=model_script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=model_script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-120286446822/rf-scikit-2020-09-17-13-21-02-527/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"features\":\"CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT\",\"min-samples-leaf\":2,\"n-estimators\":100,\"target\":\"target\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rf-scikit-2020-09-17-13-21-02-527\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-120286446822/rf-scikit-2020-09-17-13-21-02-527/source/sourcedir.tar.gz\",\"module_name\":\"model_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"model_script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--features\",\"CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT\",\"--min-samples-leaf\",\"2\",\"--n-estimators\",\"100\",\"--target\",\"target\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURES=CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT\u001b[0m\n",
      "\u001b[34mSM_HP_N-ESTIMATORS=100\u001b[0m\n",
      "\u001b[34mSM_HP_MIN-SAMPLES-LEAF=2\u001b[0m\n",
      "\u001b[34mSM_HP_TARGET=target\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python model_script.py --features CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT --min-samples-leaf 2 --n-estimators 100 --target target\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mCollecting matplotlib\n",
      "  Downloading matplotlib-3.3.2-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.7/site-packages (from matplotlib) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (88 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.7/site-packages (from matplotlib) (1.18.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /miniconda3/lib/python3.7/site-packages (from matplotlib) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting certifi>=2020.06.20\n",
      "  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyparsing, cycler, kiwisolver, certifi, matplotlib\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.4.5.1\n",
      "    Uninstalling certifi-2020.4.5.1:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled certifi-2020.4.5.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed certifi-2020.6.20 cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.3.2 pyparsing-2.4.7\u001b[0m\n",
      "\u001b[34mCollecting seaborn\n",
      "  Downloading seaborn-0.11.0-py3-none-any.whl (283 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib>=2.2 in /miniconda3/lib/python3.7/site-packages (from seaborn) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.7/site-packages (from seaborn) (1.18.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.7/site-packages (from seaborn) (1.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.7/site-packages (from seaborn) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2020.06.20 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2020.6.20)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (7.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2020.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: seaborn\u001b[0m\n",
      "\u001b[34mSuccessfully installed seaborn-0.11.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mextracting arguments\u001b[0m\n",
      "\u001b[34margs.train /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34margs.test /opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mreading train data\u001b[0m\n",
      "\u001b[34margs.train :  /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m(3341, 11)\n",
      "    0         1        2         3   ...        7    8    9    10\u001b[0m\n",
      "\u001b[34m0  0.0 -0.558426 -0.41972 -1.039734  ... -0.627142  0.0  0.0  1.0\n",
      "\u001b[0m\n",
      "\u001b[34m[1 rows x 11 columns]\u001b[0m\n",
      "\u001b[34mreading test data\u001b[0m\n",
      "\u001b[34margs.test :  /opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34m(3341, 11)\u001b[0m\n",
      "\u001b[34mbuilding training and testing datasets\u001b[0m\n",
      "\u001b[34mcolumns :  [ 0  1  2  3  4  5  6  7  8  9 10]\u001b[0m\n",
      "\u001b[34mcol_to_predict : 0, arg_type : <class 'numpy.int64'>\u001b[0m\n",
      "\u001b[34m<class 'pandas.core.series.Series'>\u001b[0m\n",
      "\u001b[34mtrain : [0. 1.] : [2670  671]\u001b[0m\n",
      "\u001b[34mtest  : [0. 1.] : [2670  671]\u001b[0m\n",
      "\u001b[34mtraining model\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mX_train.shape :  (3341, 10)\u001b[0m\n",
      "\u001b[34mmodel training on num features :  10\u001b[0m\n",
      "\u001b[34msample data : \n",
      " [[-0.55842639 -0.41971975 -1.03973418 -0.62995301 -0.59257744 -0.71598627\n",
      "  -0.62714171  0.          0.          1.        ]]\u001b[0m\n",
      "\u001b[34maccuracy  : 0.98\u001b[0m\n",
      "\u001b[34mprecision : 0.98\u001b[0m\n",
      "\u001b[34mrecall    : 0.96\n",
      "\u001b[0m\n",
      "\u001b[34mClassification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       small       0.98      0.99      0.99      2670\n",
      "       large       0.97      0.92      0.95       671\n",
      "\n",
      "    accuracy                           0.98      3341\n",
      "   macro avg       0.98      0.96      0.97      3341\u001b[0m\n",
      "\u001b[34mweighted avg       0.98      0.98      0.98      3341\n",
      "\u001b[0m\n",
      "\u001b[34mmodel persisted at /opt/ml/model/model.joblib\u001b[0m\n",
      "\u001b[34m2\u001b[0m\n",
      "\u001b[34m2020-09-17 13:24:11,813 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-09-17 13:24:20 Uploading - Uploading generated training model\n",
      "2020-09-17 13:24:20 Completed - Training job completed\n",
      "Training seconds: 73\n",
      "Billable seconds: 73\n"
     ]
    }
   ],
   "source": [
    "# TRAIN the model\n",
    "ml_estimator.fit({'train':s3_pp_train, 'test': s3_pp_test}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# step_1 : get models\n",
    "pp_transformer_model = sklearn_preprocessor.create_model()\n",
    "ml_estimator_model   = ml_estimator.create_model()\n",
    "\n",
    "# step_2 : set-up pipeline\n",
    "model_name    = 'sklearn-inference-pipeline-' + timestamp_prefix\n",
    "endpoint_name = 'sklearn-inference-pipeline-ep-' + timestamp_prefix\n",
    "ml_pipeline_model = PipelineModel(\n",
    "                                    name=model_name, \n",
    "                                    role=role, \n",
    "                                    models=[\n",
    "                                            pp_transformer_model, \n",
    "                                            ml_estimator_model\n",
    "                                            ]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# batch prediction job\n",
    "\n",
    "\"\"\"\n",
    "ml_pipeline_tf = ml_pipeline_model.transformer(\n",
    "                                            instance_count=1, \n",
    "                                            instance_type='ml.m5.xlarge',\n",
    "                                            assemble_with = 'Line',\n",
    "                                            accept = 'text/csv')\n",
    "\n",
    "# input : s3_input_raw_val (raw input data)\n",
    "ml_pipeline_tf.transform(s3_input_raw_val, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + ml_pipeline_tf.latest_transform_job.job_name)\n",
    "ml_pipeline_tf.wait()\n",
    "s3_pred_val = ml_pipeline_tf.output_path\n",
    "s3_pred_val\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deploy pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "#sm_model.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge', endpoint_name=endpoint_name)\n",
    "ml_pipeline_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict from pipeline endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sklearn-inference-pipeline-ep-2020-09-17-13-25-55'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['M', 0.43, 0.33, 0.095, 0.34, 0.1315, 0.085, 0.11199999999999999,\n",
       "        0]], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[1.0]'\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "\n",
    "\n",
    "payload = 'M, 0.43, 0.33, 0.095, 0.34, 0.1315, 0.085, 0.11' # 14\n",
    "# b'[7.8421190476190485]'\n",
    "# b'[8.006166666666667]'\n",
    "#[1.0]\n",
    "\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=csv_serializer,\n",
    "    content_type=CONTENT_TYPE_CSV,\n",
    "    accept=CONTENT_TYPE_JSON)\n",
    "\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict : only using model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy only the - ml model\n",
    "ml_predictor = ml_estimator.deploy(instance_type='ml.m4.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, file_name):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    prefix = parsed_url.path[1:]\n",
    "    s3 = boto3.resource('s3')\n",
    "    print(bucket_name)\n",
    "    print(prefix)\n",
    "    print(file_name)\n",
    "    obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n",
    "    return obj.get()[\"Body\"].read().decode('utf-8')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path       = preprocessed_val\n",
    "batch_file = 'abalone_val.csv' # imp\n",
    "output = get_csv_output_from_s3(path, '{}.out'.format(batch_file))\n",
    "validate_df = pd.read_csv(io.StringIO(output), sep=\",\", header=None)\n",
    "print(validate_df.shape)\n",
    "validate_df.sample(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `data` is a NumPy array or a Python list.\n",
    "# `response` is a NumPy array.\n",
    "\n",
    "#payload = validate_df.drop(columns=[0]).values\n",
    "payload = validate_df.values\n",
    "\n",
    "response = ml_predictor.predict(payload)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint <a class=\"anchor\" id=\"delete_endpoint\"></a>\n",
    "Once we are finished with the endpoint, we clean up the resources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
