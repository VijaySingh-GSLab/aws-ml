{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline with Scikit-learn and Linear Learner\n",
    "\n",
    "1. fit/train a sklearn pre-processor\n",
    "   \n",
    "   it will perform preprocessing of numeric cat cols\n",
    "   \n",
    "** numeric : imputation, scaling\n",
    "\n",
    "** categoric : imputation, one-hot-encoding\n",
    "   \n",
    "** also perform batch transformation of train/test data to be used for ml_model training\n",
    "   \n",
    "   \n",
    "2. train sklearn ml model (RF regressor)\n",
    "\n",
    "3. build up inference-ml-pipeline\n",
    "    raw_data --> [preprocessing ==> ml_model] --> prediction\n",
    "    \n",
    "4. deploy inference-ml-pipeline as an endpoint\n",
    "\n",
    "5. prediction using the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SHAP\n",
    "# 2. store artifacts of sm train job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, file_name):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    prefix = parsed_url.path[1:]\n",
    "    s3 = boto3.resource('s3')\n",
    "    print(bucket_name)\n",
    "    print(prefix)\n",
    "    print(file_name)\n",
    "    obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n",
    "    return obj.get()[\"Body\"].read().decode('utf-8')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sklearn-pipeline', 'sklearn-pipeline-titanic')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 prefix\n",
    "S3_BUCKET = \"sklearn-pipeline\"\n",
    "S3_PREFIX = 'sklearn-pipeline-titanic'\n",
    "\n",
    "S3_BUCKET, S3_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_predict = \"survived\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 100\n",
    "\n",
    "RAW_FILE       = 'titanic_dataset.csv'\n",
    "WORK_DIRECTORY = '/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir'\n",
    "\n",
    "RAW_FILE_PATH  = \"{}/raw_data/{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "RAW_TRAIN_PATH = \"{}/train/train_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "RAW_TEST_PATH  = \"{}/test/test_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "RAW_VAL_PATH   = \"{}/val/val_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "\n",
    "PP_TRAIN_PATH = \"{}/pp_train/train_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "PP_TEST_PATH  = \"{}/pp_test/test_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "PP_VAL_PATH   = \"{}/pp_val/val_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "\n",
    "ARTIFACTS_PATH = \"{}/artifacts\".format(WORK_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data: (1309, 7), train: (850, 7), test: (328, 7), val: (131, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>sex</th>\n",
       "      <th>pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>user_0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>user_1</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  survived user_id      age      fare embarked     sex  pclass\n",
       "0        1  user_0  29.0000  211.3375        S  female     1.0\n",
       "1        1  user_1   0.9167  151.5500        S    male     1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "X[col_to_predict] = y\n",
    "X[\"user_id\"] = [\"user_\"+str(i) for i in range(len(X))]\n",
    "\n",
    "from pre_processing_script import COLLIST_ALL, COLLIST_FEATURE\n",
    "X = X[COLLIST_ALL]\n",
    "\n",
    "# train, test, val : 65%, 25%, 10%\n",
    "train_data, test_data, val_data = np.split(X.sample(frac=1, random_state=SEED), [int(.65*len(X)), int(.9*len(X))])\n",
    "val_data = val_data[COLLIST_FEATURE]\n",
    "\n",
    "# save the data\n",
    "train_data.to_csv(path_or_buf=RAW_TRAIN_PATH, index=False, header=None)\n",
    "test_data.to_csv(path_or_buf=RAW_TEST_PATH, index=False, header=None)\n",
    "val_data.to_csv(path_or_buf=RAW_VAL_PATH, index=False, header=None)\n",
    "\n",
    "print(\"raw_data: {}, train: {}, test: {}, val: {}\".format(X.shape, train_data.shape, test_data.shape, val_data.shape))\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    526\n",
       " 1    324\n",
       " Name: survived, dtype: int64,\n",
       " 0    202\n",
       " 1    126\n",
       " Name: survived, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[col_to_predict].value_counts(), test_data[col_to_predict].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>sex</th>\n",
       "      <th>pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>user_173</td>\n",
       "      <td>32.5</td>\n",
       "      <td>211.5</td>\n",
       "      <td>C</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    survived   user_id   age   fare embarked   sex  pclass\n",
       "173        0  user_173  32.5  211.5        C  male     1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverify that the train/test/data are successfully created and saved\n",
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>user_173</td>\n",
       "      <td>32.5</td>\n",
       "      <td>211.5</td>\n",
       "      <td>C</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1     2      3  4     5    6\n",
       "0  0  user_173  32.5  211.5  C  male  1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverify that the train/test/data are successfully created and saved\n",
    "temp_train_data = pd.read_csv(filepath_or_buffer=RAW_TRAIN_PATH, header=None)\n",
    "temp_train_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://sklearn-pipeline/sklearn-pipeline-titanic/data_train/train_titanic_dataset.csv',\n",
       " 's3://sklearn-pipeline/sklearn-pipeline-titanic/data_test/test_titanic_dataset.csv',\n",
       " 's3://sklearn-pipeline/sklearn-pipeline-titanic/data_val/val_titanic_dataset.csv')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_raw_train = sagemaker_session.upload_data(\n",
    "    path=RAW_TRAIN_PATH, \n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix='{}/{}'.format(S3_PREFIX, 'data_train'))\n",
    "\n",
    "s3_input_raw_test = sagemaker_session.upload_data(\n",
    "    path=RAW_TEST_PATH, \n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix='{}/{}'.format(S3_PREFIX, 'data_test'))\n",
    "\n",
    "s3_input_raw_val = sagemaker_session.upload_data(\n",
    "    path=RAW_VAL_PATH, \n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix='{}/{}'.format(S3_PREFIX, 'data_val'))\n",
    "\n",
    "s3_input_raw_train, s3_input_raw_test, s3_input_raw_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import set_config\n",
    "#set_config(display='diagram')\n",
    "#preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================_sklearn-pre-processor_========================================\n",
      "extracting arguments\n",
      "data loading completed:\n",
      "data shape :  (850, 7)\n",
      "columns : ['survived', 'user_id', 'age', 'fare', 'embarked', 'sex', 'pclass']\n",
      "loaded RAW data : \n",
      " [[0 'user_173' 32.5 211.5 'C' 'male' 1]] \n",
      "\n",
      "to_predict_col : [0 1] : [526 324]\n",
      "\n",
      "before pp : FEATURE data shape :  (850, 5)\n",
      "columns (5 columns): ['age', 'fare', 'embarked', 'sex', 'pclass']\n",
      "sample data : \n",
      " [[32.5 211.5 'C' 'male' 1]] \n",
      "\n",
      "[ColumnTransformer] ........... (1 of 2) Processing num, total=   0.0s\n",
      "[ColumnTransformer] ........... (2 of 2) Processing cat, total=   0.0s\n",
      "\n",
      "after pp : FEATURE data shape :  (850, 10)\n",
      "(IMP) column (10 columns): ['age' 'fare' 'x0_C' 'x0_Q' 'x0_S' 'x1_female' 'x1_male' 'x2_1' 'x2_2'\n",
      " 'x2_3']\n",
      "sample data : \n",
      " [0.23750065 3.71563628 1.         0.         0.         0.\n",
      " 1.         1.         0.         0.        ]\n",
      "\n",
      "saved model at :  /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/artifacts/model.joblib\n"
     ]
    }
   ],
   "source": [
    "train_data_local_dir = \"/\".join(RAW_TRAIN_PATH.split(\"/\")[:-1])\n",
    "artifacts_local_dir  = ARTIFACTS_PATH\n",
    "artifacts_local_dir, train_data_local_dir\n",
    "\n",
    "! python pre_processing_script.py --output-data-dir /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/artifacts/ \\\n",
    "                                  --model-dir /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/artifacts/ \\\n",
    "                                  --train /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3uri_df_data(s3uri=None, return_df=False, header=None):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    prefix = parsed_url.path[1:]\n",
    "    s3 = boto3.resource('s3')\n",
    "    print(bucket_name)\n",
    "    print(prefix)\n",
    "    obj = s3.Object(bucket_name, prefix)\n",
    "    data_stream = obj.get()[\"Body\"].read().decode('utf-8')   \n",
    "    \n",
    "    if return_df:\n",
    "        df = pd.read_csv(StringIO(input_data), header=header)\n",
    "        return df\n",
    "    \n",
    "    return data_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from pre_processing_script import model_fn as pp_model_fn\n",
    "from pre_processing_script import predict_fn as pp_predict_fn\n",
    "from pre_processing_script import input_fn as pp_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.compose._column_transformer.ColumnTransformer'>\n",
      "sklearn-pipeline\n",
      "sklearn-pipeline-titanic/data_val/val_titanic_dataset.csv\n",
      "======================================== input_fn ========================================\n",
      "This pred/val data i.e unlabelled, not include col_to_predict\n",
      "df.shape :  (131, 5)\n",
      "(131, 5)\n"
     ]
    }
   ],
   "source": [
    "#s3_data_path = s3_input_raw_train\n",
    "s3_data_path = s3_input_raw_val\n",
    "model_dir = artifacts_local_dir\n",
    "\n",
    "# verify model_fn\n",
    "model     = pp_model_fn(model_dir)\n",
    "print(type(model))\n",
    "\n",
    "# verify input_fn\n",
    "input_data = get_s3uri_df_data(s3uri=s3_data_path, return_df=False, header=None)\n",
    "df = pp_input_fn(input_data, content_type=\"text/csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== predict_fn ========================================\n",
      "before pp :  data shape : (131, 5)\n",
      "input data type : <class 'pandas.core.frame.DataFrame'>\n",
      "test/pred job\n",
      "only contain the feature data\n",
      "after pp : data shape : (131, 10)\n",
      "sample data : \n",
      " [-1.69835544  0.08898475  0.          0.          1.          0.\n",
      "  1.          0.          1.          0.        ]\n",
      "(131, 10)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# verify predict_fn\n",
    "pp_data = pp_predict_fn(input_data=df, model=model)\n",
    "\n",
    "print(pp_data.shape)\n",
    "print(type(pp_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import set_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"465993ce-8e47-4dcb-9d04-c6309d5347d9\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"465993ce-8e47-4dcb-9d04-c6309d5347d9\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['age', 'fare']),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(fill_value='missing',\n",
       "                                                                strategy='constant')),\n",
       "                                                 ('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 ['embarked', 'sex', 'pclass'])],\n",
       "                  verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c3fa8ff5-cb9f-4bf2-8e62-078fe3d542c9\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c3fa8ff5-cb9f-4bf2-8e62-078fe3d542c9\">num</label><div class=\"sk-toggleable__content\"><pre>['age', 'fare']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"76b0e6aa-f8ec-485e-b82c-c33f4db04174\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"76b0e6aa-f8ec-485e-b82c-c33f4db04174\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='median')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e00f367b-7457-48ca-9fde-2dc7fe953326\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e00f367b-7457-48ca-9fde-2dc7fe953326\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b77dd35f-f020-4359-bbaf-24a4568d90f8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b77dd35f-f020-4359-bbaf-24a4568d90f8\">cat</label><div class=\"sk-toggleable__content\"><pre>['embarked', 'sex', 'pclass']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9504c1a5-cdda-4938-9979-b804c53feaba\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"9504c1a5-cdda-4938-9979-b804c53feaba\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value='missing', strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"13dd8f96-d109-4a36-9465-f2bb67e931d1\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"13dd8f96-d109-4a36-9465-f2bb67e931d1\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['age', 'fare']),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(fill_value='missing',\n",
       "                                                                strategy='constant')),\n",
       "                                                 ('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 ['embarked', 'sex', 'pclass'])],\n",
       "                  verbose=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model\n",
    "f = plt.figure()\n",
    "set_config(display='diagram')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once local run is succesfull, train the container based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_SCRIPT_NAME = 'pre_processing_script.py'\n",
    "\n",
    "# preprocessor setup\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "sklearn_preprocessor = SKLearn(\n",
    "                            entry_point=PP_SCRIPT_NAME,\n",
    "                            role=role,\n",
    "                            framework_version=FRAMEWORK_VERSION,\n",
    "                            train_instance_type=\"ml.c4.xlarge\",\n",
    "                            sagemaker_session=sagemaker_session\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-19 11:09:50 Starting - Starting the training job...\n",
      "2020-09-19 11:09:52 Starting - Launching requested ML instances.........\n",
      "2020-09-19 11:11:22 Starting - Preparing the instances for training......\n",
      "2020-09-19 11:12:29 Downloading - Downloading input data...\n",
      "2020-09-19 11:13:09 Training - Downloading the training image..\u001b[34m2020-09-19 11:13:32,813 sagemaker-training-toolkit INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-09-19 11:13:32,815 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-19 11:13:32,825 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-09-19 11:13:33,187 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\n",
      "2020-09-19 11:13:50 Uploading - Uploading generated training model\n",
      "2020-09-19 11:13:50 Completed - Training job completed\n",
      "\u001b[34m2020-09-19 11:13:39,453 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-19 11:13:39,465 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-19 11:13:39,476 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2020-09-19-11-09-49-926\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-19-11-09-49-926/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"pre_processing_script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pre_processing_script.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=pre_processing_script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=pre_processing_script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-19-11-09-49-926/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-09-19-11-09-49-926\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-19-11-09-49-926/source/sourcedir.tar.gz\",\"module_name\":\"pre_processing_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"pre_processing_script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python pre_processing_script.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m========================================_sklearn-pre-processor_========================================\u001b[0m\n",
      "\u001b[34mextracting arguments\u001b[0m\n",
      "\u001b[34mdata loading completed:\u001b[0m\n",
      "\u001b[34mdata shape :  (850, 7)\u001b[0m\n",
      "\u001b[34mcolumns : ['survived', 'user_id', 'age', 'fare', 'embarked', 'sex', 'pclass']\u001b[0m\n",
      "\u001b[34mloaded RAW data : \n",
      " [[0 'user_173' 32.5 211.5 'C' 'male' 1]] \n",
      "\u001b[0m\n",
      "\u001b[34mto_predict_col : [0 1] : [526 324]\n",
      "\u001b[0m\n",
      "\u001b[34mbefore pp : FEATURE data shape :  (850, 5)\u001b[0m\n",
      "\u001b[34mcolumns (5 columns): ['age', 'fare', 'embarked', 'sex', 'pclass']\u001b[0m\n",
      "\u001b[34msample data : \n",
      " [[32.5 211.5 'C' 'male' 1]] \n",
      "\u001b[0m\n",
      "\u001b[34m[ColumnTransformer] ........... (1 of 2) Processing num, total=   0.0s\u001b[0m\n",
      "\u001b[34m[ColumnTransformer] ........... (2 of 2) Processing cat, total=   0.0s\n",
      "\u001b[0m\n",
      "\u001b[34mafter pp : FEATURE data shape :  (850, 10)\u001b[0m\n",
      "\u001b[34m(IMP) column (10 columns): ['age' 'fare' 'x0_C' 'x0_Q' 'x0_S' 'x1_female' 'x1_male' 'x2_1' 'x2_2'\n",
      " 'x2_3']\u001b[0m\n",
      "\u001b[34msample data : \n",
      " [0.23750065 3.71563628 1.         0.         0.         0.\n",
      " 1.         1.         0.         0.        ]\n",
      "\u001b[0m\n",
      "\u001b[34msaved model at :  /opt/ml/model/model.joblib\u001b[0m\n",
      "\u001b[34m2020-09-19 11:13:41,247 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 81\n",
      "Billable seconds: 81\n"
     ]
    }
   ],
   "source": [
    "sklearn_preprocessor.fit({'train': s3_input_raw_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch transform the raw data to train/test data\n",
    "required for training the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "raw data + label : 9\n",
    "features + label : 12\n",
    "\n",
    "raw data : 8\n",
    "features : 11 (this is pred model required data)\n",
    "\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "pp_transformer = sklearn_preprocessor.transformer(\n",
    "                                                    instance_count=1, \n",
    "                                                    instance_type='ml.m5.xlarge',\n",
    "                                                    assemble_with = 'Line',\n",
    "                                                    accept = 'text/csv'\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for transform job: sagemaker-scikit-learn-2020-09-19-11-14-04-030\n",
      ".............................\u001b[34m2020-09-19 11:18:48,026 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-19 11:18:48,028 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-19 11:18:48,029 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:48 [crit] 14#14: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:48 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:48 [crit] 14#14: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:48 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-09-19 11:18:48,183 INFO - sagemaker-containers - Module pre_processing_script does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-09-19 11:18:48,183 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-09-19 11:18:48,183 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-09-19 11:18:48,183 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:48 [crit] 14#14: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:48 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:48 [crit] 14#14: *7 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:48 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:48 [crit] 14#14: *9 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:48 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:48 [crit] 14#14: *11 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:48 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:48 [crit] 14#14: *13 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:48 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pre-processing-script\n",
      "  Building wheel for pre-processing-script (setup.py): started\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:48 [crit] 14#14: *15 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:48 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:48 [crit] 14#14: *17 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:48 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\n",
      "  Building wheel for pre-processing-script (setup.py): finished with status 'done'\n",
      "  Created wheel for pre-processing-script: filename=pre_processing_script-1.0.0-py2.py3-none-any.whl size=10474 sha256=e4156f0cd7d8fe3334831601d2829e1e2e68959c87ca22c4c73d7466283994fd\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-0xaiao5p/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built pre-processing-script\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:48 [crit] 14#14: *19 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:48 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:49 [crit] 14#14: *21 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:49 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pre-processing-script\u001b[0m\n",
      "\u001b[34mSuccessfully installed pre-processing-script-1.0.0\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:49 [crit] 14#14: *23 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:49 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:49 [crit] 14#14: *25 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:49 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:49 [crit] 14#14: *27 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:49 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:49 [crit] 14#14: *29 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:49 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:49 [crit] 14#14: *31 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:49 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:49 [crit] 14#14: *33 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:49 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:49 [crit] 14#14: *35 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:49 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:18:49 [crit] 14#14: *37 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:49 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:18:49 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:18:49 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:18:49 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:18:49 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:18:50 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:18:50 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:18:50 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[34m2020-09-19 11:18:50,748 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:51 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-09-19 11:18:51,237 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:51 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-09-19 11:18:51,706 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m======================================== input_fn ========================================\u001b[0m\n",
      "\u001b[34mtraining data i.e includes the col_to_predict\u001b[0m\n",
      "\u001b[34mdf.shape :  (850, 7)\u001b[0m\n",
      "\u001b[34m======================================== predict_fn ========================================\u001b[0m\n",
      "\u001b[34mbefore pp :  data shape : (850, 7)\u001b[0m\n",
      "\u001b[34minput data type : <class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[34mtraining job\u001b[0m\n",
      "\u001b[34mbelow data includes : index_0: col_to_predict, index_1: col_primary_identifer\u001b[0m\n",
      "\u001b[34mafter pp : data shape : (850, 12)\u001b[0m\n",
      "\u001b[34msample data : \n",
      " [0 'user_173' 0.23750065072223228 3.7156362763819963 1.0 0.0 0.0 0.0 1.0\n",
      " 1.0 0.0 0.0]\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:18:52 +0000] \"POST /invocations HTTP/1.1\" 200 70646 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m2020-09-19T11:18:51.685:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Preprocess training data : s3_input_raw_train\n",
    "pp_transformer.transform(s3_input_raw_train, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + pp_transformer.latest_transform_job.job_name)\n",
    "pp_transformer.wait()\n",
    "s3_pp_train = pp_transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# batch preprocess test data : s3_input_raw_test\n",
    "pp_transformer.transform(s3_input_raw_test, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + pp_transformer.latest_transform_job.job_name)\n",
    "pp_transformer.wait()\n",
    "s3_pp_test = pp_transformer.output_path\n",
    "\"\"\"\n",
    "s3_pp_test = s3_pp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for transform job: sagemaker-scikit-learn-2020-09-19-11-19-16-956\n",
      ".............................\u001b[34m2020-09-19 11:23:50,770 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-19 11:23:50,772 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-19 11:23:50,773 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:50 [crit] 14#14: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:50 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-09-19 11:23:50,906 INFO - sagemaker-containers - Module pre_processing_script does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-09-19 11:23:50,906 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-09-19 11:23:50,906 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-09-19 11:23:50,906 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:50 [crit] 14#14: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:50 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:51 [crit] 14#14: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:51 [crit] 14#14: *7 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[35m2020-09-19 11:23:50,770 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2020-09-19 11:23:50,772 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2020-09-19 11:23:50,773 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:50 [crit] 14#14: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:50 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-09-19 11:23:50,906 INFO - sagemaker-containers - Module pre_processing_script does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2020-09-19 11:23:50,906 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2020-09-19 11:23:50,906 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2020-09-19 11:23:50,906 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:50 [crit] 14#14: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:50 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:51 [crit] 14#14: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:51 [crit] 14#14: *7 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:51 [crit] 14#14: *9 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:51 [crit] 14#14: *11 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pre-processing-script\n",
      "  Building wheel for pre-processing-script (setup.py): started\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:51 [crit] 14#14: *13 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:51 [crit] 14#14: *15 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\n",
      "  Building wheel for pre-processing-script (setup.py): finished with status 'done'\n",
      "  Created wheel for pre-processing-script: filename=pre_processing_script-1.0.0-py2.py3-none-any.whl size=10473 sha256=075d2a27f8e06d1a1b6caaad80277eb8962bf19cb402dc7c3fa4db1fb42dd0b8\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-5p5iotem/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built pre-processing-script\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:51 [crit] 14#14: *17 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:51 [crit] 14#14: *19 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pre-processing-script\u001b[0m\n",
      "\u001b[34mSuccessfully installed pre-processing-script-1.0.0\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:51 [crit] 14#14: *21 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:51 [crit] 14#14: *23 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:52 [crit] 14#14: *25 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:52 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:52 [crit] 14#14: *27 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:52 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:52 [crit] 14#14: *29 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:52 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:52 [crit] 14#14: *31 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:52 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/19 11:23:52 [crit] 14#14: *33 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:52 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:23:52 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:23:52 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:23:52 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:23:52 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:23:52 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:23:52 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[34m[2020-09-19 11:23:52 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[34m2020-09-19 11:23:53,275 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:53 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-09-19 11:23:53,719 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:51 [crit] 14#14: *9 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:51 [crit] 14#14: *11 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: pre-processing-script\n",
      "  Building wheel for pre-processing-script (setup.py): started\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:51 [crit] 14#14: *13 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:51 [crit] 14#14: *15 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\n",
      "  Building wheel for pre-processing-script (setup.py): finished with status 'done'\n",
      "  Created wheel for pre-processing-script: filename=pre_processing_script-1.0.0-py2.py3-none-any.whl size=10473 sha256=075d2a27f8e06d1a1b6caaad80277eb8962bf19cb402dc7c3fa4db1fb42dd0b8\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-5p5iotem/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[35mSuccessfully built pre-processing-script\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:51 [crit] 14#14: *17 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:51 [crit] 14#14: *19 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInstalling collected packages: pre-processing-script\u001b[0m\n",
      "\u001b[35mSuccessfully installed pre-processing-script-1.0.0\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:51 [crit] 14#14: *21 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:51 [crit] 14#14: *23 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:51 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:52 [crit] 14#14: *25 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:52 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:52 [crit] 14#14: *27 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:52 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:52 [crit] 14#14: *29 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:52 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:52 [crit] 14#14: *31 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:52 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/19 11:23:52 [crit] 14#14: *33 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:52 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2020-09-19 11:23:52 +0000] [33] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2020-09-19 11:23:52 +0000] [33] [INFO] Listening at: unix:/tmp/gunicorn.sock (33)\u001b[0m\n",
      "\u001b[35m[2020-09-19 11:23:52 +0000] [33] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-09-19 11:23:52 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-09-19 11:23:52 +0000] [37] [INFO] Booting worker with pid: 37\u001b[0m\n",
      "\u001b[35m[2020-09-19 11:23:52 +0000] [38] [INFO] Booting worker with pid: 38\u001b[0m\n",
      "\u001b[35m[2020-09-19 11:23:52 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[35m2020-09-19 11:23:53,275 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:53 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-09-19 11:23:53,719 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:54 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-09-19 11:23:54,156 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m======================================== input_fn ========================================\u001b[0m\n",
      "\u001b[34mThis pred/val data i.e unlabelled, not include col_to_predict\u001b[0m\n",
      "\u001b[34mdf.shape :  (131, 5)\u001b[0m\n",
      "\u001b[34m======================================== predict_fn ========================================\u001b[0m\n",
      "\u001b[34mbefore pp :  data shape : (131, 5)\u001b[0m\n",
      "\u001b[34minput data type : <class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[34mtest/pred job\u001b[0m\n",
      "\u001b[34monly contain the feature data\u001b[0m\n",
      "\u001b[34mafter pp : data shape : (131, 10)\u001b[0m\n",
      "\u001b[34msample data : \n",
      " [-1.69835544  0.08898475  0.          0.          1.          0.\n",
      "  1.          0.          1.          0.        ]\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [19/Sep/2020:11:23:54 +0000] \"POST /invocations HTTP/1.1\" 200 9396 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:54 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-09-19 11:23:54,156 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m======================================== input_fn ========================================\u001b[0m\n",
      "\u001b[35mThis pred/val data i.e unlabelled, not include col_to_predict\u001b[0m\n",
      "\u001b[35mdf.shape :  (131, 5)\u001b[0m\n",
      "\u001b[35m======================================== predict_fn ========================================\u001b[0m\n",
      "\u001b[35mbefore pp :  data shape : (131, 5)\u001b[0m\n",
      "\u001b[35minput data type : <class 'pandas.core.frame.DataFrame'>\u001b[0m\n",
      "\u001b[35mtest/pred job\u001b[0m\n",
      "\u001b[35monly contain the feature data\u001b[0m\n",
      "\u001b[35mafter pp : data shape : (131, 10)\u001b[0m\n",
      "\u001b[35msample data : \n",
      " [-1.69835544  0.08898475  0.          0.          1.          0.\n",
      "  1.          0.          1.          0.        ]\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [19/Sep/2020:11:23:54 +0000] \"POST /invocations HTTP/1.1\" 200 9396 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2020-09-19T11:23:54.137:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ns3_pp_val = None\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only useful for assessing the ml_model only endpoint\n",
    "\n",
    "# batch preprocess val data : s3_input_raw_val\n",
    "pp_transformer.transform(s3_input_raw_val, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + pp_transformer.latest_transform_job.job_name)\n",
    "pp_transformer.wait()\n",
    "s3_pp_val = pp_transformer.output_path\n",
    "\"\"\"\n",
    "s3_pp_val = None\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sklearn-pipeline/sklearn-pipeline-titanic/data_train/train_titanic_dataset.csv'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_raw_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-19-11-14-04-030',\n",
       " 's3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-19-11-14-04-030',\n",
       " 's3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-19-11-19-16-956')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_pp_train, s3_pp_test, s3_pp_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML model (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-120286446822\n",
      "sagemaker-scikit-learn-2020-09-19-11-14-04-030\n",
      "train_titanic_dataset.csv.out\n",
      "(850, 12) (850, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>user_615</td>\n",
       "      <td>-0.750181</td>\n",
       "      <td>-0.509231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>user_953</td>\n",
       "      <td>-0.592152</td>\n",
       "      <td>-0.523759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3    4    5    6    7    8    9    10   11\n",
       "76   0  user_615 -0.750181 -0.509231  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0\n",
       "80   1  user_953 -0.592152 -0.523759  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch data\n",
    "s3uri     = s3_pp_train\n",
    "file_name = '{}.out'.format(RAW_TRAIN_PATH.split(\"/\")[-1])\n",
    "s3_obj = get_csv_output_from_s3(s3uri, file_name)\n",
    "train_df_pp  = pd.read_csv(io.StringIO(s3_obj), sep=\",\", header=None)\n",
    "\n",
    "\"\"\"\n",
    "s3uri     = s3_pp_test\n",
    "file_name = '{}.out'.format(RAW_TEST_PATH.split(\"/\")[-1])\n",
    "s3_obj = get_csv_output_from_s3(s3uri, file_name)\n",
    "test_df_pp  = pd.read_csv(io.StringIO(s3_obj), sep=\",\", header=None)\n",
    "\"\"\"\n",
    "test_df_pp = train_df_pp.copy()\n",
    "\n",
    "\n",
    "train_df_pp.to_csv(path_or_buf=PP_TRAIN_PATH, index=False, header=None)\n",
    "test_df_pp.to_csv(path_or_buf=PP_TEST_PATH, index=False, header=None)\n",
    "#val_df_pp.to_csv(path_or_buf=PP_VAL_PATH, index=False, header=None)\n",
    "\n",
    "print(train_df_pp.shape, test_df_pp.shape)\n",
    "train_df_pp.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    526\n",
       "1    324\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_col = 0\n",
    "train_df_pp[predict_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/artifacts',\n",
       " '/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/pp_train',\n",
       " '/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/pp_train')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_train_data_local_dir = \"/\".join(PP_TRAIN_PATH.split(\"/\")[:-1])\n",
    "pp_test_data_local_dir = \"/\".join(PP_TRAIN_PATH.split(\"/\")[:-1])\n",
    "artifacts_local_dir  = ARTIFACTS_PATH\n",
    "\n",
    "artifacts_local_dir, pp_train_data_local_dir, pp_test_data_local_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (3.1.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (46.1.3.post20200330)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: seaborn in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.10.0)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seaborn) (3.1.3)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seaborn) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seaborn) (1.18.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.22.0->seaborn) (2019.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn) (46.1.3.post20200330)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=2.1.2->seaborn) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "extracting arguments\n",
      "loading train data\n",
      "args.train :  /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/pp_train/\n",
      "loading test data\n",
      "args.test :  /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/pp_train/\n",
      "\n",
      "building training and testing datasets\n",
      "!! below data print includes col_to_predict/col_primary_identifer !!\n",
      "\n",
      "!! WARNING !!\n",
      "col_to_predict: 0\n",
      "col_index_to_drop: [0, 1]\n",
      "training data shape :  (850, 12)\n",
      "train data head(1) : \n",
      "   0         1         2         3    4    5    6    7    8    9    10   11\n",
      "0   0  user_173  0.237501  3.715636  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
      "train : [0 1] : [526 324]\n",
      "test  : [0 1] : [526 324]\n",
      "model training started!!\n",
      "model training on num features :  10 \n",
      "\n",
      "accuracy  : 0.91\n",
      "precision : 0.91\n",
      "recall    : 0.89\n",
      "\n",
      "Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not-survived       0.90      0.95      0.93       526\n",
      "    survived       0.91      0.83      0.87       324\n",
      "\n",
      "    accuracy                           0.91       850\n",
      "   macro avg       0.91      0.89      0.90       850\n",
      "weighted avg       0.91      0.91      0.90       850\n",
      "\n",
      "model persisted at /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/artifacts/model.joblib\n"
     ]
    }
   ],
   "source": [
    "! python model_script.py --n-estimators 100 \\\n",
    "                         --min-samples-leaf 2 \\\n",
    "                         --model-dir '/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/artifacts/' \\\n",
    "                         --train '/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/pp_train/' \\\n",
    "                         --test '/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/pp_train/' \\\n",
    "                         --target '0' \\\n",
    "                         --col_index_to_drop '0, 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once local run is succesfull, train the container based model\n",
    "# uncomment install('matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_MODEL_SCRIPT_NAME = \"model_script.py\"\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = '0.23-1'\n",
    "ml_estimator = SKLearn(\n",
    "                    entry_point=ML_MODEL_SCRIPT_NAME,\n",
    "                    role = get_execution_role(),\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c5.xlarge',\n",
    "                    framework_version=FRAMEWORK_VERSION,\n",
    "                    base_job_name='rf-scikit',\n",
    "                    metric_definitions=[\n",
    "                                        {'Name': 'median-AE',\n",
    "                                         'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}\n",
    "                                        ],\n",
    "                    hyperparameters = {'n-estimators': 100,\n",
    "                                       'min-samples-leaf': 2,\n",
    "                                       'target': '0',\n",
    "                                       'col_index_to_drop': '0, 1'\n",
    "                                      }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-19 11:24:37 Starting - Starting the training job...\n",
      "2020-09-19 11:24:40 Starting - Launching requested ML instances.........\n",
      "2020-09-19 11:26:10 Starting - Preparing the instances for training...\n",
      "2020-09-19 11:27:02 Downloading - Downloading input data\n",
      "2020-09-19 11:27:02 Training - Downloading the training image...\n",
      "2020-09-19 11:27:32 Training - Training image download completed. Training in progress..\u001b[34m2020-09-19 11:27:33,018 sagemaker-training-toolkit INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-09-19 11:27:33,019 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-19 11:27:33,028 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-09-19 11:27:33,280 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-19 11:27:33,498 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-19 11:27:33,507 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-19 11:27:33,517 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"n-estimators\": 100,\n",
      "        \"min-samples-leaf\": 2,\n",
      "        \"col_index_to_drop\": \"0, 1\",\n",
      "        \"target\": \"0\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rf-scikit-2020-09-19-11-24-37-531\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-120286446822/rf-scikit-2020-09-19-11-24-37-531/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"model_script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"model_script.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"col_index_to_drop\":\"0, 1\",\"min-samples-leaf\":2,\"n-estimators\":100,\"target\":\"0\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=model_script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=model_script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-120286446822/rf-scikit-2020-09-19-11-24-37-531/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"col_index_to_drop\":\"0, 1\",\"min-samples-leaf\":2,\"n-estimators\":100,\"target\":\"0\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rf-scikit-2020-09-19-11-24-37-531\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-120286446822/rf-scikit-2020-09-19-11-24-37-531/source/sourcedir.tar.gz\",\"module_name\":\"model_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"model_script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--col_index_to_drop\",\"0, 1\",\"--min-samples-leaf\",\"2\",\"--n-estimators\",\"100\",\"--target\",\"0\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_N-ESTIMATORS=100\u001b[0m\n",
      "\u001b[34mSM_HP_MIN-SAMPLES-LEAF=2\u001b[0m\n",
      "\u001b[34mSM_HP_COL_INDEX_TO_DROP=0, 1\u001b[0m\n",
      "\u001b[34mSM_HP_TARGET=0\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python model_script.py --col_index_to_drop 0, 1 --min-samples-leaf 2 --n-estimators 100 --target 0\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mCollecting matplotlib\n",
      "  Downloading matplotlib-3.3.2-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34mCollecting certifi>=2020.06.20\n",
      "  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (88 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.7/site-packages (from matplotlib) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.7/site-packages (from matplotlib) (1.18.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /miniconda3/lib/python3.7/site-packages (from matplotlib) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /miniconda3/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyparsing, certifi, kiwisolver, cycler, matplotlib\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.4.5.1\n",
      "    Uninstalling certifi-2020.4.5.1:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled certifi-2020.4.5.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed certifi-2020.6.20 cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.3.2 pyparsing-2.4.7\u001b[0m\n",
      "\u001b[34mCollecting seaborn\n",
      "  Downloading seaborn-0.11.0-py3-none-any.whl (283 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.7/site-packages (from seaborn) (1.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib>=2.2 in /miniconda3/lib/python3.7/site-packages (from seaborn) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.7/site-packages (from seaborn) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.7/site-packages (from seaborn) (1.18.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2020.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.6.1 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (7.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2020.06.20 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2020.6.20)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /miniconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=0.23->seaborn) (1.15.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: seaborn\u001b[0m\n",
      "\u001b[34mSuccessfully installed seaborn-0.11.0\u001b[0m\n",
      "\u001b[34mextracting arguments\u001b[0m\n",
      "\u001b[34mloading train data\u001b[0m\n",
      "\u001b[34margs.train :  /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mloading test data\u001b[0m\n",
      "\u001b[34margs.test :  /opt/ml/input/data/test\n",
      "\u001b[0m\n",
      "\u001b[34mbuilding training and testing datasets\u001b[0m\n",
      "\u001b[34m!! below data print includes col_to_predict/col_primary_identifer !!\n",
      "\u001b[0m\n",
      "\u001b[34m!! WARNING !!\u001b[0m\n",
      "\u001b[34mcol_to_predict: 0\u001b[0m\n",
      "\u001b[34mcol_index_to_drop: [0, 1]\u001b[0m\n",
      "\u001b[34mtraining data shape :  (850, 12)\u001b[0m\n",
      "\u001b[34mtrain data head(1) : \n",
      "   0         1         2         3    4    5    6    7    8    9    10   11\u001b[0m\n",
      "\u001b[34m0   0  user_173  0.237501  3.715636  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\u001b[0m\n",
      "\u001b[34mtrain : [0 1] : [526 324]\u001b[0m\n",
      "\u001b[34mtest  : [0 1] : [526 324]\u001b[0m\n",
      "\u001b[34mmodel training started!!\u001b[0m\n",
      "\u001b[34mmodel training on num features :  10 \n",
      "\u001b[0m\n",
      "\u001b[34maccuracy  : 0.91\u001b[0m\n",
      "\u001b[34mprecision : 0.91\u001b[0m\n",
      "\u001b[34mrecall    : 0.89\n",
      "\u001b[0m\n",
      "\u001b[34mClassification report : \n",
      "              precision    recall  f1-score   support\n",
      "\u001b[0m\n",
      "\u001b[34mnot-survived       0.90      0.96      0.93       526\n",
      "    survived       0.92      0.83      0.87       324\n",
      "\n",
      "    accuracy                           0.91       850\n",
      "   macro avg       0.91      0.89      0.90       850\u001b[0m\n",
      "\u001b[34mweighted avg       0.91      0.91      0.91       850\n",
      "\u001b[0m\n",
      "\u001b[34mmodel persisted at /opt/ml/model/model.joblib\u001b[0m\n",
      "\u001b[34m2020-09-19 11:27:39,949 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-09-19 11:27:50 Uploading - Uploading generated training model\n",
      "2020-09-19 11:27:50 Completed - Training job completed\n",
      "Training seconds: 65\n",
      "Billable seconds: 65\n"
     ]
    }
   ],
   "source": [
    "# TRAIN the model\n",
    "ml_estimator.fit({'train':s3_pp_train, 'test': s3_pp_test}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# step_1 : get models\n",
    "pp_transformer_model = sklearn_preprocessor.create_model()\n",
    "ml_estimator_model   = ml_estimator.create_model()\n",
    "\n",
    "# step_2 : set-up pipeline\n",
    "model_name    = 'sip-clf-' + timestamp_prefix\n",
    "endpoint_name = 'sip-clf-ep-' + timestamp_prefix\n",
    "ml_pipeline_model = PipelineModel(\n",
    "                                    name=model_name, \n",
    "                                    role=role, \n",
    "                                    models=[\n",
    "                                            pp_transformer_model, \n",
    "                                            ml_estimator_model\n",
    "                                            ]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# batch prediction job\n",
    "\n",
    "\"\"\"\n",
    "ml_pipeline_tf = ml_pipeline_model.transformer(\n",
    "                                            instance_count=1, \n",
    "                                            instance_type='ml.m5.xlarge',\n",
    "                                            assemble_with = 'Line',\n",
    "                                            accept = 'text/csv')\n",
    "\n",
    "# input : s3_input_raw_val (raw input data)\n",
    "ml_pipeline_tf.transform(s3_input_raw_val, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + ml_pipeline_tf.latest_transform_job.job_name)\n",
    "ml_pipeline_tf.wait()\n",
    "s3_pred_val = ml_pipeline_tf.output_path\n",
    "s3_pred_val\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deploy pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sip-clf-2020-09-19-11-28-20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "#sm_model.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge', endpoint_name=endpoint_name)\n",
    "ml_pipeline_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict from pipeline endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sip-clf-ep-2020-09-19-11-28-20'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>user_1132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>user_245</td>\n",
       "      <td>33.0</td>\n",
       "      <td>86.5000</td>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0          1     2        3  4       5    6\n",
       "0  0  user_1132   NaN   7.8958  S    male  3.0\n",
       "1  1   user_245  33.0  86.5000  S  female  1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test_data = pd.read_csv(filepath_or_buffer=RAW_TEST_PATH, header=None)\n",
    "temp_test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 'user_1132', nan, 7.8958, 'S', 'male', 3.0],\n",
       "       [1, 'user_245', 33.0, 86.5, 'S', 'female', 1.0],\n",
       "       [0, 'user_1298', 36.0, 9.5, 'S', 'male', 3.0],\n",
       "       [0, 'user_426', 30.0, 13.0, 'S', 'male', 2.0]], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test_data.head(4).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'33.0, 86.5, S, female, 1.0\\n30.0, 13.0, S, male, 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[1, 1]'\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "\n",
    "\n",
    "#payload = '33.0, 86.5, S, female, 1.0' # user_245, 1, pred=1\n",
    "#payload = '30.0, 13.0, S, male, 2' # user_426, 0, pred=1\n",
    "#payload = ', 7.89, S, male, 3.0' # user_1132, 0, pred=0\n",
    "payload = '33.0, 86.5, S, female, 1.0\\n30.0, 13.0, S, male, 2' #user_245,user_426 ;1,1; '[1, 1]'\n",
    "\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=csv_serializer,\n",
    "    content_type=CONTENT_TYPE_CSV,\n",
    "    accept=CONTENT_TYPE_JSON)\n",
    "\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict : only using model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy only the - ml model\n",
    "ml_predictor = ml_estimator.deploy(instance_type='ml.m4.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, file_name):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    prefix = parsed_url.path[1:]\n",
    "    s3 = boto3.resource('s3')\n",
    "    print(bucket_name)\n",
    "    print(prefix)\n",
    "    print(file_name)\n",
    "    obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n",
    "    return obj.get()[\"Body\"].read().decode('utf-8')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path       = preprocessed_val\n",
    "batch_file = 'abalone_val.csv' # imp\n",
    "output = get_csv_output_from_s3(path, '{}.out'.format(batch_file))\n",
    "validate_df = pd.read_csv(io.StringIO(output), sep=\",\", header=None)\n",
    "print(validate_df.shape)\n",
    "validate_df.sample(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `data` is a NumPy array or a Python list.\n",
    "# `response` is a NumPy array.\n",
    "\n",
    "#payload = validate_df.drop(columns=[0]).values\n",
    "payload = validate_df.values\n",
    "\n",
    "response = ml_predictor.predict(payload)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint <a class=\"anchor\" id=\"delete_endpoint\"></a>\n",
    "Once we are finished with the endpoint, we clean up the resources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
