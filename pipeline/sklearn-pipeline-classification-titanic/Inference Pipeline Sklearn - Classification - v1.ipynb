{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Pipeline with Scikit-learn and Linear Learner\n",
    "\n",
    "1. fit/train a sklearn pre-processor\n",
    "   \n",
    "   it will perform preprocessing of numeric cat cols\n",
    "   \n",
    "** numeric : imputation, scaling\n",
    "\n",
    "** categoric : imputation, one-hot-encoding\n",
    "   \n",
    "** also perform batch transformation of train/test data to be used for ml_model training\n",
    "   \n",
    "   \n",
    "2. train sklearn ml model (RF regressor)\n",
    "\n",
    "3. build up inference-ml-pipeline\n",
    "    raw_data --> [preprocessing ==> ml_model] --> prediction\n",
    "    \n",
    "4. deploy inference-ml-pipeline as an endpoint\n",
    "\n",
    "5. prediction using the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, file_name):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    prefix = parsed_url.path[1:]\n",
    "    s3 = boto3.resource('s3')\n",
    "    print(bucket_name)\n",
    "    print(prefix)\n",
    "    print(file_name)\n",
    "    obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n",
    "    return obj.get()[\"Body\"].read().decode('utf-8')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sklearn-pipeline', 'sklearn-pipeline-titanic')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()\n",
    "\n",
    "# S3 prefix\n",
    "S3_BUCKET = \"sklearn-pipeline\"\n",
    "S3_PREFIX = 'sklearn-pipeline-titanic'\n",
    "\n",
    "S3_BUCKET, S3_PREFIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_predict = \"survived\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "path = \"/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/raw_data\"\n",
    "\n",
    "file_name = 'train.csv'\n",
    "X1 = pd.read_csv(os.path.join(path, file_name))\n",
    "\n",
    "file_name = 'test.csv'\n",
    "#X2 = pd.read_csv(os.path.join(path, file_name))\n",
    "X2 = pd.DataFrame()\n",
    "\n",
    "X = pd.concat(objs=[X1, X2]).reset_index(drop=True)\n",
    "\n",
    "file_name = \"titanic_dataset.csv\"\n",
    "#X.to_csv(path_or_buf=os.path.join(path, file_name), index=False)\n",
    "\n",
    "print(X.shape)\n",
    "X.head(2)\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 100\n",
    "\n",
    "RAW_FILE       = 'titanic_dataset.csv'\n",
    "WORK_DIRECTORY = '/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir'\n",
    "\n",
    "RAW_FILE_PATH  = \"{}/raw_data/{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "RAW_TRAIN_PATH = \"{}/train/train_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "RAW_TEST_PATH  = \"{}/test/test_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "RAW_VAL_PATH   = \"{}/val/val_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "\n",
    "PP_TRAIN_PATH = \"{}/pp_train/train_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "PP_TEST_PATH  = \"{}/pp_test/test_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "PP_VAL_PATH   = \"{}/pp_val/val_{}\".format(WORK_DIRECTORY, RAW_FILE)\n",
    "\n",
    "ARTIFACTS_PATH = \"{}/artifacts\".format(WORK_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data: (1309, 14), train: (850, 14), test: (328, 14), val: (131, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass                            name     sex      age  sibsp  parch  \\\n",
       "0     1.0   Allen, Miss. Elisabeth Walton  female  29.0000    0.0    0.0   \n",
       "1     1.0  Allison, Master. Hudson Trevor    male   0.9167    1.0    2.0   \n",
       "\n",
       "   ticket      fare    cabin embarked boat  body  \\\n",
       "0   24160  211.3375       B5        S    2   NaN   \n",
       "1  113781  151.5500  C22 C26        S   11   NaN   \n",
       "\n",
       "                         home.dest survived  \n",
       "0                     St Louis, MO        1  \n",
       "1  Montreal, PQ / Chesterville, ON        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "X[col_to_predict] = y\n",
    "\n",
    "# train, test, val : 65%, 25%, 10%\n",
    "train_data, test_data, val_data = np.split(X.sample(frac=1, random_state=SEED), [int(.65*len(X)), int(.9*len(X))])\n",
    "val_data = val_data.drop(columns=col_to_predict)\n",
    "\n",
    "# save the data\n",
    "train_data.to_csv(path_or_buf=RAW_TRAIN_PATH, index=False)\n",
    "test_data.to_csv(path_or_buf=RAW_TEST_PATH, index=False)\n",
    "val_data.to_csv(path_or_buf=RAW_VAL_PATH, index=False)\n",
    "\n",
    "print(\"raw_data: {}, train: {}, test: {}, val: {}\".format(X.shape, train_data.shape, test_data.shape, val_data.shape))\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    526\n",
       " 1    324\n",
       " Name: survived, dtype: int64,\n",
       " 0    202\n",
       " 1    126\n",
       " Name: survived, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[col_to_predict].value_counts(), test_data[col_to_predict].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Keeping, Mr. Edwin</td>\n",
       "      <td>male</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113503</td>\n",
       "      <td>211.5</td>\n",
       "      <td>C132</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>45.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass                name   sex   age  sibsp  parch  ticket   fare  \\\n",
       "173     1.0  Keeping, Mr. Edwin  male  32.5    0.0    0.0  113503  211.5   \n",
       "\n",
       "    cabin embarked  boat  body home.dest survived  \n",
       "173  C132        C  None  45.0      None        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://sklearn-pipeline/sklearn-pipeline-titanic/data_train/train_titanic_dataset.csv',\n",
       " 's3://sklearn-pipeline/sklearn-pipeline-titanic/data_test/test_titanic_dataset.csv',\n",
       " 's3://sklearn-pipeline/sklearn-pipeline-titanic/data_val/val_titanic_dataset.csv')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_raw_train = sagemaker_session.upload_data(\n",
    "    path=RAW_TRAIN_PATH, \n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix='{}/{}'.format(S3_PREFIX, 'data_train'))\n",
    "\n",
    "s3_input_raw_test = sagemaker_session.upload_data(\n",
    "    path=RAW_TEST_PATH, \n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix='{}/{}'.format(S3_PREFIX, 'data_test'))\n",
    "\n",
    "s3_input_raw_val = sagemaker_session.upload_data(\n",
    "    path=RAW_VAL_PATH, \n",
    "    bucket=S3_BUCKET,\n",
    "    key_prefix='{}/{}'.format(S3_PREFIX, 'data_val'))\n",
    "\n",
    "s3_input_raw_train, s3_input_raw_test, s3_input_raw_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PP_SCRIPT_NAME = 'pre_processing_script.py'\n",
    "\n",
    "# preprocessor setup\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "sklearn_preprocessor = SKLearn(\n",
    "                            entry_point=PP_SCRIPT_NAME,\n",
    "                            role=role,\n",
    "                            framework_version=FRAMEWORK_VERSION,\n",
    "                            train_instance_type=\"ml.c4.xlarge\",\n",
    "                            sagemaker_session=sagemaker_session\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import set_config\n",
    "#set_config(display='diagram')\n",
    "#preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================_sklearn-pre-processor_========================================\n",
      "extracting arguments\n",
      "data loading completed:\n",
      "data shape :  (850, 6)\n",
      "to_predict_col : [0 1] : [526 324]\n",
      "\n",
      "before pp : data shape :  (850, 5)\n",
      "sample data : \n",
      " [[32.5 211.5 'C' 'male' 1]] \n",
      "\n",
      "[ColumnTransformer] ........... (1 of 2) Processing num, total=   0.0s\n",
      "[ColumnTransformer] ........... (2 of 2) Processing cat, total=   0.0s\n",
      "\n",
      "after pp : data shape :  (850, 10)\n",
      "sample data : \n",
      " [0.23750065 3.71563628 1.         0.         0.         0.\n",
      " 1.         1.         0.         0.        ]\n",
      "\n",
      "column name of pp data:\n",
      "num cols : 10\n",
      "['age' 'fare' 'x0_C' 'x0_Q' 'x0_S' 'x1_female' 'x1_male' 'x2_1' 'x2_2'\n",
      " 'x2_3']\n",
      "\n",
      "\n",
      "saved model at :  /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/artifacts/model.joblib\n"
     ]
    }
   ],
   "source": [
    "train_data_local_dir = \"/\".join(RAW_TRAIN_PATH.split(\"/\")[:-1])\n",
    "artifacts_local_dir  = ARTIFACTS_PATH\n",
    "artifacts_local_dir, train_data_local_dir\n",
    "\n",
    "! python pre_processing_script.py --output-data-dir /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/artifacts/ \\\n",
    "                                  --model-dir /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/artifacts/ \\\n",
    "                                  --train /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once local run is succesfull, train the container based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-18 19:35:55 Starting - Starting the training job...\n",
      "2020-09-18 19:35:57 Starting - Launching requested ML instances......\n",
      "2020-09-18 19:37:12 Starting - Preparing the instances for training......\n",
      "2020-09-18 19:38:24 Downloading - Downloading input data\n",
      "2020-09-18 19:38:24 Training - Downloading the training image......\n",
      "2020-09-18 19:39:23 Training - Training image download completed. Training in progress..\u001b[34m2020-09-18 19:39:23,774 sagemaker-training-toolkit INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-09-18 19:39:23,776 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-18 19:39:23,786 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-09-18 19:39:24,142 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-18 19:39:24,154 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-18 19:39:24,166 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-18 19:39:24,177 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2020-09-18-19-35-54-623\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-18-19-35-54-623/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"pre_processing_script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pre_processing_script.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=pre_processing_script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=pre_processing_script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-18-19-35-54-623/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-09-18-19-35-54-623\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-18-19-35-54-623/source/sourcedir.tar.gz\",\"module_name\":\"pre_processing_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"pre_processing_script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python pre_processing_script.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m========================================_sklearn-pre-processor_========================================\u001b[0m\n",
      "\u001b[34mextracting arguments\u001b[0m\n",
      "\u001b[34mdata loading completed:\u001b[0m\n",
      "\u001b[34mdata shape :  (850, 6)\u001b[0m\n",
      "\u001b[34mto_predict_col : [0 1] : [526 324]\n",
      "\u001b[0m\n",
      "\u001b[34mbefore pp : data shape :  (850, 5)\u001b[0m\n",
      "\u001b[34msample data : \n",
      " [[32.5 211.5 'C' 'male' 1]] \n",
      "\u001b[0m\n",
      "\u001b[34m[ColumnTransformer] ........... (1 of 2) Processing num, total=   0.0s\u001b[0m\n",
      "\u001b[34m[ColumnTransformer] ........... (2 of 2) Processing cat, total=   0.0s\n",
      "\u001b[0m\n",
      "\u001b[34mafter pp : data shape :  (850, 10)\u001b[0m\n",
      "\u001b[34msample data : \n",
      " [0.23750065 3.71563628 1.         0.         0.         0.\n",
      " 1.         1.         0.         0.        ]\n",
      "\u001b[0m\n",
      "\u001b[34mcolumn name of pp data:\u001b[0m\n",
      "\u001b[34mnum cols : 10\u001b[0m\n",
      "\u001b[34m['age' 'fare' 'x0_C' 'x0_Q' 'x0_S' 'x1_female' 'x1_male' 'x2_1' 'x2_2'\n",
      " 'x2_3']\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34msaved model at :  /opt/ml/model/model.joblib\u001b[0m\n",
      "\u001b[34m2020-09-18 19:39:25,831 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-09-18 19:39:35 Uploading - Uploading generated training model\n",
      "2020-09-18 19:39:35 Completed - Training job completed\n",
      "Training seconds: 88\n",
      "Billable seconds: 88\n"
     ]
    }
   ],
   "source": [
    "sklearn_preprocessor.fit({'train': s3_input_raw_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### batch transform the raw data to train/test data\n",
    "required for training the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "raw data + label : 9\n",
    "features + label : 12\n",
    "\n",
    "raw data : 8\n",
    "features : 11 (this is pred model required data)\n",
    "\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# Define a SKLearn Transformer from the trained SKLearn Estimator\n",
    "pp_transformer = sklearn_preprocessor.transformer(\n",
    "                                                    instance_count=1, \n",
    "                                                    instance_type='ml.m5.xlarge',\n",
    "                                                    assemble_with = 'Line',\n",
    "                                                    accept = 'text/csv'\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for transform job: sagemaker-scikit-learn-2020-09-18-19-42-22-094\n",
      "..............................\n",
      "\u001b[34m2020-09-18 19:47:10,069 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-18 19:47:10,072 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-18 19:47:10,072 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[35m2020-09-18 19:47:10,069 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2020-09-18 19:47:10,072 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2020-09-18 19:47:10,072 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\n",
      "\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\n",
      "\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\n",
      "\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:10 [crit] 13#13: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-09-18 19:47:10,207 INFO - sagemaker-containers - Module pre_processing_script does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-09-18 19:47:10,207 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-09-18 19:47:10,207 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-09-18 19:47:10,207 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:10 [crit] 13#13: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:10 [crit] 13#13: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:10 [crit] 13#13: *7 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:10 [crit] 13#13: *9 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:10 [crit] 13#13: *11 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "\n",
      "    keepalive_timeout 3;\n",
      "\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:10 [crit] 13#13: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-09-18 19:47:10,207 INFO - sagemaker-containers - Module pre_processing_script does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2020-09-18 19:47:10,207 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2020-09-18 19:47:10,207 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2020-09-18 19:47:10,207 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:10 [crit] 13#13: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:10 [crit] 13#13: *5 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:10 [crit] 13#13: *7 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:10 [crit] 13#13: *9 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:10 [crit] 13#13: *11 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pre-processing-script\n",
      "  Building wheel for pre-processing-script (setup.py): started\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:10 [crit] 13#13: *13 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:10 [crit] 13#13: *15 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:10 [crit] 13#13: *17 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\n",
      "  Building wheel for pre-processing-script (setup.py): finished with status 'done'\n",
      "  Created wheel for pre-processing-script: filename=pre_processing_script-1.0.0-py2.py3-none-any.whl size=9970 sha256=b730bdcf22631154362220661285f806bff7737c7202e4a90b136357e2497144\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-cn5hpisw/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built pre-processing-script\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:11 [crit] 13#13: *19 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:11 [crit] 13#13: *21 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pre-processing-script\u001b[0m\n",
      "\u001b[34mSuccessfully installed pre-processing-script-1.0.0\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:11 [crit] 13#13: *23 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:11 [crit] 13#13: *25 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: pre-processing-script\n",
      "  Building wheel for pre-processing-script (setup.py): started\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:10 [crit] 13#13: *13 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:10 [crit] 13#13: *15 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:10 [crit] 13#13: *17 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:10 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\n",
      "  Building wheel for pre-processing-script (setup.py): finished with status 'done'\n",
      "  Created wheel for pre-processing-script: filename=pre_processing_script-1.0.0-py2.py3-none-any.whl size=9970 sha256=b730bdcf22631154362220661285f806bff7737c7202e4a90b136357e2497144\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-cn5hpisw/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[35mSuccessfully built pre-processing-script\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:11 [crit] 13#13: *19 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:11 [crit] 13#13: *21 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInstalling collected packages: pre-processing-script\u001b[0m\n",
      "\u001b[35mSuccessfully installed pre-processing-script-1.0.0\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:11 [crit] 13#13: *23 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:11 [crit] 13#13: *25 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:11 [crit] 13#13: *27 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:11 [crit] 13#13: *29 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:11 [crit] 13#13: *31 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:11 [crit] 13#13: *33 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m2020/09/18 19:47:11 [crit] 13#13: *35 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-09-18 19:47:11 +0000] [32] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2020-09-18 19:47:11 +0000] [32] [INFO] Listening at: unix:/tmp/gunicorn.sock (32)\u001b[0m\n",
      "\u001b[34m[2020-09-18 19:47:11 +0000] [32] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-09-18 19:47:11 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[2020-09-18 19:47:11 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[34m[2020-09-18 19:47:12 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2020-09-18 19:47:12 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:11 [crit] 13#13: *27 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:11 [crit] 13#13: *29 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:11 [crit] 13#13: *31 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:11 [crit] 13#13: *33 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m2020/09/18 19:47:11 [crit] 13#13: *35 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:11 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2020-09-18 19:47:11 +0000] [32] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2020-09-18 19:47:11 +0000] [32] [INFO] Listening at: unix:/tmp/gunicorn.sock (32)\u001b[0m\n",
      "\u001b[35m[2020-09-18 19:47:11 +0000] [32] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-09-18 19:47:11 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[35m[2020-09-18 19:47:11 +0000] [36] [INFO] Booting worker with pid: 36\u001b[0m\n",
      "\u001b[35m[2020-09-18 19:47:12 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2020-09-18 19:47:12 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m2020-09-18 19:47:12,648 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:13 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-09-18 19:47:13,147 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2020-09-18 19:47:12,648 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:13 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-09-18 19:47:13,147 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:13 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2020-09-18 19:47:13,605 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m======================================== input_fn ========================================\u001b[0m\n",
      "\u001b[34mdf.shape :  (850, 14)\u001b[0m\n",
      "\u001b[34mdf.head(1):\n",
      "    pclass                name   sex   age  ...  boat  body home.dest  survived\u001b[0m\n",
      "\u001b[34m0     1.0  Keeping, Mr. Edwin  male  32.5  ...   NaN  45.0       NaN         0\n",
      "\u001b[0m\n",
      "\u001b[34m[1 rows x 14 columns]\u001b[0m\n",
      "\u001b[34m======================================== predict_fn ========================================\u001b[0m\n",
      "\u001b[34mbefore pp :  data shape : \u001b[0m\n",
      "\u001b[34mtraining job\u001b[0m\n",
      "\u001b[34mafter pp : data shape : (850, 11)\u001b[0m\n",
      "\u001b[34msample data : \n",
      " [0.         0.23750065 3.71563628 1.         0.         0.\n",
      " 0.         1.         1.         0.         0.        ]\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [18/Sep/2020:19:47:14 +0000] \"POST /invocations HTTP/1.1\" 200 64550 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:13 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2020-09-18 19:47:13,605 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m======================================== input_fn ========================================\u001b[0m\n",
      "\u001b[35mdf.shape :  (850, 14)\u001b[0m\n",
      "\u001b[35mdf.head(1):\n",
      "    pclass                name   sex   age  ...  boat  body home.dest  survived\u001b[0m\n",
      "\u001b[35m0     1.0  Keeping, Mr. Edwin  male  32.5  ...   NaN  45.0       NaN         0\n",
      "\u001b[0m\n",
      "\u001b[35m[1 rows x 14 columns]\u001b[0m\n",
      "\u001b[35m======================================== predict_fn ========================================\u001b[0m\n",
      "\u001b[35mbefore pp :  data shape : \u001b[0m\n",
      "\u001b[35mtraining job\u001b[0m\n",
      "\u001b[35mafter pp : data shape : (850, 11)\u001b[0m\n",
      "\u001b[35msample data : \n",
      " [0.         0.23750065 3.71563628 1.         0.         0.\n",
      " 0.         1.         1.         0.         0.        ]\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [18/Sep/2020:19:47:14 +0000] \"POST /invocations HTTP/1.1\" 200 64550 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2020-09-18T19:47:13.584:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Preprocess training data : s3_input_raw_train\n",
    "pp_transformer.transform(s3_input_raw_train, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + pp_transformer.latest_transform_job.job_name)\n",
    "pp_transformer.wait()\n",
    "s3_pp_train = pp_transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# batch preprocess test data : s3_input_raw_test\n",
    "pp_transformer.transform(s3_input_raw_test, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + pp_transformer.latest_transform_job.job_name)\n",
    "pp_transformer.wait()\n",
    "s3_pp_test = pp_transformer.output_path\n",
    "\"\"\"\n",
    "s3_pp_test = s3_pp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only useful to assessing the ml_model only endpoint\n",
    "\"\"\"\n",
    "# batch preprocess val data : s3_input_raw_val\n",
    "pp_transformer.transform(s3_input_raw_val, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + pp_transformer.latest_transform_job.job_name)\n",
    "pp_transformer.wait()\n",
    "s3_pp_val = pp_transformer.output_path\n",
    "\"\"\"\n",
    "s3_pp_val = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sklearn-pipeline/sklearn-pipeline-titanic/data_train/train_titanic_dataset.csv'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_raw_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('s3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-18-19-42-22-094',\n",
       " 's3://sagemaker-us-east-1-120286446822/sagemaker-scikit-learn-2020-09-18-19-42-22-094',\n",
       " None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_pp_train, s3_pp_test, s3_pp_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML model (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_MODEL_SCRIPT_NAME = \"model_script.py\"\n",
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = '0.23-1'\n",
    "ml_estimator = SKLearn(\n",
    "                    entry_point=ML_MODEL_SCRIPT_NAME,\n",
    "                    role = get_execution_role(),\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c5.xlarge',\n",
    "                    framework_version=FRAMEWORK_VERSION,\n",
    "                    base_job_name='rf-scikit',\n",
    "                    metric_definitions=[\n",
    "                                        {'Name': 'median-AE',\n",
    "                                         'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}\n",
    "                                        ],\n",
    "                    hyperparameters = {'n-estimators': 100,\n",
    "                                       'min-samples-leaf': 2,\n",
    "                                       'features': 'NA',\n",
    "                                       'target': 'NA'\n",
    "                                      }\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-120286446822\n",
      "sagemaker-scikit-learn-2020-09-18-19-42-22-094\n",
      "train_titanic_dataset.csv.out\n",
      "(850, 11) (850, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830110</td>\n",
       "      <td>-0.098402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.750181</td>\n",
       "      <td>-0.510700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2    3    4    5    6    7    8    9    10\n",
       "9    0.0  0.830110 -0.098402  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
       "438  0.0 -0.750181 -0.510700  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch data\n",
    "s3uri     = s3_pp_train\n",
    "file_name = '{}.out'.format(RAW_TRAIN_PATH.split(\"/\")[-1])\n",
    "s3_obj = get_csv_output_from_s3(s3uri, file_name)\n",
    "train_df_pp  = pd.read_csv(io.StringIO(s3_obj), sep=\",\", header=None)\n",
    "\n",
    "\"\"\"\n",
    "s3uri     = s3_pp_test\n",
    "file_name = '{}.out'.format(RAW_TEST_PATH.split(\"/\")[-1])\n",
    "s3_obj = get_csv_output_from_s3(s3uri, file_name)\n",
    "test_df_pp  = pd.read_csv(io.StringIO(s3_obj), sep=\",\", header=None)\n",
    "\"\"\"\n",
    "test_df_pp = train_df_pp.copy()\n",
    "\n",
    "\n",
    "train_df_pp.to_csv(path_or_buf=PP_TRAIN_PATH, index=False, header=None)\n",
    "test_df_pp.to_csv(path_or_buf=PP_TEST_PATH, index=False, header=None)\n",
    "#val_df_pp.to_csv(path_or_buf=PP_VAL_PATH, index=False, header=None)\n",
    "\n",
    "print(train_df_pp.shape, test_df_pp.shape)\n",
    "train_df_pp.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    526\n",
       "1.0    324\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_col = 0\n",
    "train_df_pp[predict_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/artifacts',\n",
       " '/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/pp_train',\n",
       " '/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/pp_train')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_train_data_local_dir = \"/\".join(PP_TRAIN_PATH.split(\"/\")[:-1])\n",
    "pp_test_data_local_dir = \"/\".join(PP_TRAIN_PATH.split(\"/\")[:-1])\n",
    "artifacts_local_dir  = ARTIFACTS_PATH\n",
    "\n",
    "artifacts_local_dir, pp_train_data_local_dir, pp_test_data_local_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (46.1.3.post20200330)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: seaborn in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.10.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seaborn) (1.18.1)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seaborn) (1.0.5)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from seaborn) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.22.0->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.22.0->seaborn) (2019.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas>=0.22.0->seaborn) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn) (46.1.3.post20200330)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "extracting arguments\n",
      "loading train data\n",
      "args.train :  /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/pp_train/\n",
      "loading test data\n",
      "args.test :  /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/pp_train/\n",
      "\n",
      "building training and testing datasets\n",
      "!! below data print includes col_to_predict !!\n",
      "training data shape :  (850, 11)\n",
      "train data head(1) : \n",
      "    0         1         2    3    4    5    6    7    8    9    10\n",
      "0  0.0  0.237501  3.715636  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
      "\n",
      "!! WARNING !!\n",
      "0th index column is assumed as : col_to_predict\n",
      "\n",
      "columns :  [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "col_to_predict : 0, arg_type : <class 'numpy.int64'>\n",
      "train : [0. 1.] : [526 324]\n",
      "test  : [0. 1.] : [526 324]\n",
      "model training started!!\n",
      "model training on num features :  10 \n",
      "\n",
      "accuracy  : 0.91\n",
      "precision : 0.91\n",
      "recall    : 0.89\n",
      "\n",
      "Classification report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "not-survived       0.90      0.96      0.93       526\n",
      "    survived       0.92      0.82      0.87       324\n",
      "\n",
      "    accuracy                           0.91       850\n",
      "   macro avg       0.91      0.89      0.90       850\n",
      "weighted avg       0.91      0.91      0.91       850\n",
      "\n",
      "model persisted at /home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/artifacts/model.joblib\n"
     ]
    }
   ],
   "source": [
    "! python model_script.py --n-estimators 100 \\\n",
    "                         --min-samples-leaf 2 \\\n",
    "                         --model-dir '/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/artifacts/' \\\n",
    "                         --train '/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/pp_train/' \\\n",
    "                         --test '/home/ec2-user/SageMaker/aws-ml/pipeline/sklearn-pipeline-classification-titanic/data_dir/pp_train/' \\\n",
    "                         --target 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once local run is succesfull, train the container based model\n",
    "# uncomment install('matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-18 20:08:05 Starting - Starting the training job...\n",
      "2020-09-18 20:08:07 Starting - Launching requested ML instances......\n",
      "2020-09-18 20:09:20 Starting - Preparing the instances for training...\n",
      "2020-09-18 20:09:59 Downloading - Downloading input data...\n",
      "2020-09-18 20:10:16 Training - Downloading the training image..\u001b[34m2020-09-18 20:10:48,417 sagemaker-training-toolkit INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-09-18 20:10:48,419 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-18 20:10:48,427 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-09-18 20:10:48,727 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-18 20:10:51,788 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-18 20:10:51,798 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-09-18 20:10:51,808 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"features\": \"NA\",\n",
      "        \"n-estimators\": 100,\n",
      "        \"min-samples-leaf\": 2,\n",
      "        \"target\": \"NA\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"rf-scikit-2020-09-18-20-08-04-892\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-120286446822/rf-scikit-2020-09-18-20-08-04-892/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"model_script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"model_script.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"features\":\"NA\",\"min-samples-leaf\":2,\"n-estimators\":100,\"target\":\"NA\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=model_script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=model_script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-120286446822/rf-scikit-2020-09-18-20-08-04-892/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"features\":\"NA\",\"min-samples-leaf\":2,\"n-estimators\":100,\"target\":\"NA\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"rf-scikit-2020-09-18-20-08-04-892\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-120286446822/rf-scikit-2020-09-18-20-08-04-892/source/sourcedir.tar.gz\",\"module_name\":\"model_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"model_script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--features\",\"NA\",\"--min-samples-leaf\",\"2\",\"--n-estimators\",\"100\",\"--target\",\"NA\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURES=NA\u001b[0m\n",
      "\u001b[34mSM_HP_N-ESTIMATORS=100\u001b[0m\n",
      "\u001b[34mSM_HP_MIN-SAMPLES-LEAF=2\u001b[0m\n",
      "\u001b[34mSM_HP_TARGET=NA\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python model_script.py --features NA --min-samples-leaf 2 --n-estimators 100 --target NA\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mCollecting matplotlib\n",
      "  Downloading matplotlib-3.3.2-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\u001b[0m\n",
      "\n",
      "2020-09-18 20:10:48 Training - Training image download completed. Training in progress.\u001b[34mRequirement already satisfied: python-dateutil>=2.1 in /miniconda3/lib/python3.7/site-packages (from matplotlib) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (88 kB)\u001b[0m\n",
      "\u001b[34mCollecting certifi>=2020.06.20\n",
      "  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.7/site-packages (from matplotlib) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.7/site-packages (from matplotlib) (1.18.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /miniconda3/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: kiwisolver, certifi, cycler, pyparsing, matplotlib\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2020.4.5.1\n",
      "    Uninstalling certifi-2020.4.5.1:\n",
      "      Successfully uninstalled certifi-2020.4.5.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed certifi-2020.6.20 cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.3.2 pyparsing-2.4.7\u001b[0m\n",
      "\u001b[34mCollecting seaborn\n",
      "  Downloading seaborn-0.11.0-py3-none-any.whl (283 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.7/site-packages (from seaborn) (1.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.7/site-packages (from seaborn) (1.18.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib>=2.2 in /miniconda3/lib/python3.7/site-packages (from seaborn) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.7/site-packages (from seaborn) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2020.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.6.1 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2020.06.20 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2020.6.20)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (7.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /miniconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=0.23->seaborn) (1.15.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: seaborn\u001b[0m\n",
      "\u001b[34mSuccessfully installed seaborn-0.11.0\u001b[0m\n",
      "\u001b[34mextracting arguments\u001b[0m\n",
      "\u001b[34mloading train data\u001b[0m\n",
      "\u001b[34margs.train :  /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mloading test data\u001b[0m\n",
      "\u001b[34margs.test :  /opt/ml/input/data/test\n",
      "\u001b[0m\n",
      "\u001b[34mbuilding training and testing datasets\u001b[0m\n",
      "\u001b[34m!! below data print includes col_to_predict !!\u001b[0m\n",
      "\u001b[34mtraining data shape :  (850, 11)\u001b[0m\n",
      "\u001b[34mtrain data head(1) : \n",
      "    0         1         2    3    4    5    6    7    8    9    10\u001b[0m\n",
      "\u001b[34m0  0.0  0.237501  3.715636  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0\n",
      "\u001b[0m\n",
      "\u001b[34m!! WARNING !!\u001b[0m\n",
      "\u001b[34m0th index column is assumed as : col_to_predict\n",
      "\u001b[0m\n",
      "\u001b[34mcolumns :  [ 0  1  2  3  4  5  6  7  8  9 10]\u001b[0m\n",
      "\u001b[34mcol_to_predict : 0, arg_type : <class 'numpy.int64'>\u001b[0m\n",
      "\u001b[34mtrain : [0. 1.] : [526 324]\u001b[0m\n",
      "\u001b[34mtest  : [0. 1.] : [526 324]\u001b[0m\n",
      "\u001b[34mmodel training started!!\u001b[0m\n",
      "\u001b[34mmodel training on num features :  10 \n",
      "\u001b[0m\n",
      "\u001b[34maccuracy  : 0.92\u001b[0m\n",
      "\u001b[34mprecision : 0.92\u001b[0m\n",
      "\u001b[34mrecall    : 0.9\n",
      "\u001b[0m\n",
      "\u001b[34mClassification report : \n",
      "              precision    recall  f1-score   support\n",
      "\u001b[0m\n",
      "\u001b[34mnot-survived       0.91      0.96      0.93       526\n",
      "    survived       0.93      0.85      0.88       324\n",
      "\n",
      "    accuracy                           0.92       850\n",
      "   macro avg       0.92      0.90      0.91       850\u001b[0m\n",
      "\u001b[34mweighted avg       0.92      0.92      0.91       850\n",
      "\u001b[0m\n",
      "\u001b[34mmodel persisted at /opt/ml/model/model.joblib\u001b[0m\n",
      "\u001b[34m2020-09-18 20:10:58,575 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-09-18 20:11:19 Uploading - Uploading generated training model\n",
      "2020-09-18 20:11:19 Completed - Training job completed\n",
      "Training seconds: 80\n",
      "Billable seconds: 80\n"
     ]
    }
   ],
   "source": [
    "# TRAIN the model\n",
    "ml_estimator.fit({'train':s3_pp_train, 'test': s3_pp_test}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# step_1 : get models\n",
    "pp_transformer_model = sklearn_preprocessor.create_model()\n",
    "ml_estimator_model   = ml_estimator.create_model()\n",
    "\n",
    "# step_2 : set-up pipeline\n",
    "model_name    = 'sklearn-inference-pipeline-' + timestamp_prefix\n",
    "endpoint_name = 'sklearn-inference-pipeline-ep-' + timestamp_prefix\n",
    "ml_pipeline_model = PipelineModel(\n",
    "                                    name=model_name, \n",
    "                                    role=role, \n",
    "                                    models=[\n",
    "                                            pp_transformer_model, \n",
    "                                            ml_estimator_model\n",
    "                                            ]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# batch prediction job\n",
    "\n",
    "\"\"\"\n",
    "ml_pipeline_tf = ml_pipeline_model.transformer(\n",
    "                                            instance_count=1, \n",
    "                                            instance_type='ml.m5.xlarge',\n",
    "                                            assemble_with = 'Line',\n",
    "                                            accept = 'text/csv')\n",
    "\n",
    "# input : s3_input_raw_val (raw input data)\n",
    "ml_pipeline_tf.transform(s3_input_raw_val, content_type=\"text/csv\")\n",
    "print(\"Waiting for transform job: \" + ml_pipeline_tf.latest_transform_job.job_name)\n",
    "ml_pipeline_tf.wait()\n",
    "s3_pred_val = ml_pipeline_tf.output_path\n",
    "s3_pred_val\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deploy pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------"
     ]
    }
   ],
   "source": [
    "#sm_model.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge', endpoint_name=endpoint_name)\n",
    "ml_pipeline_model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge', endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict from pipeline endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sklearn-inference-pipeline-ep-2020-09-18-20-12-36'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Plotcharsky, Mr. Vasil</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>349227</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass                    name   sex  age  sibsp  parch  ticket    fare  \\\n",
       "1132     3.0  Plotcharsky, Mr. Vasil  male  NaN    0.0    0.0  349227  7.8958   \n",
       "\n",
       "     cabin embarked  boat  body home.dest survived  \n",
       "1132  None        S  None   NaN      None        0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['3.0, Plotcharsky, male, 12, 0.0, 0.0, 349227, 7.8958, None, S, None, na, None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from container-1 with message \"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/sklearn-inference-pipeline-ep-2020-09-18-20-12-36 in account 120286446822 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-7b17eac6bd77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     accept=CONTENT_TYPE_JSON)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mrequest_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_request_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (500) from container-1 with message \"<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/sklearn-inference-pipeline-ep-2020-09-18-20-12-36 in account 120286446822 for more information."
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "\n",
    "\n",
    "payload = '3.0, Plotcharsky, male, 12, 0.0, 0.0, 349227, 7.8958, None, S, None, na, None' # 0\n",
    "#\n",
    "\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=csv_serializer,\n",
    "    content_type=CONTENT_TYPE_CSV,\n",
    "    accept=CONTENT_TYPE_JSON)\n",
    "\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict : only using model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy only the - ml model\n",
    "ml_predictor = ml_estimator.deploy(instance_type='ml.m4.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "import boto3\n",
    "\n",
    "def get_csv_output_from_s3(s3uri, file_name):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    prefix = parsed_url.path[1:]\n",
    "    s3 = boto3.resource('s3')\n",
    "    print(bucket_name)\n",
    "    print(prefix)\n",
    "    print(file_name)\n",
    "    obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n",
    "    return obj.get()[\"Body\"].read().decode('utf-8')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path       = preprocessed_val\n",
    "batch_file = 'abalone_val.csv' # imp\n",
    "output = get_csv_output_from_s3(path, '{}.out'.format(batch_file))\n",
    "validate_df = pd.read_csv(io.StringIO(output), sep=\",\", header=None)\n",
    "print(validate_df.shape)\n",
    "validate_df.sample(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `data` is a NumPy array or a Python list.\n",
    "# `response` is a NumPy array.\n",
    "\n",
    "#payload = validate_df.drop(columns=[0]).values\n",
    "payload = validate_df.values\n",
    "\n",
    "response = ml_predictor.predict(payload)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint <a class=\"anchor\" id=\"delete_endpoint\"></a>\n",
    "Once we are finished with the endpoint, we clean up the resources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
